{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of mel_spec_pix2pix",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Laxmaan/Emotional-Speech-Synthesis/blob/main/Pix2pix%20to%20convert%20from%20normal%20mel%20spectrogram%20to%20emotional\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wNjDKdQy35h"
      },
      "source": [
        "# Install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D27DLWGWobIj",
        "outputId": "122602c0-dd19-4eea-efd0-ffbec44d0eca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# mount drive to access data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFOLU7cx7udI"
      },
      "source": [
        "import os\n",
        "os.chdir('drive/My Drive/IST597/pix2pix')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRm-USlsHgEV",
        "outputId": "c0458eb7-1146-4042-f4c1-8c692fced0af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pytorch-CycleGAN-and-pix2pix'...\n",
            "remote: Enumerating objects: 2238, done.\u001b[K\n",
            "remote: Total 2238 (delta 0), reused 0 (delta 0), pack-reused 2238\u001b[K\n",
            "Receiving objects: 100% (2238/2238), 8.04 MiB | 3.99 MiB/s, done.\n",
            "Resolving deltas: 100% (1449/1449), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pt3igws3eiVp"
      },
      "source": [
        "os.chdir('pytorch-CycleGAN-and-pix2pix/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1EySlOXwwoa",
        "outputId": "ab4585a8-b434-46cd-efa9-4115fdcff89a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (1.5.0+cu101)\n",
            "Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (0.6.0+cu101)\n",
            "Collecting dominate>=2.3.1\n",
            "  Downloading https://files.pythonhosted.org/packages/4f/e6/794a119963b7cfe4bd41177c8f9d4195fe901652f04189fbd2edf513c7b2/dominate-2.5.1-py2.py3-none-any.whl\n",
            "Collecting visdom>=0.1.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/75/e078f5a2e1df7e0d3044749089fc2823e62d029cc027ed8ae5d71fafcbdc/visdom-0.1.8.9.tar.gz (676kB)\n",
            "\u001b[K     |████████████████████████████████| 686kB 11.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->-r requirements.txt (line 1)) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->-r requirements.txt (line 1)) (1.18.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.2.1->-r requirements.txt (line 2)) (7.0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from visdom>=0.1.8.3->-r requirements.txt (line 4)) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from visdom>=0.1.8.3->-r requirements.txt (line 4)) (2.23.0)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.6/dist-packages (from visdom>=0.1.8.3->-r requirements.txt (line 4)) (4.5.3)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.6/dist-packages (from visdom>=0.1.8.3->-r requirements.txt (line 4)) (19.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from visdom>=0.1.8.3->-r requirements.txt (line 4)) (1.12.0)\n",
            "Collecting jsonpatch\n",
            "  Downloading https://files.pythonhosted.org/packages/82/53/73ca86f2a680c705dcd1708be4887c559dfe9ed250486dd3ccd8821b8ccb/jsonpatch-1.25-py2.py3-none-any.whl\n",
            "Collecting torchfile\n",
            "  Downloading https://files.pythonhosted.org/packages/91/af/5b305f86f2d218091af657ddb53f984ecbd9518ca9fe8ef4103a007252c9/torchfile-0.1.0.tar.gz\n",
            "Collecting websocket-client\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 47.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->visdom>=0.1.8.3->-r requirements.txt (line 4)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->visdom>=0.1.8.3->-r requirements.txt (line 4)) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->visdom>=0.1.8.3->-r requirements.txt (line 4)) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->visdom>=0.1.8.3->-r requirements.txt (line 4)) (1.24.3)\n",
            "Collecting jsonpointer>=1.9\n",
            "  Downloading https://files.pythonhosted.org/packages/18/b0/a80d29577c08eea401659254dfaed87f1af45272899e1812d7e01b679bc5/jsonpointer-2.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: visdom, torchfile\n",
            "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for visdom: filename=visdom-0.1.8.9-cp36-none-any.whl size=655250 sha256=b2b2925af18b281b59a38e4a2de3e57403f7f0ec02e856eb9611334a023dd1f7\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/19/a7/6d589ed967f4dfefd33bc166d081257bd4ed0cb618dccfd62a\n",
            "  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchfile: filename=torchfile-0.1.0-cp36-none-any.whl size=5712 sha256=ae1f3481df0aacac94d7f10e4083ec262c3fcb264dd03f07e4c852c6974fc16e\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/c3/d6/9a1cc8f3a99a0fc1124cae20153f36af59a6e683daca0a0814\n",
            "Successfully built visdom torchfile\n",
            "Installing collected packages: dominate, jsonpointer, jsonpatch, torchfile, websocket-client, visdom\n",
            "Successfully installed dominate-2.5.1 jsonpatch-1.25 jsonpointer-2.0 torchfile-0.1.0 visdom-0.1.8.9 websocket-client-0.57.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrdOettJxaCc",
        "outputId": "393f3aaf-08c5-4bf9-ee65-54e06504212e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!bash python datasets/combine_A_and_B.py --fold_A '../drive/My Drive/pix2pix_angry/A' --fold_B '../drive/My Drive/pix2pix_angry/B' --fold_AB '../drive/My Drive/pix2pix_angry/AB'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[fold_A] =  ../drive/My Drive/pix2pix_angry/A\n",
            "[fold_B] =  ../drive/My Drive/pix2pix_angry/B\n",
            "[fold_AB] =  ../drive/My Drive/pix2pix_angry/AB\n",
            "[num_imgs] =  1000000\n",
            "[use_AB] =  False\n",
            "split = val, use 157/157 images\n",
            "split = val, number of images = 157\n",
            "split = train, use 690/690 images\n",
            "split = train, number of images = 690\n",
            "split = test, use 154/154 images\n",
            "split = test, number of images = 154\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFw1kDQBx3LN"
      },
      "source": [
        "# Training\n",
        "\n",
        "-   `python train.py --dataroot ./datasets/facades --name facades_pix2pix --model pix2pix --direction BtoA`\n",
        "\n",
        "Change the `--dataroot` and `--name` to your own dataset's path and model's name. Use `--gpu_ids 0,1,..` to train on multiple GPUs and `--batch_size` to change the batch size. Add `--direction BtoA` if you want to train a model to transfrom from class B to A."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sp7TCT2x9dB",
        "outputId": "ebb7477e-336f-48ae-e5a8-852a48f9d97a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python train.py --dataroot '../AB1' --name mel_pix2pix --model pix2pix --preprocess crop --crop_size 80 --direction AtoB --netG resnet_6blocks --n_epochs 300 --n_epochs_decay 300 --checkpoints_dir './checkpoints' --epoch_count 264 --continue_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------- Options ---------------\n",
            "               batch_size: 1                             \n",
            "                    beta1: 0.5                           \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "           continue_train: False                         \n",
            "                crop_size: 80                            \t[default: 256]\n",
            "                 dataroot: ../AB1                        \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "              display_env: main                          \n",
            "             display_freq: 400                           \n",
            "               display_id: 1                             \n",
            "            display_ncols: 4                             \n",
            "             display_port: 8097                          \n",
            "           display_server: http://localhost              \n",
            "          display_winsize: 256                           \n",
            "                    epoch: latest                        \n",
            "              epoch_count: 1                             \n",
            "                 gan_mode: vanilla                       \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: True                          \t[default: None]\n",
            "                lambda_L1: 100.0                         \n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 286                           \n",
            "                       lr: 0.0002                        \n",
            "           lr_decay_iters: 50                            \n",
            "                lr_policy: linear                        \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: cycle_gan]\n",
            "                 n_epochs: 300                           \t[default: 100]\n",
            "           n_epochs_decay: 300                           \t[default: 100]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                  no_html: False                         \n",
            "                     norm: batch                         \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: train                         \n",
            "                pool_size: 0                             \n",
            "               preprocess: crop                          \t[default: resize_and_crop]\n",
            "               print_freq: 100                           \n",
            "             save_by_iter: False                         \n",
            "          save_epoch_freq: 5                             \n",
            "         save_latest_freq: 5000                          \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "         update_html_freq: 1000                          \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "The number of training images = 296\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "[Network D] Total number of parameters : 2.769 M\n",
            "-----------------------------------------------\n",
            "Setting up a new session...\n",
            "create web directory ./checkpoints/mel_pix2pix/web...\n",
            "(epoch: 1, iters: 100, time: 0.025, data: 0.903) G_GAN: 3.009 G_L1: 37.768 D_real: 0.171 D_fake: 0.055 \n",
            "(epoch: 1, iters: 200, time: 0.026, data: 0.002) G_GAN: 3.394 G_L1: 37.531 D_real: 0.126 D_fake: 0.942 \n",
            "End of epoch 1 / 600 \t Time Taken: 41 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 2, iters: 4, time: 0.025, data: 0.005) G_GAN: 2.846 G_L1: 27.491 D_real: 0.114 D_fake: 0.089 \n",
            "(epoch: 2, iters: 104, time: 0.062, data: 0.000) G_GAN: 3.656 G_L1: 26.475 D_real: 0.407 D_fake: 0.232 \n",
            "(epoch: 2, iters: 204, time: 0.024, data: 0.001) G_GAN: 2.779 G_L1: 30.606 D_real: 0.307 D_fake: 0.058 \n",
            "End of epoch 2 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 3, iters: 8, time: 0.022, data: 0.001) G_GAN: 2.865 G_L1: 26.469 D_real: 0.106 D_fake: 0.752 \n",
            "(epoch: 3, iters: 108, time: 0.028, data: 0.001) G_GAN: 3.137 G_L1: 31.196 D_real: 2.637 D_fake: 0.013 \n",
            "(epoch: 3, iters: 208, time: 0.055, data: 0.001) G_GAN: 4.855 G_L1: 44.651 D_real: 0.010 D_fake: 0.751 \n",
            "End of epoch 3 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 4, iters: 12, time: 0.022, data: 0.001) G_GAN: 2.420 G_L1: 35.283 D_real: 0.113 D_fake: 0.303 \n",
            "(epoch: 4, iters: 112, time: 0.024, data: 0.001) G_GAN: 2.496 G_L1: 34.644 D_real: 0.060 D_fake: 0.105 \n",
            "(epoch: 4, iters: 212, time: 0.024, data: 0.001) G_GAN: 2.956 G_L1: 37.235 D_real: 0.013 D_fake: 0.183 \n",
            "End of epoch 4 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 5, iters: 16, time: 0.060, data: 0.001) G_GAN: 2.775 G_L1: 31.361 D_real: 0.030 D_fake: 1.070 \n",
            "(epoch: 5, iters: 116, time: 0.025, data: 0.001) G_GAN: 1.049 G_L1: 29.138 D_real: 1.041 D_fake: 0.187 \n",
            "(epoch: 5, iters: 216, time: 0.022, data: 0.001) G_GAN: 4.955 G_L1: 39.694 D_real: 0.022 D_fake: 0.617 \n",
            "saving the model at the end of epoch 5, iters 1480\n",
            "End of epoch 5 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 6, iters: 20, time: 0.022, data: 0.001) G_GAN: 3.772 G_L1: 27.973 D_real: 0.268 D_fake: 0.017 \n",
            "(epoch: 6, iters: 120, time: 0.058, data: 0.001) G_GAN: 2.081 G_L1: 26.018 D_real: 0.329 D_fake: 0.069 \n",
            "(epoch: 6, iters: 220, time: 0.037, data: 0.001) G_GAN: 2.934 G_L1: 46.323 D_real: 0.012 D_fake: 0.246 \n",
            "End of epoch 6 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 7, iters: 24, time: 0.025, data: 0.003) G_GAN: 2.503 G_L1: 28.442 D_real: 0.248 D_fake: 0.080 \n",
            "(epoch: 7, iters: 124, time: 0.027, data: 0.001) G_GAN: 4.156 G_L1: 34.524 D_real: 0.030 D_fake: 0.023 \n",
            "(epoch: 7, iters: 224, time: 0.059, data: 0.001) G_GAN: 3.357 G_L1: 21.665 D_real: 0.089 D_fake: 0.143 \n",
            "End of epoch 7 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 8, iters: 28, time: 0.022, data: 0.001) G_GAN: 2.753 G_L1: 36.223 D_real: 0.050 D_fake: 0.584 \n",
            "(epoch: 8, iters: 128, time: 0.027, data: 0.001) G_GAN: 2.223 G_L1: 29.213 D_real: 0.399 D_fake: 0.198 \n",
            "(epoch: 8, iters: 228, time: 0.028, data: 0.001) G_GAN: 0.949 G_L1: 33.408 D_real: 0.788 D_fake: 0.086 \n",
            "End of epoch 8 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 9, iters: 32, time: 0.060, data: 0.001) G_GAN: 3.311 G_L1: 28.095 D_real: 0.027 D_fake: 0.158 \n",
            "(epoch: 9, iters: 132, time: 0.026, data: 0.001) G_GAN: 1.939 G_L1: 31.108 D_real: 0.629 D_fake: 0.340 \n",
            "(epoch: 9, iters: 232, time: 0.023, data: 0.001) G_GAN: 2.627 G_L1: 28.352 D_real: 0.074 D_fake: 0.280 \n",
            "End of epoch 9 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 10, iters: 36, time: 0.023, data: 0.001) G_GAN: 4.726 G_L1: 56.382 D_real: 0.020 D_fake: 0.032 \n",
            "(epoch: 10, iters: 136, time: 0.063, data: 0.001) G_GAN: 2.825 G_L1: 39.330 D_real: 0.052 D_fake: 0.156 \n",
            "(epoch: 10, iters: 236, time: 0.025, data: 0.001) G_GAN: 2.425 G_L1: 18.498 D_real: 0.134 D_fake: 0.140 \n",
            "saving the model at the end of epoch 10, iters 2960\n",
            "End of epoch 10 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 11, iters: 40, time: 0.024, data: 0.001) G_GAN: 5.805 G_L1: 35.416 D_real: 0.003 D_fake: 2.117 \n",
            "(epoch: 11, iters: 140, time: 0.023, data: 0.001) G_GAN: 3.320 G_L1: 30.384 D_real: 0.066 D_fake: 0.084 \n",
            "(epoch: 11, iters: 240, time: 0.064, data: 0.001) G_GAN: 3.655 G_L1: 33.041 D_real: 0.008 D_fake: 0.815 \n",
            "End of epoch 11 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 12, iters: 44, time: 0.023, data: 0.001) G_GAN: 3.513 G_L1: 42.028 D_real: 0.003 D_fake: 0.143 \n",
            "(epoch: 12, iters: 144, time: 0.028, data: 0.001) G_GAN: 4.383 G_L1: 29.423 D_real: 1.039 D_fake: 0.009 \n",
            "(epoch: 12, iters: 244, time: 0.024, data: 0.001) G_GAN: 3.908 G_L1: 24.001 D_real: 0.282 D_fake: 0.025 \n",
            "End of epoch 12 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 13, iters: 48, time: 0.070, data: 0.001) G_GAN: 2.834 G_L1: 26.432 D_real: 0.078 D_fake: 0.163 \n",
            "(epoch: 13, iters: 148, time: 0.030, data: 0.001) G_GAN: 2.402 G_L1: 43.624 D_real: 0.851 D_fake: 0.031 \n",
            "(epoch: 13, iters: 248, time: 0.023, data: 0.002) G_GAN: 1.568 G_L1: 28.089 D_real: 0.828 D_fake: 0.056 \n",
            "End of epoch 13 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 14, iters: 52, time: 0.022, data: 0.001) G_GAN: 4.455 G_L1: 22.987 D_real: 0.119 D_fake: 1.280 \n",
            "(epoch: 14, iters: 152, time: 0.086, data: 0.001) G_GAN: 2.542 G_L1: 23.846 D_real: 0.441 D_fake: 0.174 \n",
            "(epoch: 14, iters: 252, time: 0.023, data: 0.001) G_GAN: 3.546 G_L1: 24.306 D_real: 0.153 D_fake: 0.298 \n",
            "End of epoch 14 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 15, iters: 56, time: 0.023, data: 0.001) G_GAN: 3.303 G_L1: 22.665 D_real: 0.057 D_fake: 0.121 \n",
            "(epoch: 15, iters: 156, time: 0.024, data: 0.001) G_GAN: 3.096 G_L1: 33.757 D_real: 0.163 D_fake: 0.095 \n",
            "(epoch: 15, iters: 256, time: 0.065, data: 0.001) G_GAN: 6.004 G_L1: 33.435 D_real: 0.384 D_fake: 0.013 \n",
            "saving the model at the end of epoch 15, iters 4440\n",
            "End of epoch 15 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 16, iters: 60, time: 0.023, data: 0.001) G_GAN: 4.328 G_L1: 37.409 D_real: 0.002 D_fake: 0.511 \n",
            "(epoch: 16, iters: 160, time: 0.023, data: 0.001) G_GAN: 3.418 G_L1: 14.381 D_real: 0.154 D_fake: 0.732 \n",
            "(epoch: 16, iters: 260, time: 0.022, data: 0.001) G_GAN: 4.345 G_L1: 41.527 D_real: 0.083 D_fake: 0.089 \n",
            "End of epoch 16 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 17, iters: 64, time: 0.105, data: 0.002) G_GAN: 4.188 G_L1: 33.274 D_real: 0.340 D_fake: 0.011 \n",
            "(epoch: 17, iters: 164, time: 0.025, data: 0.001) G_GAN: 4.865 G_L1: 39.821 D_real: 0.022 D_fake: 0.010 \n",
            "(epoch: 17, iters: 264, time: 0.024, data: 0.001) G_GAN: 4.930 G_L1: 24.599 D_real: 0.016 D_fake: 0.075 \n",
            "saving the latest model (epoch 17, total_iters 5000)\n",
            "End of epoch 17 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 18, iters: 68, time: 0.025, data: 0.001) G_GAN: 4.178 G_L1: 27.144 D_real: 1.181 D_fake: 0.003 \n",
            "(epoch: 18, iters: 168, time: 0.074, data: 0.001) G_GAN: 6.095 G_L1: 37.638 D_real: 0.427 D_fake: 0.003 \n",
            "(epoch: 18, iters: 268, time: 0.029, data: 0.001) G_GAN: 5.076 G_L1: 38.176 D_real: 0.023 D_fake: 0.017 \n",
            "End of epoch 18 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 19, iters: 72, time: 0.028, data: 0.001) G_GAN: 2.187 G_L1: 33.395 D_real: 0.772 D_fake: 0.057 \n",
            "(epoch: 19, iters: 172, time: 0.028, data: 0.001) G_GAN: 2.496 G_L1: 29.529 D_real: 0.346 D_fake: 0.164 \n",
            "(epoch: 19, iters: 272, time: 0.210, data: 0.001) G_GAN: 3.348 G_L1: 37.365 D_real: 0.004 D_fake: 0.036 \n",
            "End of epoch 19 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 20, iters: 76, time: 0.023, data: 0.001) G_GAN: 2.585 G_L1: 29.951 D_real: 0.324 D_fake: 0.389 \n",
            "(epoch: 20, iters: 176, time: 0.023, data: 0.001) G_GAN: 3.436 G_L1: 24.259 D_real: 0.371 D_fake: 0.143 \n",
            "(epoch: 20, iters: 276, time: 0.023, data: 0.001) G_GAN: 4.754 G_L1: 22.185 D_real: 0.018 D_fake: 2.746 \n",
            "saving the model at the end of epoch 20, iters 5920\n",
            "End of epoch 20 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 21, iters: 80, time: 0.079, data: 0.001) G_GAN: 3.803 G_L1: 22.584 D_real: 0.004 D_fake: 0.118 \n",
            "(epoch: 21, iters: 180, time: 0.023, data: 0.001) G_GAN: 2.509 G_L1: 31.570 D_real: 0.010 D_fake: 0.288 \n",
            "(epoch: 21, iters: 280, time: 0.025, data: 0.001) G_GAN: 3.051 G_L1: 21.904 D_real: 0.107 D_fake: 0.089 \n",
            "End of epoch 21 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 22, iters: 84, time: 0.026, data: 0.001) G_GAN: 1.860 G_L1: 23.411 D_real: 0.366 D_fake: 0.091 \n",
            "(epoch: 22, iters: 184, time: 0.095, data: 0.001) G_GAN: 5.120 G_L1: 51.456 D_real: 0.001 D_fake: 0.523 \n",
            "(epoch: 22, iters: 284, time: 0.029, data: 0.001) G_GAN: 4.378 G_L1: 43.492 D_real: 0.023 D_fake: 0.129 \n",
            "End of epoch 22 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 23, iters: 88, time: 0.024, data: 0.001) G_GAN: 4.529 G_L1: 31.697 D_real: 0.005 D_fake: 0.585 \n",
            "(epoch: 23, iters: 188, time: 0.023, data: 0.001) G_GAN: 3.020 G_L1: 27.510 D_real: 0.271 D_fake: 0.267 \n",
            "(epoch: 23, iters: 288, time: 0.073, data: 0.001) G_GAN: 0.899 G_L1: 20.771 D_real: 1.841 D_fake: 0.022 \n",
            "End of epoch 23 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 24, iters: 92, time: 0.024, data: 0.001) G_GAN: 2.363 G_L1: 31.322 D_real: 0.183 D_fake: 0.175 \n",
            "(epoch: 24, iters: 192, time: 0.024, data: 0.001) G_GAN: 3.232 G_L1: 22.225 D_real: 0.931 D_fake: 0.010 \n",
            "(epoch: 24, iters: 292, time: 0.026, data: 0.001) G_GAN: 5.053 G_L1: 33.201 D_real: 0.031 D_fake: 0.023 \n",
            "End of epoch 24 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 25, iters: 96, time: 0.074, data: 0.001) G_GAN: 1.543 G_L1: 22.814 D_real: 0.994 D_fake: 0.651 \n",
            "(epoch: 25, iters: 196, time: 0.030, data: 0.001) G_GAN: 5.513 G_L1: 25.118 D_real: 0.088 D_fake: 0.003 \n",
            "(epoch: 25, iters: 296, time: 0.022, data: 0.001) G_GAN: 3.484 G_L1: 23.763 D_real: 0.050 D_fake: 0.040 \n",
            "saving the model at the end of epoch 25, iters 7400\n",
            "End of epoch 25 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 26, iters: 100, time: 0.023, data: 0.114) G_GAN: 3.911 G_L1: 33.237 D_real: 0.042 D_fake: 0.181 \n",
            "(epoch: 26, iters: 200, time: 0.091, data: 0.001) G_GAN: 4.600 G_L1: 29.564 D_real: 0.015 D_fake: 0.019 \n",
            "End of epoch 26 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 27, iters: 4, time: 0.024, data: 0.002) G_GAN: 3.064 G_L1: 27.516 D_real: 0.075 D_fake: 0.360 \n",
            "(epoch: 27, iters: 104, time: 0.029, data: 0.000) G_GAN: 4.848 G_L1: 45.084 D_real: 0.004 D_fake: 0.013 \n",
            "(epoch: 27, iters: 204, time: 0.027, data: 0.001) G_GAN: 3.861 G_L1: 45.259 D_real: 2.315 D_fake: 0.013 \n",
            "End of epoch 27 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 28, iters: 8, time: 0.081, data: 0.001) G_GAN: 3.956 G_L1: 28.852 D_real: 0.936 D_fake: 0.004 \n",
            "(epoch: 28, iters: 108, time: 0.023, data: 0.001) G_GAN: 3.793 G_L1: 38.808 D_real: 0.088 D_fake: 0.158 \n",
            "(epoch: 28, iters: 208, time: 0.022, data: 0.001) G_GAN: 3.438 G_L1: 34.018 D_real: 0.196 D_fake: 0.055 \n",
            "End of epoch 28 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 29, iters: 12, time: 0.023, data: 0.001) G_GAN: 4.849 G_L1: 18.090 D_real: 0.143 D_fake: 0.041 \n",
            "(epoch: 29, iters: 112, time: 0.091, data: 0.001) G_GAN: 3.098 G_L1: 27.865 D_real: 0.118 D_fake: 0.176 \n",
            "(epoch: 29, iters: 212, time: 0.023, data: 0.001) G_GAN: 3.305 G_L1: 27.465 D_real: 0.319 D_fake: 0.023 \n",
            "End of epoch 29 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 30, iters: 16, time: 0.023, data: 0.001) G_GAN: 4.060 G_L1: 32.353 D_real: 0.029 D_fake: 0.037 \n",
            "(epoch: 30, iters: 116, time: 0.023, data: 0.001) G_GAN: 4.256 G_L1: 45.980 D_real: 0.014 D_fake: 0.031 \n",
            "(epoch: 30, iters: 216, time: 0.080, data: 0.001) G_GAN: 3.994 G_L1: 34.182 D_real: 0.004 D_fake: 0.092 \n",
            "saving the model at the end of epoch 30, iters 8880\n",
            "End of epoch 30 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 31, iters: 20, time: 0.029, data: 0.001) G_GAN: 3.466 G_L1: 37.971 D_real: 0.000 D_fake: 1.726 \n",
            "(epoch: 31, iters: 120, time: 0.023, data: 0.001) G_GAN: 1.289 G_L1: 30.786 D_real: 2.465 D_fake: 0.074 \n",
            "(epoch: 31, iters: 220, time: 0.026, data: 0.001) G_GAN: 2.661 G_L1: 21.855 D_real: 0.562 D_fake: 0.056 \n",
            "End of epoch 31 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 32, iters: 24, time: 0.081, data: 0.001) G_GAN: 3.482 G_L1: 30.918 D_real: 0.470 D_fake: 0.034 \n",
            "(epoch: 32, iters: 124, time: 0.028, data: 0.001) G_GAN: 2.693 G_L1: 18.838 D_real: 0.104 D_fake: 0.241 \n",
            "(epoch: 32, iters: 224, time: 0.025, data: 0.001) G_GAN: 2.017 G_L1: 25.370 D_real: 2.132 D_fake: 0.021 \n",
            "End of epoch 32 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 33, iters: 28, time: 0.023, data: 0.001) G_GAN: 2.566 G_L1: 21.800 D_real: 0.231 D_fake: 0.094 \n",
            "(epoch: 33, iters: 128, time: 0.087, data: 0.001) G_GAN: 5.188 G_L1: 38.538 D_real: 0.012 D_fake: 0.009 \n",
            "(epoch: 33, iters: 228, time: 0.024, data: 0.002) G_GAN: 4.082 G_L1: 40.011 D_real: 0.018 D_fake: 0.411 \n",
            "End of epoch 33 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 34, iters: 32, time: 0.024, data: 0.001) G_GAN: 5.906 G_L1: 25.607 D_real: 0.041 D_fake: 0.009 \n",
            "(epoch: 34, iters: 132, time: 0.029, data: 0.001) G_GAN: 3.454 G_L1: 29.537 D_real: 0.008 D_fake: 0.041 \n",
            "(epoch: 34, iters: 232, time: 0.078, data: 0.001) G_GAN: 3.438 G_L1: 25.625 D_real: 0.004 D_fake: 0.488 \n",
            "saving the latest model (epoch 34, total_iters 10000)\n",
            "End of epoch 34 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 35, iters: 36, time: 0.028, data: 0.001) G_GAN: 0.634 G_L1: 21.519 D_real: 1.238 D_fake: 0.564 \n",
            "(epoch: 35, iters: 136, time: 0.023, data: 0.001) G_GAN: 4.693 G_L1: 27.110 D_real: 0.010 D_fake: 1.156 \n",
            "(epoch: 35, iters: 236, time: 0.023, data: 0.001) G_GAN: 5.836 G_L1: 39.225 D_real: 0.062 D_fake: 0.012 \n",
            "saving the model at the end of epoch 35, iters 10360\n",
            "End of epoch 35 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 36, iters: 40, time: 0.085, data: 0.001) G_GAN: 4.029 G_L1: 21.527 D_real: 0.064 D_fake: 0.282 \n",
            "(epoch: 36, iters: 140, time: 0.023, data: 0.001) G_GAN: 1.490 G_L1: 15.833 D_real: 0.673 D_fake: 0.047 \n",
            "(epoch: 36, iters: 240, time: 0.028, data: 0.001) G_GAN: 3.379 G_L1: 26.120 D_real: 0.132 D_fake: 0.250 \n",
            "End of epoch 36 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 37, iters: 44, time: 0.024, data: 0.001) G_GAN: 6.158 G_L1: 25.824 D_real: 0.700 D_fake: 0.001 \n",
            "(epoch: 37, iters: 144, time: 0.096, data: 0.001) G_GAN: 4.487 G_L1: 24.672 D_real: 0.098 D_fake: 0.011 \n",
            "(epoch: 37, iters: 244, time: 0.026, data: 0.001) G_GAN: 4.418 G_L1: 37.599 D_real: 0.003 D_fake: 0.076 \n",
            "End of epoch 37 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 38, iters: 48, time: 0.023, data: 0.001) G_GAN: 4.806 G_L1: 40.239 D_real: 0.027 D_fake: 0.025 \n",
            "(epoch: 38, iters: 148, time: 0.024, data: 0.002) G_GAN: 4.015 G_L1: 31.905 D_real: 0.150 D_fake: 0.021 \n",
            "(epoch: 38, iters: 248, time: 0.088, data: 0.001) G_GAN: 2.856 G_L1: 16.011 D_real: 0.257 D_fake: 0.357 \n",
            "End of epoch 38 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 39, iters: 52, time: 0.023, data: 0.001) G_GAN: 3.013 G_L1: 22.957 D_real: 0.024 D_fake: 0.298 \n",
            "(epoch: 39, iters: 152, time: 0.024, data: 0.001) G_GAN: 5.990 G_L1: 34.075 D_real: 0.308 D_fake: 0.003 \n",
            "(epoch: 39, iters: 252, time: 0.022, data: 0.001) G_GAN: 3.563 G_L1: 25.756 D_real: 0.020 D_fake: 0.113 \n",
            "End of epoch 39 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 40, iters: 56, time: 0.084, data: 0.001) G_GAN: 5.078 G_L1: 27.913 D_real: 0.913 D_fake: 0.004 \n",
            "(epoch: 40, iters: 156, time: 0.024, data: 0.001) G_GAN: 4.179 G_L1: 31.803 D_real: 0.024 D_fake: 0.037 \n",
            "(epoch: 40, iters: 256, time: 0.023, data: 0.001) G_GAN: 3.542 G_L1: 40.444 D_real: 0.178 D_fake: 0.142 \n",
            "saving the model at the end of epoch 40, iters 11840\n",
            "End of epoch 40 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 41, iters: 60, time: 0.023, data: 0.001) G_GAN: 2.919 G_L1: 30.139 D_real: 0.019 D_fake: 0.706 \n",
            "(epoch: 41, iters: 160, time: 0.128, data: 0.001) G_GAN: 4.080 G_L1: 21.581 D_real: 0.013 D_fake: 0.042 \n",
            "(epoch: 41, iters: 260, time: 0.029, data: 0.001) G_GAN: 3.286 G_L1: 53.783 D_real: 0.001 D_fake: 0.133 \n",
            "End of epoch 41 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 42, iters: 64, time: 0.038, data: 0.001) G_GAN: 4.911 G_L1: 23.129 D_real: 0.031 D_fake: 0.042 \n",
            "(epoch: 42, iters: 164, time: 0.024, data: 0.004) G_GAN: 2.919 G_L1: 26.415 D_real: 0.007 D_fake: 0.271 \n",
            "(epoch: 42, iters: 264, time: 0.092, data: 0.001) G_GAN: 3.987 G_L1: 28.782 D_real: 0.366 D_fake: 0.014 \n",
            "End of epoch 42 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 43, iters: 68, time: 0.023, data: 0.001) G_GAN: 6.102 G_L1: 30.291 D_real: 0.170 D_fake: 0.008 \n",
            "(epoch: 43, iters: 168, time: 0.022, data: 0.001) G_GAN: 4.762 G_L1: 48.100 D_real: 0.001 D_fake: 2.017 \n",
            "(epoch: 43, iters: 268, time: 0.023, data: 0.001) G_GAN: 3.809 G_L1: 49.292 D_real: 0.002 D_fake: 0.190 \n",
            "End of epoch 43 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 44, iters: 72, time: 0.092, data: 0.001) G_GAN: 4.904 G_L1: 26.507 D_real: 0.046 D_fake: 0.056 \n",
            "(epoch: 44, iters: 172, time: 0.023, data: 0.001) G_GAN: 3.545 G_L1: 45.237 D_real: 0.000 D_fake: 0.127 \n",
            "(epoch: 44, iters: 272, time: 0.028, data: 0.001) G_GAN: 3.911 G_L1: 25.367 D_real: 0.100 D_fake: 0.049 \n",
            "End of epoch 44 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 45, iters: 76, time: 0.023, data: 0.001) G_GAN: 4.869 G_L1: 24.846 D_real: 0.007 D_fake: 0.624 \n",
            "(epoch: 45, iters: 176, time: 0.089, data: 0.001) G_GAN: 4.238 G_L1: 47.765 D_real: 0.000 D_fake: 0.020 \n",
            "(epoch: 45, iters: 276, time: 0.024, data: 0.001) G_GAN: 4.477 G_L1: 30.230 D_real: 0.064 D_fake: 0.818 \n",
            "saving the model at the end of epoch 45, iters 13320\n",
            "End of epoch 45 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 46, iters: 80, time: 0.023, data: 0.001) G_GAN: 3.504 G_L1: 32.612 D_real: 0.084 D_fake: 0.083 \n",
            "(epoch: 46, iters: 180, time: 0.034, data: 0.001) G_GAN: 4.378 G_L1: 20.731 D_real: 0.014 D_fake: 0.040 \n",
            "(epoch: 46, iters: 280, time: 0.098, data: 0.001) G_GAN: 4.439 G_L1: 23.332 D_real: 0.005 D_fake: 0.116 \n",
            "End of epoch 46 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 47, iters: 84, time: 0.028, data: 0.001) G_GAN: 3.946 G_L1: 28.863 D_real: 0.023 D_fake: 0.096 \n",
            "(epoch: 47, iters: 184, time: 0.024, data: 0.001) G_GAN: 3.985 G_L1: 23.807 D_real: 0.625 D_fake: 0.019 \n",
            "(epoch: 47, iters: 284, time: 0.023, data: 0.001) G_GAN: 4.323 G_L1: 40.121 D_real: 0.001 D_fake: 0.727 \n",
            "End of epoch 47 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 48, iters: 88, time: 0.097, data: 0.001) G_GAN: 3.192 G_L1: 45.757 D_real: 0.000 D_fake: 0.682 \n",
            "(epoch: 48, iters: 188, time: 0.023, data: 0.001) G_GAN: 5.716 G_L1: 32.944 D_real: 0.096 D_fake: 0.005 \n",
            "(epoch: 48, iters: 288, time: 0.029, data: 0.001) G_GAN: 6.705 G_L1: 38.898 D_real: 0.016 D_fake: 0.005 \n",
            "End of epoch 48 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 49, iters: 92, time: 0.023, data: 0.001) G_GAN: 3.957 G_L1: 39.777 D_real: 0.012 D_fake: 0.178 \n",
            "(epoch: 49, iters: 192, time: 0.136, data: 0.001) G_GAN: 3.310 G_L1: 25.126 D_real: 0.060 D_fake: 0.273 \n",
            "(epoch: 49, iters: 292, time: 0.026, data: 0.001) G_GAN: 3.079 G_L1: 19.237 D_real: 0.030 D_fake: 0.054 \n",
            "End of epoch 49 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 50, iters: 96, time: 0.022, data: 0.001) G_GAN: 3.111 G_L1: 42.570 D_real: 0.054 D_fake: 0.324 \n",
            "(epoch: 50, iters: 196, time: 0.023, data: 0.001) G_GAN: 1.976 G_L1: 22.531 D_real: 0.933 D_fake: 0.098 \n",
            "(epoch: 50, iters: 296, time: 0.098, data: 0.001) G_GAN: 5.434 G_L1: 25.048 D_real: 0.009 D_fake: 0.865 \n",
            "saving the model at the end of epoch 50, iters 14800\n",
            "End of epoch 50 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 51, iters: 100, time: 0.023, data: 0.119) G_GAN: 4.589 G_L1: 32.249 D_real: 0.014 D_fake: 0.310 \n",
            "(epoch: 51, iters: 200, time: 0.023, data: 0.001) G_GAN: 3.693 G_L1: 26.899 D_real: 0.229 D_fake: 0.025 \n",
            "saving the latest model (epoch 51, total_iters 15000)\n",
            "End of epoch 51 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 52, iters: 4, time: 0.024, data: 0.002) G_GAN: 3.580 G_L1: 26.108 D_real: 0.007 D_fake: 0.316 \n",
            "(epoch: 52, iters: 104, time: 0.140, data: 0.000) G_GAN: 3.609 G_L1: 22.791 D_real: 0.011 D_fake: 0.149 \n",
            "(epoch: 52, iters: 204, time: 0.025, data: 0.002) G_GAN: 3.587 G_L1: 26.967 D_real: 0.090 D_fake: 0.091 \n",
            "End of epoch 52 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 53, iters: 8, time: 0.022, data: 0.001) G_GAN: 7.273 G_L1: 43.826 D_real: 1.718 D_fake: 0.001 \n",
            "(epoch: 53, iters: 108, time: 0.023, data: 0.000) G_GAN: 3.839 G_L1: 35.557 D_real: 0.002 D_fake: 0.149 \n",
            "(epoch: 53, iters: 208, time: 0.097, data: 0.001) G_GAN: 7.412 G_L1: 43.530 D_real: 0.037 D_fake: 0.002 \n",
            "End of epoch 53 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 54, iters: 12, time: 0.023, data: 0.001) G_GAN: 6.642 G_L1: 30.077 D_real: 0.041 D_fake: 0.007 \n",
            "(epoch: 54, iters: 112, time: 0.023, data: 0.001) G_GAN: 3.449 G_L1: 23.538 D_real: 0.020 D_fake: 0.143 \n",
            "(epoch: 54, iters: 212, time: 0.024, data: 0.001) G_GAN: 3.162 G_L1: 30.754 D_real: 0.127 D_fake: 0.165 \n",
            "End of epoch 54 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 55, iters: 16, time: 0.093, data: 0.001) G_GAN: 6.876 G_L1: 32.983 D_real: 0.116 D_fake: 0.004 \n",
            "(epoch: 55, iters: 116, time: 0.023, data: 0.001) G_GAN: 5.546 G_L1: 24.436 D_real: 0.025 D_fake: 0.036 \n",
            "(epoch: 55, iters: 216, time: 0.023, data: 0.001) G_GAN: 4.609 G_L1: 32.960 D_real: 0.017 D_fake: 0.090 \n",
            "saving the model at the end of epoch 55, iters 16280\n",
            "End of epoch 55 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 56, iters: 20, time: 0.023, data: 0.001) G_GAN: 5.347 G_L1: 18.334 D_real: 0.249 D_fake: 1.620 \n",
            "(epoch: 56, iters: 120, time: 0.103, data: 0.001) G_GAN: 4.202 G_L1: 27.408 D_real: 0.086 D_fake: 0.023 \n",
            "(epoch: 56, iters: 220, time: 0.023, data: 0.001) G_GAN: 4.388 G_L1: 27.199 D_real: 0.093 D_fake: 0.029 \n",
            "End of epoch 56 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 57, iters: 24, time: 0.023, data: 0.001) G_GAN: 3.050 G_L1: 21.773 D_real: 0.046 D_fake: 0.106 \n",
            "(epoch: 57, iters: 124, time: 0.024, data: 0.001) G_GAN: 4.801 G_L1: 44.623 D_real: 0.000 D_fake: 0.052 \n",
            "(epoch: 57, iters: 224, time: 0.142, data: 0.001) G_GAN: 6.127 G_L1: 30.972 D_real: 0.037 D_fake: 0.006 \n",
            "End of epoch 57 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 58, iters: 28, time: 0.023, data: 0.001) G_GAN: 3.380 G_L1: 24.588 D_real: 1.094 D_fake: 0.016 \n",
            "(epoch: 58, iters: 128, time: 0.025, data: 0.001) G_GAN: 4.200 G_L1: 25.825 D_real: 0.046 D_fake: 0.457 \n",
            "(epoch: 58, iters: 228, time: 0.023, data: 0.001) G_GAN: 4.346 G_L1: 33.475 D_real: 0.140 D_fake: 0.042 \n",
            "End of epoch 58 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 59, iters: 32, time: 0.111, data: 0.001) G_GAN: 4.265 G_L1: 15.263 D_real: 0.212 D_fake: 0.017 \n",
            "(epoch: 59, iters: 132, time: 0.023, data: 0.001) G_GAN: 4.234 G_L1: 21.213 D_real: 0.068 D_fake: 1.083 \n",
            "(epoch: 59, iters: 232, time: 0.023, data: 0.001) G_GAN: 4.309 G_L1: 31.274 D_real: 0.004 D_fake: 0.564 \n",
            "End of epoch 59 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 60, iters: 36, time: 0.023, data: 0.001) G_GAN: 4.936 G_L1: 28.288 D_real: 0.034 D_fake: 0.017 \n",
            "(epoch: 60, iters: 136, time: 0.166, data: 0.001) G_GAN: 1.615 G_L1: 21.088 D_real: 0.800 D_fake: 0.232 \n",
            "(epoch: 60, iters: 236, time: 0.023, data: 0.001) G_GAN: 4.078 G_L1: 35.441 D_real: 0.031 D_fake: 0.037 \n",
            "saving the model at the end of epoch 60, iters 17760\n",
            "End of epoch 60 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 61, iters: 40, time: 0.023, data: 0.001) G_GAN: 3.662 G_L1: 23.530 D_real: 0.025 D_fake: 0.201 \n",
            "(epoch: 61, iters: 140, time: 0.029, data: 0.001) G_GAN: 3.689 G_L1: 44.329 D_real: 0.000 D_fake: 0.103 \n",
            "(epoch: 61, iters: 240, time: 0.098, data: 0.001) G_GAN: 2.823 G_L1: 27.061 D_real: 0.019 D_fake: 0.144 \n",
            "End of epoch 61 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 62, iters: 44, time: 0.023, data: 0.001) G_GAN: 4.383 G_L1: 26.793 D_real: 0.041 D_fake: 0.041 \n",
            "(epoch: 62, iters: 144, time: 0.022, data: 0.001) G_GAN: 5.435 G_L1: 22.739 D_real: 0.356 D_fake: 0.008 \n",
            "(epoch: 62, iters: 244, time: 0.024, data: 0.001) G_GAN: 1.736 G_L1: 17.864 D_real: 0.821 D_fake: 0.077 \n",
            "End of epoch 62 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 63, iters: 48, time: 0.110, data: 0.001) G_GAN: 3.969 G_L1: 35.917 D_real: 0.009 D_fake: 0.045 \n",
            "(epoch: 63, iters: 148, time: 0.024, data: 0.001) G_GAN: 5.058 G_L1: 34.937 D_real: 0.007 D_fake: 0.018 \n",
            "(epoch: 63, iters: 248, time: 0.023, data: 0.001) G_GAN: 2.087 G_L1: 20.877 D_real: 1.562 D_fake: 0.012 \n",
            "End of epoch 63 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 64, iters: 52, time: 0.023, data: 0.001) G_GAN: 3.397 G_L1: 19.805 D_real: 0.033 D_fake: 0.201 \n",
            "(epoch: 64, iters: 152, time: 0.108, data: 0.001) G_GAN: 3.779 G_L1: 43.636 D_real: 0.001 D_fake: 0.136 \n",
            "(epoch: 64, iters: 252, time: 0.023, data: 0.002) G_GAN: 6.181 G_L1: 20.545 D_real: 0.134 D_fake: 0.008 \n",
            "End of epoch 64 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 65, iters: 56, time: 0.026, data: 0.001) G_GAN: 4.304 G_L1: 41.191 D_real: 0.021 D_fake: 0.038 \n",
            "(epoch: 65, iters: 156, time: 0.023, data: 0.001) G_GAN: 5.763 G_L1: 40.140 D_real: 0.008 D_fake: 0.008 \n",
            "(epoch: 65, iters: 256, time: 0.106, data: 0.001) G_GAN: 3.089 G_L1: 48.142 D_real: 0.296 D_fake: 0.215 \n",
            "saving the model at the end of epoch 65, iters 19240\n",
            "End of epoch 65 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 66, iters: 60, time: 0.023, data: 0.001) G_GAN: 2.682 G_L1: 31.433 D_real: 0.441 D_fake: 0.051 \n",
            "(epoch: 66, iters: 160, time: 0.024, data: 0.001) G_GAN: 4.563 G_L1: 25.418 D_real: 0.123 D_fake: 0.017 \n",
            "(epoch: 66, iters: 260, time: 0.029, data: 0.001) G_GAN: 6.463 G_L1: 34.374 D_real: 0.034 D_fake: 0.005 \n",
            "End of epoch 66 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 67, iters: 64, time: 0.120, data: 0.001) G_GAN: 5.235 G_L1: 25.606 D_real: 0.140 D_fake: 0.020 \n",
            "(epoch: 67, iters: 164, time: 0.025, data: 0.001) G_GAN: 4.010 G_L1: 27.904 D_real: 0.011 D_fake: 0.090 \n",
            "(epoch: 67, iters: 264, time: 0.023, data: 0.001) G_GAN: 3.935 G_L1: 18.849 D_real: 0.139 D_fake: 0.074 \n",
            "End of epoch 67 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 68, iters: 68, time: 0.023, data: 0.001) G_GAN: 6.773 G_L1: 33.873 D_real: 0.312 D_fake: 0.004 \n",
            "(epoch: 68, iters: 168, time: 0.115, data: 0.001) G_GAN: 3.824 G_L1: 26.260 D_real: 0.007 D_fake: 0.121 \n",
            "saving the latest model (epoch 68, total_iters 20000)\n",
            "(epoch: 68, iters: 268, time: 0.024, data: 0.002) G_GAN: 1.574 G_L1: 23.477 D_real: 1.786 D_fake: 0.050 \n",
            "End of epoch 68 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 69, iters: 72, time: 0.024, data: 0.001) G_GAN: 4.321 G_L1: 20.639 D_real: 0.119 D_fake: 0.664 \n",
            "(epoch: 69, iters: 172, time: 0.025, data: 0.001) G_GAN: 4.150 G_L1: 29.394 D_real: 0.036 D_fake: 0.051 \n",
            "(epoch: 69, iters: 272, time: 0.107, data: 0.001) G_GAN: 2.834 G_L1: 20.476 D_real: 0.251 D_fake: 0.265 \n",
            "End of epoch 69 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 70, iters: 76, time: 0.024, data: 0.001) G_GAN: 3.089 G_L1: 21.924 D_real: 0.024 D_fake: 0.082 \n",
            "(epoch: 70, iters: 176, time: 0.025, data: 0.001) G_GAN: 3.894 G_L1: 36.511 D_real: 0.156 D_fake: 0.218 \n",
            "(epoch: 70, iters: 276, time: 0.030, data: 0.001) G_GAN: 5.136 G_L1: 20.416 D_real: 0.149 D_fake: 0.854 \n",
            "saving the model at the end of epoch 70, iters 20720\n",
            "End of epoch 70 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 71, iters: 80, time: 0.121, data: 0.001) G_GAN: 3.500 G_L1: 24.135 D_real: 0.121 D_fake: 0.257 \n",
            "(epoch: 71, iters: 180, time: 0.023, data: 0.001) G_GAN: 5.598 G_L1: 31.539 D_real: 0.004 D_fake: 0.010 \n",
            "(epoch: 71, iters: 280, time: 0.115, data: 0.001) G_GAN: 2.524 G_L1: 23.296 D_real: 0.866 D_fake: 0.027 \n",
            "End of epoch 71 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 72, iters: 84, time: 0.026, data: 0.003) G_GAN: 2.367 G_L1: 18.655 D_real: 0.786 D_fake: 0.027 \n",
            "(epoch: 72, iters: 184, time: 0.116, data: 0.001) G_GAN: 6.400 G_L1: 27.661 D_real: 0.016 D_fake: 0.008 \n",
            "(epoch: 72, iters: 284, time: 0.025, data: 0.002) G_GAN: 4.606 G_L1: 20.758 D_real: 0.306 D_fake: 0.019 \n",
            "End of epoch 72 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 73, iters: 88, time: 0.023, data: 0.001) G_GAN: 7.100 G_L1: 36.382 D_real: 0.013 D_fake: 0.003 \n",
            "(epoch: 73, iters: 188, time: 0.024, data: 0.001) G_GAN: 4.098 G_L1: 29.407 D_real: 0.005 D_fake: 0.053 \n",
            "(epoch: 73, iters: 288, time: 0.125, data: 0.001) G_GAN: 4.906 G_L1: 22.865 D_real: 0.009 D_fake: 0.703 \n",
            "End of epoch 73 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 74, iters: 92, time: 0.027, data: 0.001) G_GAN: 3.136 G_L1: 17.268 D_real: 0.289 D_fake: 0.040 \n",
            "(epoch: 74, iters: 192, time: 0.023, data: 0.001) G_GAN: 3.333 G_L1: 35.086 D_real: 0.721 D_fake: 0.017 \n",
            "(epoch: 74, iters: 292, time: 0.021, data: 0.001) G_GAN: 4.813 G_L1: 30.372 D_real: 0.029 D_fake: 0.017 \n",
            "End of epoch 74 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 75, iters: 96, time: 0.208, data: 0.001) G_GAN: 4.323 G_L1: 29.416 D_real: 0.007 D_fake: 0.335 \n",
            "(epoch: 75, iters: 196, time: 0.025, data: 0.001) G_GAN: 3.617 G_L1: 23.953 D_real: 0.359 D_fake: 0.042 \n",
            "(epoch: 75, iters: 296, time: 0.021, data: 0.001) G_GAN: 2.423 G_L1: 20.249 D_real: 0.321 D_fake: 0.134 \n",
            "saving the model at the end of epoch 75, iters 22200\n",
            "End of epoch 75 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 76, iters: 100, time: 0.024, data: 0.124) G_GAN: 2.873 G_L1: 30.998 D_real: 0.004 D_fake: 0.056 \n",
            "(epoch: 76, iters: 200, time: 0.383, data: 0.001) G_GAN: 3.978 G_L1: 41.426 D_real: 0.000 D_fake: 0.122 \n",
            "End of epoch 76 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 77, iters: 4, time: 0.024, data: 0.001) G_GAN: 5.349 G_L1: 42.179 D_real: 0.019 D_fake: 0.611 \n",
            "(epoch: 77, iters: 104, time: 0.023, data: 0.000) G_GAN: 4.933 G_L1: 40.841 D_real: 0.003 D_fake: 0.022 \n",
            "(epoch: 77, iters: 204, time: 0.023, data: 0.001) G_GAN: 3.649 G_L1: 24.052 D_real: 0.168 D_fake: 0.037 \n",
            "End of epoch 77 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 78, iters: 8, time: 0.240, data: 0.001) G_GAN: 5.310 G_L1: 22.700 D_real: 0.007 D_fake: 0.538 \n",
            "(epoch: 78, iters: 108, time: 0.024, data: 0.000) G_GAN: 4.064 G_L1: 30.870 D_real: 0.420 D_fake: 0.004 \n",
            "(epoch: 78, iters: 208, time: 0.024, data: 0.001) G_GAN: 4.708 G_L1: 33.072 D_real: 0.043 D_fake: 0.015 \n",
            "End of epoch 78 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 79, iters: 12, time: 0.023, data: 0.001) G_GAN: 4.462 G_L1: 27.741 D_real: 0.001 D_fake: 0.042 \n",
            "(epoch: 79, iters: 112, time: 0.122, data: 0.001) G_GAN: 5.298 G_L1: 31.831 D_real: 0.001 D_fake: 0.040 \n",
            "(epoch: 79, iters: 212, time: 0.023, data: 0.001) G_GAN: 5.168 G_L1: 29.662 D_real: 0.164 D_fake: 0.014 \n",
            "End of epoch 79 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 80, iters: 16, time: 0.032, data: 0.001) G_GAN: 5.049 G_L1: 17.598 D_real: 0.060 D_fake: 0.836 \n",
            "(epoch: 80, iters: 116, time: 0.025, data: 0.001) G_GAN: 3.838 G_L1: 22.847 D_real: 0.865 D_fake: 0.030 \n",
            "(epoch: 80, iters: 216, time: 0.115, data: 0.001) G_GAN: 3.710 G_L1: 44.504 D_real: 0.004 D_fake: 0.107 \n",
            "saving the model at the end of epoch 80, iters 23680\n",
            "End of epoch 80 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 81, iters: 20, time: 0.023, data: 0.001) G_GAN: 3.416 G_L1: 19.234 D_real: 0.063 D_fake: 0.034 \n",
            "(epoch: 81, iters: 120, time: 0.023, data: 0.001) G_GAN: 6.776 G_L1: 27.821 D_real: 0.010 D_fake: 0.004 \n",
            "(epoch: 81, iters: 220, time: 0.023, data: 0.001) G_GAN: 5.284 G_L1: 24.795 D_real: 0.003 D_fake: 1.105 \n",
            "End of epoch 81 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 82, iters: 24, time: 0.143, data: 0.001) G_GAN: 2.422 G_L1: 21.226 D_real: 0.728 D_fake: 0.077 \n",
            "(epoch: 82, iters: 124, time: 0.029, data: 0.002) G_GAN: 4.369 G_L1: 32.740 D_real: 0.141 D_fake: 0.088 \n",
            "(epoch: 82, iters: 224, time: 0.023, data: 0.001) G_GAN: 3.732 G_L1: 22.926 D_real: 0.050 D_fake: 0.201 \n",
            "End of epoch 82 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 83, iters: 28, time: 0.023, data: 0.001) G_GAN: 3.640 G_L1: 38.124 D_real: 0.199 D_fake: 0.036 \n",
            "(epoch: 83, iters: 128, time: 0.129, data: 0.001) G_GAN: 3.280 G_L1: 40.985 D_real: 0.113 D_fake: 0.063 \n",
            "(epoch: 83, iters: 228, time: 0.024, data: 0.001) G_GAN: 5.255 G_L1: 18.059 D_real: 0.016 D_fake: 1.975 \n",
            "End of epoch 83 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 84, iters: 32, time: 0.023, data: 0.001) G_GAN: 4.181 G_L1: 21.924 D_real: 0.016 D_fake: 0.418 \n",
            "(epoch: 84, iters: 132, time: 0.027, data: 0.001) G_GAN: 3.644 G_L1: 29.205 D_real: 0.007 D_fake: 0.250 \n",
            "(epoch: 84, iters: 232, time: 0.119, data: 0.001) G_GAN: 3.997 G_L1: 24.617 D_real: 0.140 D_fake: 0.051 \n",
            "End of epoch 84 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 85, iters: 36, time: 0.024, data: 0.001) G_GAN: 7.881 G_L1: 30.790 D_real: 0.076 D_fake: 0.002 \n",
            "(epoch: 85, iters: 136, time: 0.023, data: 0.001) G_GAN: 4.322 G_L1: 38.094 D_real: 0.077 D_fake: 0.021 \n",
            "saving the latest model (epoch 85, total_iters 25000)\n",
            "(epoch: 85, iters: 236, time: 0.024, data: 0.005) G_GAN: 4.051 G_L1: 26.590 D_real: 0.002 D_fake: 0.214 \n",
            "saving the model at the end of epoch 85, iters 25160\n",
            "End of epoch 85 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 86, iters: 40, time: 0.235, data: 0.001) G_GAN: 7.710 G_L1: 25.170 D_real: 0.147 D_fake: 0.001 \n",
            "(epoch: 86, iters: 140, time: 0.023, data: 0.002) G_GAN: 3.775 G_L1: 33.920 D_real: 0.001 D_fake: 0.300 \n",
            "(epoch: 86, iters: 240, time: 0.057, data: 0.001) G_GAN: 3.186 G_L1: 50.682 D_real: 0.250 D_fake: 0.245 \n",
            "End of epoch 86 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 87, iters: 44, time: 0.024, data: 0.009) G_GAN: 2.528 G_L1: 21.854 D_real: 0.730 D_fake: 0.013 \n",
            "(epoch: 87, iters: 144, time: 0.182, data: 0.001) G_GAN: 4.059 G_L1: 17.639 D_real: 0.109 D_fake: 0.041 \n",
            "(epoch: 87, iters: 244, time: 0.023, data: 0.001) G_GAN: 4.690 G_L1: 24.576 D_real: 0.029 D_fake: 0.625 \n",
            "End of epoch 87 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 88, iters: 48, time: 0.023, data: 0.001) G_GAN: 4.604 G_L1: 27.091 D_real: 0.433 D_fake: 0.005 \n",
            "(epoch: 88, iters: 148, time: 0.023, data: 0.001) G_GAN: 8.488 G_L1: 37.533 D_real: 0.435 D_fake: 0.000 \n",
            "(epoch: 88, iters: 248, time: 0.123, data: 0.001) G_GAN: 5.558 G_L1: 23.687 D_real: 0.115 D_fake: 0.211 \n",
            "End of epoch 88 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 89, iters: 52, time: 0.029, data: 0.001) G_GAN: 6.222 G_L1: 26.082 D_real: 0.006 D_fake: 0.005 \n",
            "(epoch: 89, iters: 152, time: 0.023, data: 0.001) G_GAN: 3.809 G_L1: 37.113 D_real: 0.033 D_fake: 0.177 \n",
            "(epoch: 89, iters: 252, time: 0.023, data: 0.001) G_GAN: 7.498 G_L1: 27.490 D_real: 0.010 D_fake: 0.004 \n",
            "End of epoch 89 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 90, iters: 56, time: 0.126, data: 0.002) G_GAN: 3.960 G_L1: 26.359 D_real: 0.000 D_fake: 0.207 \n",
            "(epoch: 90, iters: 156, time: 0.023, data: 0.001) G_GAN: 5.752 G_L1: 31.223 D_real: 0.153 D_fake: 0.017 \n",
            "(epoch: 90, iters: 256, time: 0.024, data: 0.001) G_GAN: 8.916 G_L1: 32.880 D_real: 0.006 D_fake: 0.003 \n",
            "saving the model at the end of epoch 90, iters 26640\n",
            "End of epoch 90 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 91, iters: 60, time: 0.024, data: 0.001) G_GAN: 6.550 G_L1: 25.092 D_real: 0.025 D_fake: 0.006 \n",
            "(epoch: 91, iters: 160, time: 0.131, data: 0.001) G_GAN: 5.358 G_L1: 30.475 D_real: 0.145 D_fake: 0.011 \n",
            "(epoch: 91, iters: 260, time: 0.023, data: 0.001) G_GAN: 5.187 G_L1: 27.118 D_real: 0.001 D_fake: 0.022 \n",
            "End of epoch 91 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 92, iters: 64, time: 0.033, data: 0.001) G_GAN: 5.287 G_L1: 24.387 D_real: 0.001 D_fake: 0.041 \n",
            "(epoch: 92, iters: 164, time: 0.029, data: 0.002) G_GAN: 6.583 G_L1: 25.973 D_real: 0.005 D_fake: 0.525 \n",
            "(epoch: 92, iters: 264, time: 0.133, data: 0.001) G_GAN: 5.556 G_L1: 28.131 D_real: 0.008 D_fake: 0.006 \n",
            "End of epoch 92 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 93, iters: 68, time: 0.024, data: 0.001) G_GAN: 4.968 G_L1: 16.004 D_real: 0.004 D_fake: 1.245 \n",
            "(epoch: 93, iters: 168, time: 0.025, data: 0.001) G_GAN: 3.947 G_L1: 36.882 D_real: 0.003 D_fake: 0.047 \n",
            "(epoch: 93, iters: 268, time: 0.033, data: 0.001) G_GAN: 5.645 G_L1: 34.494 D_real: 0.001 D_fake: 0.029 \n",
            "End of epoch 93 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 94, iters: 72, time: 0.135, data: 0.003) G_GAN: 5.515 G_L1: 31.289 D_real: 0.048 D_fake: 0.007 \n",
            "(epoch: 94, iters: 172, time: 0.024, data: 0.001) G_GAN: 5.258 G_L1: 15.996 D_real: 0.015 D_fake: 1.099 \n",
            "(epoch: 94, iters: 272, time: 0.027, data: 0.001) G_GAN: 4.428 G_L1: 49.333 D_real: 0.007 D_fake: 0.142 \n",
            "End of epoch 94 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 95, iters: 76, time: 0.023, data: 0.001) G_GAN: 3.464 G_L1: 28.418 D_real: 0.250 D_fake: 0.047 \n",
            "(epoch: 95, iters: 176, time: 0.205, data: 0.005) G_GAN: 5.629 G_L1: 17.875 D_real: 0.010 D_fake: 1.131 \n",
            "(epoch: 95, iters: 276, time: 0.025, data: 0.001) G_GAN: 6.930 G_L1: 37.300 D_real: 0.008 D_fake: 0.003 \n",
            "saving the model at the end of epoch 95, iters 28120\n",
            "End of epoch 95 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 96, iters: 80, time: 0.038, data: 0.001) G_GAN: 5.347 G_L1: 31.275 D_real: 0.002 D_fake: 0.027 \n",
            "(epoch: 96, iters: 180, time: 0.029, data: 0.002) G_GAN: 8.064 G_L1: 26.339 D_real: 0.077 D_fake: 0.001 \n",
            "(epoch: 96, iters: 280, time: 0.130, data: 0.002) G_GAN: 3.747 G_L1: 39.924 D_real: 0.020 D_fake: 0.046 \n",
            "End of epoch 96 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 97, iters: 84, time: 0.024, data: 0.002) G_GAN: 3.724 G_L1: 28.357 D_real: 0.010 D_fake: 0.247 \n",
            "(epoch: 97, iters: 184, time: 0.026, data: 0.001) G_GAN: 6.708 G_L1: 31.498 D_real: 0.003 D_fake: 0.006 \n",
            "(epoch: 97, iters: 284, time: 0.023, data: 0.002) G_GAN: 7.946 G_L1: 20.992 D_real: 0.017 D_fake: 1.532 \n",
            "End of epoch 97 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 98, iters: 88, time: 0.320, data: 0.001) G_GAN: 6.392 G_L1: 17.504 D_real: 0.021 D_fake: 2.142 \n",
            "(epoch: 98, iters: 188, time: 0.029, data: 0.001) G_GAN: 7.346 G_L1: 30.570 D_real: 0.001 D_fake: 0.005 \n",
            "(epoch: 98, iters: 288, time: 0.023, data: 0.001) G_GAN: 4.772 G_L1: 20.077 D_real: 0.019 D_fake: 0.017 \n",
            "End of epoch 98 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 99, iters: 92, time: 0.023, data: 0.001) G_GAN: 7.369 G_L1: 26.469 D_real: 0.463 D_fake: 0.000 \n",
            "(epoch: 99, iters: 192, time: 0.128, data: 0.001) G_GAN: 6.202 G_L1: 24.049 D_real: 0.374 D_fake: 0.001 \n",
            "(epoch: 99, iters: 292, time: 0.022, data: 0.001) G_GAN: 7.027 G_L1: 34.598 D_real: 0.059 D_fake: 0.003 \n",
            "End of epoch 99 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 100, iters: 96, time: 0.023, data: 0.001) G_GAN: 7.077 G_L1: 21.407 D_real: 0.130 D_fake: 0.001 \n",
            "(epoch: 100, iters: 196, time: 0.029, data: 0.001) G_GAN: 6.338 G_L1: 25.014 D_real: 1.931 D_fake: 0.001 \n",
            "(epoch: 100, iters: 296, time: 0.140, data: 0.001) G_GAN: 2.905 G_L1: 16.918 D_real: 0.278 D_fake: 0.053 \n",
            "saving the model at the end of epoch 100, iters 29600\n",
            "End of epoch 100 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 101, iters: 100, time: 0.023, data: 0.120) G_GAN: 2.651 G_L1: 22.467 D_real: 0.394 D_fake: 0.436 \n",
            "(epoch: 101, iters: 200, time: 0.023, data: 0.001) G_GAN: 6.484 G_L1: 27.251 D_real: 0.013 D_fake: 0.004 \n",
            "End of epoch 101 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 102, iters: 4, time: 0.027, data: 0.001) G_GAN: 8.689 G_L1: 27.624 D_real: 0.279 D_fake: 0.000 \n",
            "(epoch: 102, iters: 104, time: 0.132, data: 0.000) G_GAN: 10.882 G_L1: 26.751 D_real: 0.005 D_fake: 0.000 \n",
            "saving the latest model (epoch 102, total_iters 30000)\n",
            "(epoch: 102, iters: 204, time: 0.024, data: 0.001) G_GAN: 5.849 G_L1: 22.878 D_real: 0.028 D_fake: 0.007 \n",
            "End of epoch 102 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 103, iters: 8, time: 0.023, data: 0.001) G_GAN: 6.433 G_L1: 28.521 D_real: 0.016 D_fake: 0.049 \n",
            "(epoch: 103, iters: 108, time: 0.023, data: 0.001) G_GAN: 4.826 G_L1: 35.451 D_real: 0.037 D_fake: 0.051 \n",
            "(epoch: 103, iters: 208, time: 0.173, data: 0.001) G_GAN: 4.192 G_L1: 16.130 D_real: 0.104 D_fake: 0.250 \n",
            "End of epoch 103 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 104, iters: 12, time: 0.023, data: 0.001) G_GAN: 5.199 G_L1: 21.267 D_real: 0.020 D_fake: 0.612 \n",
            "(epoch: 104, iters: 112, time: 0.022, data: 0.001) G_GAN: 6.573 G_L1: 35.258 D_real: 0.124 D_fake: 0.002 \n",
            "(epoch: 104, iters: 212, time: 0.023, data: 0.001) G_GAN: 4.204 G_L1: 15.330 D_real: 0.514 D_fake: 0.025 \n",
            "End of epoch 104 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 105, iters: 16, time: 0.136, data: 0.001) G_GAN: 3.980 G_L1: 25.250 D_real: 0.001 D_fake: 0.050 \n",
            "(epoch: 105, iters: 116, time: 0.024, data: 0.001) G_GAN: 2.616 G_L1: 22.146 D_real: 0.488 D_fake: 0.275 \n",
            "(epoch: 105, iters: 216, time: 0.026, data: 0.001) G_GAN: 5.502 G_L1: 25.996 D_real: 0.021 D_fake: 0.011 \n",
            "saving the model at the end of epoch 105, iters 31080\n",
            "End of epoch 105 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 106, iters: 20, time: 0.030, data: 0.001) G_GAN: 3.340 G_L1: 21.400 D_real: 0.357 D_fake: 0.101 \n",
            "(epoch: 106, iters: 120, time: 0.164, data: 0.001) G_GAN: 4.718 G_L1: 31.883 D_real: 0.001 D_fake: 0.024 \n",
            "(epoch: 106, iters: 220, time: 0.024, data: 0.001) G_GAN: 8.843 G_L1: 19.657 D_real: 0.176 D_fake: 0.001 \n",
            "End of epoch 106 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 107, iters: 24, time: 0.025, data: 0.001) G_GAN: 4.035 G_L1: 18.154 D_real: 0.015 D_fake: 0.511 \n",
            "(epoch: 107, iters: 124, time: 0.024, data: 0.001) G_GAN: 6.519 G_L1: 18.688 D_real: 0.002 D_fake: 2.032 \n",
            "(epoch: 107, iters: 224, time: 0.192, data: 0.001) G_GAN: 2.834 G_L1: 21.977 D_real: 0.475 D_fake: 0.036 \n",
            "End of epoch 107 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 108, iters: 28, time: 0.023, data: 0.001) G_GAN: 3.595 G_L1: 29.893 D_real: 0.006 D_fake: 0.240 \n",
            "(epoch: 108, iters: 128, time: 0.023, data: 0.001) G_GAN: 3.509 G_L1: 21.669 D_real: 0.040 D_fake: 0.287 \n",
            "(epoch: 108, iters: 228, time: 0.024, data: 0.001) G_GAN: 4.668 G_L1: 20.274 D_real: 0.006 D_fake: 0.595 \n",
            "End of epoch 108 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 109, iters: 32, time: 0.137, data: 0.001) G_GAN: 4.480 G_L1: 26.751 D_real: 0.034 D_fake: 0.215 \n",
            "(epoch: 109, iters: 132, time: 0.028, data: 0.001) G_GAN: 3.980 G_L1: 41.931 D_real: 0.000 D_fake: 0.133 \n",
            "(epoch: 109, iters: 232, time: 0.023, data: 0.002) G_GAN: 3.667 G_L1: 29.342 D_real: 0.037 D_fake: 0.148 \n",
            "End of epoch 109 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 110, iters: 36, time: 0.023, data: 0.001) G_GAN: 4.058 G_L1: 22.925 D_real: 0.058 D_fake: 0.031 \n",
            "(epoch: 110, iters: 136, time: 0.186, data: 0.001) G_GAN: 2.292 G_L1: 19.545 D_real: 0.841 D_fake: 0.269 \n",
            "(epoch: 110, iters: 236, time: 0.025, data: 0.002) G_GAN: 5.378 G_L1: 21.178 D_real: 0.020 D_fake: 0.064 \n",
            "saving the model at the end of epoch 110, iters 32560\n",
            "End of epoch 110 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 111, iters: 40, time: 0.026, data: 0.001) G_GAN: 6.216 G_L1: 40.980 D_real: 0.185 D_fake: 0.011 \n",
            "(epoch: 111, iters: 140, time: 0.023, data: 0.001) G_GAN: 7.406 G_L1: 27.540 D_real: 0.010 D_fake: 0.002 \n",
            "(epoch: 111, iters: 240, time: 0.141, data: 0.001) G_GAN: 3.260 G_L1: 18.106 D_real: 0.035 D_fake: 0.256 \n",
            "End of epoch 111 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 112, iters: 44, time: 0.028, data: 0.001) G_GAN: 8.724 G_L1: 40.980 D_real: 0.004 D_fake: 0.001 \n",
            "(epoch: 112, iters: 144, time: 0.025, data: 0.001) G_GAN: 6.176 G_L1: 32.767 D_real: 0.166 D_fake: 0.001 \n",
            "(epoch: 112, iters: 244, time: 0.022, data: 0.001) G_GAN: 5.320 G_L1: 28.213 D_real: 0.002 D_fake: 0.035 \n",
            "End of epoch 112 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 113, iters: 48, time: 0.150, data: 0.001) G_GAN: 4.918 G_L1: 18.258 D_real: 0.007 D_fake: 0.481 \n",
            "(epoch: 113, iters: 148, time: 0.028, data: 0.001) G_GAN: 4.829 G_L1: 22.792 D_real: 0.411 D_fake: 0.005 \n",
            "(epoch: 113, iters: 248, time: 0.026, data: 0.001) G_GAN: 5.244 G_L1: 32.256 D_real: 0.006 D_fake: 0.056 \n",
            "End of epoch 113 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 114, iters: 52, time: 0.023, data: 0.001) G_GAN: 5.941 G_L1: 35.577 D_real: 0.000 D_fake: 0.010 \n",
            "(epoch: 114, iters: 152, time: 0.140, data: 0.001) G_GAN: 2.824 G_L1: 18.257 D_real: 0.806 D_fake: 0.064 \n",
            "(epoch: 114, iters: 252, time: 0.024, data: 0.001) G_GAN: 4.678 G_L1: 22.659 D_real: 0.073 D_fake: 0.077 \n",
            "End of epoch 114 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 115, iters: 56, time: 0.023, data: 0.001) G_GAN: 5.508 G_L1: 21.192 D_real: 0.002 D_fake: 0.267 \n",
            "(epoch: 115, iters: 156, time: 0.023, data: 0.001) G_GAN: 3.912 G_L1: 16.661 D_real: 0.019 D_fake: 0.062 \n",
            "(epoch: 115, iters: 256, time: 0.163, data: 0.001) G_GAN: 4.776 G_L1: 24.970 D_real: 0.002 D_fake: 0.077 \n",
            "saving the model at the end of epoch 115, iters 34040\n",
            "End of epoch 115 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 116, iters: 60, time: 0.022, data: 0.001) G_GAN: 1.999 G_L1: 19.096 D_real: 1.274 D_fake: 0.049 \n",
            "(epoch: 116, iters: 160, time: 0.030, data: 0.001) G_GAN: 3.283 G_L1: 49.771 D_real: 0.005 D_fake: 0.139 \n",
            "(epoch: 116, iters: 260, time: 0.024, data: 0.001) G_GAN: 2.751 G_L1: 23.434 D_real: 1.111 D_fake: 0.008 \n",
            "End of epoch 116 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 117, iters: 64, time: 0.217, data: 0.001) G_GAN: 3.756 G_L1: 19.387 D_real: 0.233 D_fake: 0.019 \n",
            "(epoch: 117, iters: 164, time: 0.029, data: 0.001) G_GAN: 9.195 G_L1: 29.969 D_real: 0.025 D_fake: 0.002 \n",
            "(epoch: 117, iters: 264, time: 0.024, data: 0.001) G_GAN: 8.268 G_L1: 27.131 D_real: 0.028 D_fake: 0.001 \n",
            "End of epoch 117 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 118, iters: 68, time: 0.023, data: 0.001) G_GAN: 3.757 G_L1: 41.246 D_real: 0.006 D_fake: 0.269 \n",
            "(epoch: 118, iters: 168, time: 0.168, data: 0.001) G_GAN: 4.961 G_L1: 30.422 D_real: 0.007 D_fake: 0.430 \n",
            "(epoch: 118, iters: 268, time: 0.022, data: 0.001) G_GAN: 7.249 G_L1: 22.110 D_real: 0.090 D_fake: 0.003 \n",
            "End of epoch 118 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 119, iters: 72, time: 0.024, data: 0.001) G_GAN: 1.583 G_L1: 27.341 D_real: 1.002 D_fake: 0.132 \n",
            "saving the latest model (epoch 119, total_iters 35000)\n",
            "(epoch: 119, iters: 172, time: 0.023, data: 0.001) G_GAN: 3.697 G_L1: 18.752 D_real: 0.293 D_fake: 0.211 \n",
            "(epoch: 119, iters: 272, time: 0.170, data: 0.001) G_GAN: 3.323 G_L1: 19.453 D_real: 0.182 D_fake: 0.255 \n",
            "End of epoch 119 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 120, iters: 76, time: 0.024, data: 0.001) G_GAN: 6.115 G_L1: 35.277 D_real: 0.007 D_fake: 0.021 \n",
            "(epoch: 120, iters: 176, time: 0.023, data: 0.001) G_GAN: 4.161 G_L1: 41.345 D_real: 0.140 D_fake: 0.102 \n",
            "(epoch: 120, iters: 276, time: 0.028, data: 0.001) G_GAN: 5.251 G_L1: 45.953 D_real: 0.091 D_fake: 0.006 \n",
            "saving the model at the end of epoch 120, iters 35520\n",
            "End of epoch 120 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 121, iters: 80, time: 0.187, data: 0.001) G_GAN: 5.383 G_L1: 28.292 D_real: 0.002 D_fake: 0.153 \n",
            "(epoch: 121, iters: 180, time: 0.023, data: 0.001) G_GAN: 7.423 G_L1: 23.006 D_real: 0.026 D_fake: 0.002 \n",
            "(epoch: 121, iters: 280, time: 0.040, data: 0.001) G_GAN: 6.905 G_L1: 31.510 D_real: 0.044 D_fake: 0.018 \n",
            "End of epoch 121 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 122, iters: 84, time: 0.029, data: 0.001) G_GAN: 2.910 G_L1: 18.566 D_real: 1.947 D_fake: 0.000 \n",
            "(epoch: 122, iters: 184, time: 0.152, data: 0.001) G_GAN: 6.593 G_L1: 22.764 D_real: 0.597 D_fake: 0.001 \n",
            "(epoch: 122, iters: 284, time: 0.024, data: 0.001) G_GAN: 6.881 G_L1: 27.431 D_real: 0.055 D_fake: 1.170 \n",
            "End of epoch 122 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 123, iters: 88, time: 0.025, data: 0.001) G_GAN: 2.816 G_L1: 18.252 D_real: 0.152 D_fake: 0.055 \n",
            "(epoch: 123, iters: 188, time: 0.024, data: 0.001) G_GAN: 3.887 G_L1: 23.107 D_real: 0.057 D_fake: 0.137 \n",
            "(epoch: 123, iters: 288, time: 0.152, data: 0.001) G_GAN: 3.803 G_L1: 24.203 D_real: 0.006 D_fake: 0.072 \n",
            "End of epoch 123 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 124, iters: 92, time: 0.034, data: 0.001) G_GAN: 7.642 G_L1: 26.777 D_real: 0.005 D_fake: 0.002 \n",
            "(epoch: 124, iters: 192, time: 0.027, data: 0.001) G_GAN: 4.867 G_L1: 21.488 D_real: 0.218 D_fake: 0.011 \n",
            "(epoch: 124, iters: 292, time: 0.022, data: 0.001) G_GAN: 7.274 G_L1: 27.311 D_real: 0.004 D_fake: 0.003 \n",
            "End of epoch 124 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 125, iters: 96, time: 0.223, data: 0.001) G_GAN: 8.543 G_L1: 30.230 D_real: 0.107 D_fake: 0.001 \n",
            "(epoch: 125, iters: 196, time: 0.029, data: 0.001) G_GAN: 3.748 G_L1: 20.373 D_real: 0.062 D_fake: 0.131 \n",
            "(epoch: 125, iters: 296, time: 0.028, data: 0.002) G_GAN: 3.349 G_L1: 13.740 D_real: 0.133 D_fake: 0.075 \n",
            "saving the model at the end of epoch 125, iters 37000\n",
            "End of epoch 125 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 126, iters: 100, time: 0.027, data: 0.117) G_GAN: 5.806 G_L1: 23.411 D_real: 0.005 D_fake: 0.023 \n",
            "(epoch: 126, iters: 200, time: 0.158, data: 0.001) G_GAN: 7.724 G_L1: 26.458 D_real: 0.041 D_fake: 0.003 \n",
            "End of epoch 126 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 127, iters: 4, time: 0.027, data: 0.004) G_GAN: 4.685 G_L1: 26.704 D_real: 0.011 D_fake: 0.180 \n",
            "(epoch: 127, iters: 104, time: 0.022, data: 0.000) G_GAN: 8.721 G_L1: 37.793 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 127, iters: 204, time: 0.024, data: 0.001) G_GAN: 6.765 G_L1: 20.123 D_real: 0.030 D_fake: 1.308 \n",
            "End of epoch 127 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 128, iters: 8, time: 0.156, data: 0.001) G_GAN: 4.202 G_L1: 19.374 D_real: 0.101 D_fake: 0.073 \n",
            "(epoch: 128, iters: 108, time: 0.028, data: 0.000) G_GAN: 6.117 G_L1: 22.747 D_real: 0.011 D_fake: 0.010 \n",
            "(epoch: 128, iters: 208, time: 0.024, data: 0.001) G_GAN: 5.455 G_L1: 22.927 D_real: 0.007 D_fake: 0.560 \n",
            "End of epoch 128 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 129, iters: 12, time: 0.023, data: 0.001) G_GAN: 3.960 G_L1: 17.225 D_real: 0.017 D_fake: 0.221 \n",
            "(epoch: 129, iters: 112, time: 0.152, data: 0.001) G_GAN: 3.950 G_L1: 18.113 D_real: 0.367 D_fake: 0.019 \n",
            "(epoch: 129, iters: 212, time: 0.023, data: 0.001) G_GAN: 3.394 G_L1: 17.411 D_real: 0.040 D_fake: 0.069 \n",
            "End of epoch 129 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 130, iters: 16, time: 0.030, data: 0.001) G_GAN: 5.116 G_L1: 15.948 D_real: 0.040 D_fake: 0.508 \n",
            "(epoch: 130, iters: 116, time: 0.023, data: 0.001) G_GAN: 6.636 G_L1: 15.755 D_real: 0.017 D_fake: 1.122 \n",
            "(epoch: 130, iters: 216, time: 0.295, data: 0.001) G_GAN: 4.485 G_L1: 27.251 D_real: 0.019 D_fake: 0.052 \n",
            "saving the model at the end of epoch 130, iters 38480\n",
            "End of epoch 130 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 131, iters: 20, time: 0.026, data: 0.001) G_GAN: 5.323 G_L1: 27.662 D_real: 0.054 D_fake: 0.816 \n",
            "(epoch: 131, iters: 120, time: 0.023, data: 0.001) G_GAN: 6.893 G_L1: 26.717 D_real: 0.027 D_fake: 0.009 \n",
            "(epoch: 131, iters: 220, time: 0.047, data: 0.001) G_GAN: 4.061 G_L1: 29.843 D_real: 0.033 D_fake: 0.052 \n",
            "End of epoch 131 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 132, iters: 24, time: 0.157, data: 0.002) G_GAN: 3.710 G_L1: 16.162 D_real: 0.071 D_fake: 0.101 \n",
            "(epoch: 132, iters: 124, time: 0.025, data: 0.001) G_GAN: 5.651 G_L1: 20.542 D_real: 0.051 D_fake: 0.036 \n",
            "(epoch: 132, iters: 224, time: 0.024, data: 0.002) G_GAN: 5.395 G_L1: 28.232 D_real: 0.236 D_fake: 0.013 \n",
            "End of epoch 132 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 133, iters: 28, time: 0.023, data: 0.001) G_GAN: 3.940 G_L1: 19.181 D_real: 0.040 D_fake: 0.142 \n",
            "(epoch: 133, iters: 128, time: 0.220, data: 0.001) G_GAN: 4.013 G_L1: 27.735 D_real: 0.043 D_fake: 0.040 \n",
            "(epoch: 133, iters: 228, time: 0.024, data: 0.001) G_GAN: 6.137 G_L1: 27.236 D_real: 0.030 D_fake: 0.027 \n",
            "End of epoch 133 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 134, iters: 32, time: 0.023, data: 0.001) G_GAN: 7.175 G_L1: 28.680 D_real: 0.001 D_fake: 0.006 \n",
            "(epoch: 134, iters: 132, time: 0.024, data: 0.001) G_GAN: 3.449 G_L1: 16.010 D_real: 0.146 D_fake: 0.223 \n",
            "(epoch: 134, iters: 232, time: 0.160, data: 0.001) G_GAN: 5.069 G_L1: 18.244 D_real: 0.511 D_fake: 0.004 \n",
            "End of epoch 134 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 135, iters: 36, time: 0.023, data: 0.001) G_GAN: 4.425 G_L1: 25.141 D_real: 0.037 D_fake: 0.035 \n",
            "(epoch: 135, iters: 136, time: 0.023, data: 0.001) G_GAN: 3.566 G_L1: 22.180 D_real: 0.190 D_fake: 0.056 \n",
            "(epoch: 135, iters: 236, time: 0.032, data: 0.001) G_GAN: 5.846 G_L1: 36.409 D_real: 0.017 D_fake: 0.007 \n",
            "saving the model at the end of epoch 135, iters 39960\n",
            "End of epoch 135 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 136, iters: 40, time: 0.166, data: 0.001) G_GAN: 2.377 G_L1: 24.541 D_real: 0.890 D_fake: 0.078 \n",
            "saving the latest model (epoch 136, total_iters 40000)\n",
            "(epoch: 136, iters: 140, time: 0.024, data: 0.001) G_GAN: 4.897 G_L1: 21.118 D_real: 0.154 D_fake: 0.010 \n",
            "(epoch: 136, iters: 240, time: 0.024, data: 0.001) G_GAN: 5.042 G_L1: 21.503 D_real: 0.001 D_fake: 0.079 \n",
            "End of epoch 136 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 137, iters: 44, time: 0.023, data: 0.001) G_GAN: 3.644 G_L1: 29.581 D_real: 0.041 D_fake: 0.066 \n",
            "(epoch: 137, iters: 144, time: 0.166, data: 0.001) G_GAN: 9.479 G_L1: 23.649 D_real: 0.183 D_fake: 0.000 \n",
            "(epoch: 137, iters: 244, time: 0.036, data: 0.001) G_GAN: 4.663 G_L1: 16.950 D_real: 0.046 D_fake: 0.727 \n",
            "End of epoch 137 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 138, iters: 48, time: 0.024, data: 0.001) G_GAN: 2.435 G_L1: 23.000 D_real: 1.185 D_fake: 0.012 \n",
            "(epoch: 138, iters: 148, time: 0.023, data: 0.001) G_GAN: 5.959 G_L1: 40.993 D_real: 0.002 D_fake: 0.007 \n",
            "(epoch: 138, iters: 248, time: 0.159, data: 0.001) G_GAN: 3.754 G_L1: 29.543 D_real: 0.013 D_fake: 0.112 \n",
            "End of epoch 138 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 139, iters: 52, time: 0.029, data: 0.001) G_GAN: 4.935 G_L1: 27.185 D_real: 0.001 D_fake: 0.031 \n",
            "(epoch: 139, iters: 152, time: 0.023, data: 0.001) G_GAN: 7.162 G_L1: 22.781 D_real: 0.134 D_fake: 0.002 \n",
            "(epoch: 139, iters: 252, time: 0.023, data: 0.001) G_GAN: 6.937 G_L1: 21.170 D_real: 0.086 D_fake: 0.003 \n",
            "End of epoch 139 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 140, iters: 56, time: 0.222, data: 0.001) G_GAN: 4.832 G_L1: 16.786 D_real: 0.010 D_fake: 0.502 \n",
            "(epoch: 140, iters: 156, time: 0.023, data: 0.001) G_GAN: 4.279 G_L1: 26.150 D_real: 0.001 D_fake: 0.142 \n",
            "(epoch: 140, iters: 256, time: 0.026, data: 0.001) G_GAN: 4.536 G_L1: 23.875 D_real: 0.020 D_fake: 0.017 \n",
            "saving the model at the end of epoch 140, iters 41440\n",
            "End of epoch 140 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 141, iters: 60, time: 0.024, data: 0.001) G_GAN: 5.269 G_L1: 29.759 D_real: 0.022 D_fake: 0.026 \n",
            "(epoch: 141, iters: 160, time: 0.170, data: 0.001) G_GAN: 8.605 G_L1: 32.566 D_real: 0.285 D_fake: 0.000 \n",
            "(epoch: 141, iters: 260, time: 0.023, data: 0.001) G_GAN: 4.642 G_L1: 22.083 D_real: 0.038 D_fake: 0.297 \n",
            "End of epoch 141 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 142, iters: 64, time: 0.040, data: 0.001) G_GAN: 9.204 G_L1: 34.794 D_real: 0.161 D_fake: 0.002 \n",
            "(epoch: 142, iters: 164, time: 0.024, data: 0.002) G_GAN: 5.332 G_L1: 20.785 D_real: 0.008 D_fake: 0.676 \n",
            "(epoch: 142, iters: 264, time: 0.175, data: 0.001) G_GAN: 4.704 G_L1: 22.473 D_real: 0.001 D_fake: 0.049 \n",
            "End of epoch 142 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 143, iters: 68, time: 0.025, data: 0.001) G_GAN: 6.156 G_L1: 16.511 D_real: 0.019 D_fake: 0.851 \n",
            "(epoch: 143, iters: 168, time: 0.030, data: 0.001) G_GAN: 1.001 G_L1: 13.725 D_real: 0.869 D_fake: 0.108 \n",
            "(epoch: 143, iters: 268, time: 0.024, data: 0.001) G_GAN: 6.382 G_L1: 28.906 D_real: 0.017 D_fake: 0.011 \n",
            "End of epoch 143 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 144, iters: 72, time: 0.195, data: 0.001) G_GAN: 4.448 G_L1: 22.860 D_real: 0.002 D_fake: 0.047 \n",
            "(epoch: 144, iters: 172, time: 0.024, data: 0.001) G_GAN: 4.798 G_L1: 28.206 D_real: 0.002 D_fake: 0.016 \n",
            "(epoch: 144, iters: 272, time: 0.024, data: 0.001) G_GAN: 6.400 G_L1: 23.765 D_real: 0.031 D_fake: 0.008 \n",
            "End of epoch 144 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 145, iters: 76, time: 0.023, data: 0.001) G_GAN: 4.813 G_L1: 24.850 D_real: 0.493 D_fake: 0.005 \n",
            "(epoch: 145, iters: 176, time: 0.165, data: 0.001) G_GAN: 7.330 G_L1: 30.094 D_real: 0.056 D_fake: 0.002 \n",
            "(epoch: 145, iters: 276, time: 0.028, data: 0.001) G_GAN: 4.374 G_L1: 31.376 D_real: 0.005 D_fake: 0.494 \n",
            "saving the model at the end of epoch 145, iters 42920\n",
            "End of epoch 145 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 146, iters: 80, time: 0.023, data: 0.003) G_GAN: 4.487 G_L1: 33.622 D_real: 0.007 D_fake: 0.099 \n",
            "(epoch: 146, iters: 180, time: 0.024, data: 0.001) G_GAN: 4.474 G_L1: 25.224 D_real: 0.722 D_fake: 0.027 \n",
            "(epoch: 146, iters: 280, time: 0.228, data: 0.001) G_GAN: 3.540 G_L1: 23.206 D_real: 0.062 D_fake: 0.234 \n",
            "End of epoch 146 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 147, iters: 84, time: 0.024, data: 0.002) G_GAN: 8.582 G_L1: 25.225 D_real: 0.046 D_fake: 0.002 \n",
            "(epoch: 147, iters: 184, time: 0.039, data: 0.001) G_GAN: 3.730 G_L1: 14.159 D_real: 0.204 D_fake: 0.040 \n",
            "(epoch: 147, iters: 284, time: 0.024, data: 0.001) G_GAN: 5.383 G_L1: 19.593 D_real: 0.033 D_fake: 0.006 \n",
            "End of epoch 147 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 148, iters: 88, time: 0.191, data: 0.001) G_GAN: 4.877 G_L1: 16.956 D_real: 0.070 D_fake: 0.031 \n",
            "(epoch: 148, iters: 188, time: 0.025, data: 0.002) G_GAN: 6.556 G_L1: 29.317 D_real: 0.141 D_fake: 0.013 \n",
            "(epoch: 148, iters: 288, time: 0.030, data: 0.001) G_GAN: 4.399 G_L1: 26.739 D_real: 0.000 D_fake: 0.052 \n",
            "End of epoch 148 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 149, iters: 92, time: 0.023, data: 0.001) G_GAN: 7.991 G_L1: 23.695 D_real: 0.024 D_fake: 0.005 \n",
            "(epoch: 149, iters: 192, time: 0.178, data: 0.001) G_GAN: 3.503 G_L1: 19.613 D_real: 0.294 D_fake: 0.072 \n",
            "(epoch: 149, iters: 292, time: 0.022, data: 0.001) G_GAN: 3.132 G_L1: 19.762 D_real: 1.481 D_fake: 0.004 \n",
            "End of epoch 149 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 150, iters: 96, time: 0.024, data: 0.001) G_GAN: 4.917 G_L1: 18.979 D_real: 0.001 D_fake: 0.084 \n",
            "(epoch: 150, iters: 196, time: 0.023, data: 0.001) G_GAN: 3.387 G_L1: 28.180 D_real: 0.058 D_fake: 0.195 \n",
            "(epoch: 150, iters: 296, time: 0.171, data: 0.001) G_GAN: 7.889 G_L1: 29.997 D_real: 0.003 D_fake: 0.002 \n",
            "saving the model at the end of epoch 150, iters 44400\n",
            "End of epoch 150 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 151, iters: 100, time: 0.029, data: 0.126) G_GAN: 5.031 G_L1: 23.873 D_real: 0.011 D_fake: 0.091 \n",
            "(epoch: 151, iters: 200, time: 0.024, data: 0.001) G_GAN: 7.184 G_L1: 25.544 D_real: 0.393 D_fake: 0.005 \n",
            "End of epoch 151 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 152, iters: 4, time: 0.032, data: 0.001) G_GAN: 4.748 G_L1: 18.913 D_real: 1.395 D_fake: 0.001 \n",
            "(epoch: 152, iters: 104, time: 0.178, data: 0.000) G_GAN: 7.098 G_L1: 37.953 D_real: 0.001 D_fake: 0.003 \n",
            "(epoch: 152, iters: 204, time: 0.024, data: 0.001) G_GAN: 4.101 G_L1: 20.896 D_real: 0.004 D_fake: 0.070 \n",
            "End of epoch 152 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 153, iters: 8, time: 0.029, data: 0.001) G_GAN: 4.840 G_L1: 34.095 D_real: 0.000 D_fake: 1.009 \n",
            "saving the latest model (epoch 153, total_iters 45000)\n",
            "(epoch: 153, iters: 108, time: 0.028, data: 0.002) G_GAN: 4.288 G_L1: 19.315 D_real: 0.294 D_fake: 0.018 \n",
            "(epoch: 153, iters: 208, time: 0.240, data: 0.001) G_GAN: 7.498 G_L1: 23.700 D_real: 0.015 D_fake: 0.002 \n",
            "End of epoch 153 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 154, iters: 12, time: 0.023, data: 0.007) G_GAN: 3.620 G_L1: 17.902 D_real: 0.263 D_fake: 0.475 \n",
            "(epoch: 154, iters: 112, time: 0.024, data: 0.001) G_GAN: 7.548 G_L1: 27.327 D_real: 0.000 D_fake: 0.022 \n",
            "(epoch: 154, iters: 212, time: 0.024, data: 0.001) G_GAN: 5.782 G_L1: 20.126 D_real: 0.003 D_fake: 0.032 \n",
            "End of epoch 154 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 155, iters: 16, time: 0.188, data: 0.001) G_GAN: 5.756 G_L1: 23.541 D_real: 0.020 D_fake: 0.008 \n",
            "(epoch: 155, iters: 116, time: 0.023, data: 0.002) G_GAN: 5.128 G_L1: 22.989 D_real: 0.014 D_fake: 0.128 \n",
            "(epoch: 155, iters: 216, time: 0.024, data: 0.001) G_GAN: 4.650 G_L1: 30.156 D_real: 0.311 D_fake: 0.009 \n",
            "saving the model at the end of epoch 155, iters 45880\n",
            "End of epoch 155 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 156, iters: 20, time: 0.029, data: 0.001) G_GAN: 2.803 G_L1: 17.753 D_real: 0.502 D_fake: 0.057 \n",
            "(epoch: 156, iters: 120, time: 0.175, data: 0.001) G_GAN: 3.730 G_L1: 19.159 D_real: 0.007 D_fake: 0.229 \n",
            "(epoch: 156, iters: 220, time: 0.024, data: 0.001) G_GAN: 8.249 G_L1: 28.391 D_real: 0.002 D_fake: 0.001 \n",
            "End of epoch 156 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 157, iters: 24, time: 0.024, data: 0.001) G_GAN: 4.813 G_L1: 30.633 D_real: 0.001 D_fake: 0.025 \n",
            "(epoch: 157, iters: 124, time: 0.030, data: 0.001) G_GAN: 8.663 G_L1: 25.814 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 157, iters: 224, time: 0.174, data: 0.001) G_GAN: 6.554 G_L1: 23.653 D_real: 0.438 D_fake: 0.002 \n",
            "End of epoch 157 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 158, iters: 28, time: 0.027, data: 0.001) G_GAN: 5.027 G_L1: 22.459 D_real: 0.077 D_fake: 0.009 \n",
            "(epoch: 158, iters: 128, time: 0.029, data: 0.001) G_GAN: 5.027 G_L1: 25.152 D_real: 0.000 D_fake: 0.030 \n",
            "(epoch: 158, iters: 228, time: 0.024, data: 0.001) G_GAN: 6.335 G_L1: 24.866 D_real: 0.019 D_fake: 0.011 \n",
            "End of epoch 158 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 159, iters: 32, time: 0.180, data: 0.001) G_GAN: 6.835 G_L1: 22.268 D_real: 0.014 D_fake: 0.006 \n",
            "(epoch: 159, iters: 132, time: 0.030, data: 0.001) G_GAN: 3.916 G_L1: 24.102 D_real: 0.000 D_fake: 0.138 \n",
            "(epoch: 159, iters: 232, time: 0.031, data: 0.001) G_GAN: 4.733 G_L1: 20.677 D_real: 0.001 D_fake: 0.191 \n",
            "End of epoch 159 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 160, iters: 36, time: 0.029, data: 0.002) G_GAN: 5.070 G_L1: 20.983 D_real: 0.123 D_fake: 0.086 \n",
            "(epoch: 160, iters: 136, time: 0.230, data: 0.001) G_GAN: 5.495 G_L1: 35.624 D_real: 0.001 D_fake: 0.628 \n",
            "(epoch: 160, iters: 236, time: 0.023, data: 0.001) G_GAN: 3.735 G_L1: 24.314 D_real: 1.000 D_fake: 0.022 \n",
            "saving the model at the end of epoch 160, iters 47360\n",
            "End of epoch 160 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 161, iters: 40, time: 0.024, data: 0.001) G_GAN: 4.661 G_L1: 21.361 D_real: 0.027 D_fake: 0.493 \n",
            "(epoch: 161, iters: 140, time: 0.024, data: 0.001) G_GAN: 5.425 G_L1: 18.435 D_real: 0.014 D_fake: 0.240 \n",
            "(epoch: 161, iters: 240, time: 0.226, data: 0.001) G_GAN: 0.886 G_L1: 20.101 D_real: 1.328 D_fake: 0.130 \n",
            "End of epoch 161 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 162, iters: 44, time: 0.024, data: 0.002) G_GAN: 4.611 G_L1: 21.751 D_real: 0.035 D_fake: 0.024 \n",
            "(epoch: 162, iters: 144, time: 0.023, data: 0.001) G_GAN: 4.933 G_L1: 22.665 D_real: 0.042 D_fake: 0.139 \n",
            "(epoch: 162, iters: 244, time: 0.024, data: 0.001) G_GAN: 5.191 G_L1: 21.506 D_real: 0.029 D_fake: 0.049 \n",
            "End of epoch 162 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 163, iters: 48, time: 0.186, data: 0.001) G_GAN: 7.151 G_L1: 24.845 D_real: 0.009 D_fake: 0.002 \n",
            "(epoch: 163, iters: 148, time: 0.024, data: 0.001) G_GAN: 3.879 G_L1: 21.413 D_real: 0.035 D_fake: 0.156 \n",
            "(epoch: 163, iters: 248, time: 0.024, data: 0.001) G_GAN: 4.679 G_L1: 19.125 D_real: 0.326 D_fake: 0.016 \n",
            "End of epoch 163 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 164, iters: 52, time: 0.024, data: 0.001) G_GAN: 3.166 G_L1: 24.006 D_real: 0.194 D_fake: 0.072 \n",
            "(epoch: 164, iters: 152, time: 0.209, data: 0.001) G_GAN: 4.652 G_L1: 21.336 D_real: 0.003 D_fake: 0.031 \n",
            "(epoch: 164, iters: 252, time: 0.023, data: 0.001) G_GAN: 4.538 G_L1: 19.542 D_real: 0.013 D_fake: 0.182 \n",
            "End of epoch 164 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 165, iters: 56, time: 0.023, data: 0.001) G_GAN: 4.370 G_L1: 22.446 D_real: 0.003 D_fake: 0.048 \n",
            "(epoch: 165, iters: 156, time: 0.026, data: 0.001) G_GAN: 3.855 G_L1: 22.912 D_real: 0.402 D_fake: 0.007 \n",
            "(epoch: 165, iters: 256, time: 0.191, data: 0.001) G_GAN: 4.142 G_L1: 28.223 D_real: 0.127 D_fake: 0.075 \n",
            "saving the model at the end of epoch 165, iters 48840\n",
            "End of epoch 165 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 166, iters: 60, time: 0.025, data: 0.001) G_GAN: 4.930 G_L1: 21.726 D_real: 0.056 D_fake: 0.171 \n",
            "(epoch: 166, iters: 160, time: 0.023, data: 0.001) G_GAN: 3.510 G_L1: 19.816 D_real: 0.634 D_fake: 0.005 \n",
            "(epoch: 166, iters: 260, time: 0.023, data: 0.001) G_GAN: 6.445 G_L1: 29.379 D_real: 0.007 D_fake: 0.040 \n",
            "End of epoch 166 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 167, iters: 64, time: 0.267, data: 0.001) G_GAN: 6.407 G_L1: 24.313 D_real: 0.008 D_fake: 0.002 \n",
            "(epoch: 167, iters: 164, time: 0.024, data: 0.002) G_GAN: 4.601 G_L1: 21.253 D_real: 0.073 D_fake: 0.042 \n",
            "(epoch: 167, iters: 264, time: 0.023, data: 0.001) G_GAN: 3.310 G_L1: 16.478 D_real: 0.015 D_fake: 0.138 \n",
            "End of epoch 167 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 168, iters: 68, time: 0.029, data: 0.001) G_GAN: 4.245 G_L1: 17.519 D_real: 0.019 D_fake: 0.175 \n",
            "(epoch: 168, iters: 168, time: 0.191, data: 0.002) G_GAN: 5.533 G_L1: 26.357 D_real: 0.002 D_fake: 0.008 \n",
            "(epoch: 168, iters: 268, time: 0.032, data: 0.001) G_GAN: 4.129 G_L1: 21.080 D_real: 0.001 D_fake: 0.077 \n",
            "End of epoch 168 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 169, iters: 72, time: 0.023, data: 0.001) G_GAN: 5.558 G_L1: 21.199 D_real: 0.011 D_fake: 0.151 \n",
            "(epoch: 169, iters: 172, time: 0.023, data: 0.001) G_GAN: 4.996 G_L1: 23.613 D_real: 0.084 D_fake: 0.254 \n",
            "(epoch: 169, iters: 272, time: 0.194, data: 0.001) G_GAN: 5.455 G_L1: 23.370 D_real: 0.253 D_fake: 0.841 \n",
            "saving the latest model (epoch 169, total_iters 50000)\n",
            "End of epoch 169 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 170, iters: 76, time: 0.024, data: 0.001) G_GAN: 2.713 G_L1: 19.463 D_real: 1.231 D_fake: 0.009 \n",
            "(epoch: 170, iters: 176, time: 0.027, data: 0.001) G_GAN: 3.131 G_L1: 17.960 D_real: 0.233 D_fake: 0.132 \n",
            "(epoch: 170, iters: 276, time: 0.025, data: 0.002) G_GAN: 11.090 G_L1: 22.002 D_real: 0.004 D_fake: 0.000 \n",
            "saving the model at the end of epoch 170, iters 50320\n",
            "End of epoch 170 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 171, iters: 80, time: 0.192, data: 0.001) G_GAN: 4.143 G_L1: 17.650 D_real: 0.122 D_fake: 0.046 \n",
            "(epoch: 171, iters: 180, time: 0.031, data: 0.001) G_GAN: 2.443 G_L1: 20.804 D_real: 0.572 D_fake: 0.142 \n",
            "(epoch: 171, iters: 280, time: 0.024, data: 0.001) G_GAN: 4.911 G_L1: 20.931 D_real: 0.191 D_fake: 0.030 \n",
            "End of epoch 171 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 172, iters: 84, time: 0.024, data: 0.001) G_GAN: 7.229 G_L1: 41.482 D_real: 0.073 D_fake: 0.001 \n",
            "(epoch: 172, iters: 184, time: 0.257, data: 0.001) G_GAN: 4.586 G_L1: 16.355 D_real: 0.011 D_fake: 0.845 \n",
            "(epoch: 172, iters: 284, time: 0.023, data: 0.001) G_GAN: 5.177 G_L1: 24.486 D_real: 0.020 D_fake: 0.378 \n",
            "End of epoch 172 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 173, iters: 88, time: 0.025, data: 0.001) G_GAN: 5.807 G_L1: 20.427 D_real: 0.018 D_fake: 1.460 \n",
            "(epoch: 173, iters: 188, time: 0.029, data: 0.001) G_GAN: 4.632 G_L1: 21.776 D_real: 0.056 D_fake: 0.022 \n",
            "(epoch: 173, iters: 288, time: 0.190, data: 0.001) G_GAN: 3.980 G_L1: 19.351 D_real: 0.005 D_fake: 0.223 \n",
            "End of epoch 173 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 174, iters: 92, time: 0.027, data: 0.002) G_GAN: 3.855 G_L1: 20.888 D_real: 0.009 D_fake: 0.221 \n",
            "(epoch: 174, iters: 192, time: 0.023, data: 0.001) G_GAN: 5.224 G_L1: 14.975 D_real: 0.035 D_fake: 0.028 \n",
            "(epoch: 174, iters: 292, time: 0.028, data: 0.001) G_GAN: 4.348 G_L1: 17.616 D_real: 0.006 D_fake: 0.036 \n",
            "End of epoch 174 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 175, iters: 96, time: 0.195, data: 0.001) G_GAN: 4.145 G_L1: 23.901 D_real: 0.022 D_fake: 0.018 \n",
            "(epoch: 175, iters: 196, time: 0.033, data: 0.001) G_GAN: 5.590 G_L1: 20.732 D_real: 0.050 D_fake: 0.008 \n",
            "(epoch: 175, iters: 296, time: 0.024, data: 0.001) G_GAN: 6.031 G_L1: 24.925 D_real: 0.003 D_fake: 0.009 \n",
            "saving the model at the end of epoch 175, iters 51800\n",
            "End of epoch 175 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 176, iters: 100, time: 0.023, data: 0.127) G_GAN: 3.783 G_L1: 42.783 D_real: 0.003 D_fake: 0.051 \n",
            "(epoch: 176, iters: 200, time: 0.470, data: 0.001) G_GAN: 3.704 G_L1: 18.227 D_real: 0.077 D_fake: 0.182 \n",
            "End of epoch 176 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 177, iters: 4, time: 0.036, data: 0.002) G_GAN: 4.847 G_L1: 30.698 D_real: 0.281 D_fake: 0.011 \n",
            "(epoch: 177, iters: 104, time: 0.024, data: 0.000) G_GAN: 3.326 G_L1: 14.620 D_real: 0.088 D_fake: 0.055 \n",
            "(epoch: 177, iters: 204, time: 0.024, data: 0.001) G_GAN: 7.104 G_L1: 24.588 D_real: 0.048 D_fake: 0.004 \n",
            "End of epoch 177 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 178, iters: 8, time: 0.389, data: 0.001) G_GAN: 8.556 G_L1: 16.735 D_real: 0.088 D_fake: 0.002 \n",
            "(epoch: 178, iters: 108, time: 0.023, data: 0.001) G_GAN: 4.895 G_L1: 24.251 D_real: 0.001 D_fake: 0.173 \n",
            "(epoch: 178, iters: 208, time: 0.024, data: 0.001) G_GAN: 4.311 G_L1: 20.161 D_real: 0.293 D_fake: 0.023 \n",
            "End of epoch 178 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 179, iters: 12, time: 0.024, data: 0.001) G_GAN: 6.087 G_L1: 16.378 D_real: 0.003 D_fake: 0.680 \n",
            "(epoch: 179, iters: 112, time: 0.189, data: 0.001) G_GAN: 7.248 G_L1: 19.795 D_real: 0.572 D_fake: 0.001 \n",
            "(epoch: 179, iters: 212, time: 0.023, data: 0.001) G_GAN: 6.226 G_L1: 17.572 D_real: 0.040 D_fake: 0.005 \n",
            "End of epoch 179 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 180, iters: 16, time: 0.029, data: 0.001) G_GAN: 6.585 G_L1: 27.406 D_real: 0.022 D_fake: 0.008 \n",
            "(epoch: 180, iters: 116, time: 0.024, data: 0.001) G_GAN: 5.900 G_L1: 16.548 D_real: 0.027 D_fake: 0.010 \n",
            "(epoch: 180, iters: 216, time: 0.193, data: 0.001) G_GAN: 5.592 G_L1: 21.749 D_real: 0.124 D_fake: 0.006 \n",
            "saving the model at the end of epoch 180, iters 53280\n",
            "End of epoch 180 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 181, iters: 20, time: 0.029, data: 0.001) G_GAN: 4.928 G_L1: 17.677 D_real: 0.336 D_fake: 0.008 \n",
            "(epoch: 181, iters: 120, time: 0.023, data: 0.001) G_GAN: 3.364 G_L1: 18.521 D_real: 0.016 D_fake: 0.068 \n",
            "(epoch: 181, iters: 220, time: 0.024, data: 0.001) G_GAN: 5.156 G_L1: 20.179 D_real: 0.106 D_fake: 0.030 \n",
            "End of epoch 181 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 182, iters: 24, time: 0.205, data: 0.001) G_GAN: 5.202 G_L1: 22.732 D_real: 0.100 D_fake: 0.785 \n",
            "(epoch: 182, iters: 124, time: 0.029, data: 0.001) G_GAN: 4.815 G_L1: 21.122 D_real: 0.026 D_fake: 0.597 \n",
            "(epoch: 182, iters: 224, time: 0.024, data: 0.001) G_GAN: 7.031 G_L1: 16.078 D_real: 0.007 D_fake: 1.283 \n",
            "End of epoch 182 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 183, iters: 28, time: 0.023, data: 0.001) G_GAN: 6.764 G_L1: 31.760 D_real: 0.081 D_fake: 0.002 \n",
            "(epoch: 183, iters: 128, time: 0.262, data: 0.001) G_GAN: 7.322 G_L1: 18.647 D_real: 0.488 D_fake: 0.002 \n",
            "(epoch: 183, iters: 228, time: 0.025, data: 0.001) G_GAN: 4.614 G_L1: 19.912 D_real: 0.016 D_fake: 0.076 \n",
            "End of epoch 183 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 184, iters: 32, time: 0.023, data: 0.001) G_GAN: 1.459 G_L1: 15.444 D_real: 1.712 D_fake: 0.055 \n",
            "(epoch: 184, iters: 132, time: 0.023, data: 0.001) G_GAN: 4.332 G_L1: 17.993 D_real: 0.001 D_fake: 0.191 \n",
            "(epoch: 184, iters: 232, time: 0.208, data: 0.001) G_GAN: 4.839 G_L1: 17.382 D_real: 0.093 D_fake: 0.057 \n",
            "End of epoch 184 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 185, iters: 36, time: 0.030, data: 0.001) G_GAN: 5.463 G_L1: 24.907 D_real: 0.013 D_fake: 0.322 \n",
            "(epoch: 185, iters: 136, time: 0.023, data: 0.001) G_GAN: 5.141 G_L1: 15.636 D_real: 0.768 D_fake: 0.003 \n",
            "(epoch: 185, iters: 236, time: 0.027, data: 0.001) G_GAN: 4.170 G_L1: 22.008 D_real: 0.014 D_fake: 0.312 \n",
            "saving the model at the end of epoch 185, iters 54760\n",
            "End of epoch 185 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 186, iters: 40, time: 0.205, data: 0.001) G_GAN: 9.381 G_L1: 27.250 D_real: 0.022 D_fake: 0.000 \n",
            "(epoch: 186, iters: 140, time: 0.024, data: 0.002) G_GAN: 4.997 G_L1: 21.041 D_real: 0.013 D_fake: 0.277 \n",
            "(epoch: 186, iters: 240, time: 0.024, data: 0.002) G_GAN: 6.171 G_L1: 18.148 D_real: 0.031 D_fake: 0.994 \n",
            "saving the latest model (epoch 186, total_iters 55000)\n",
            "End of epoch 186 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 187, iters: 44, time: 0.023, data: 0.001) G_GAN: 4.633 G_L1: 19.155 D_real: 0.238 D_fake: 0.012 \n",
            "(epoch: 187, iters: 144, time: 0.247, data: 0.001) G_GAN: 4.889 G_L1: 19.876 D_real: 0.013 D_fake: 0.017 \n",
            "(epoch: 187, iters: 244, time: 0.023, data: 0.001) G_GAN: 2.634 G_L1: 23.052 D_real: 1.073 D_fake: 0.009 \n",
            "End of epoch 187 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 188, iters: 48, time: 0.027, data: 0.001) G_GAN: 5.824 G_L1: 19.165 D_real: 0.005 D_fake: 0.105 \n",
            "(epoch: 188, iters: 148, time: 0.023, data: 0.001) G_GAN: 4.019 G_L1: 19.345 D_real: 0.009 D_fake: 0.403 \n",
            "(epoch: 188, iters: 248, time: 0.253, data: 0.002) G_GAN: 5.718 G_L1: 12.868 D_real: 0.002 D_fake: 3.897 \n",
            "End of epoch 188 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 189, iters: 52, time: 0.025, data: 0.001) G_GAN: 2.624 G_L1: 18.279 D_real: 0.677 D_fake: 0.171 \n",
            "(epoch: 189, iters: 152, time: 0.024, data: 0.001) G_GAN: 4.518 G_L1: 21.403 D_real: 0.836 D_fake: 0.012 \n",
            "(epoch: 189, iters: 252, time: 0.029, data: 0.001) G_GAN: 6.385 G_L1: 21.478 D_real: 0.017 D_fake: 0.007 \n",
            "End of epoch 189 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 190, iters: 56, time: 0.208, data: 0.002) G_GAN: 9.425 G_L1: 14.465 D_real: 0.004 D_fake: 1.835 \n",
            "(epoch: 190, iters: 156, time: 0.025, data: 0.001) G_GAN: 6.199 G_L1: 17.163 D_real: 0.025 D_fake: 0.903 \n",
            "(epoch: 190, iters: 256, time: 0.025, data: 0.001) G_GAN: 4.765 G_L1: 17.209 D_real: 0.124 D_fake: 0.013 \n",
            "saving the model at the end of epoch 190, iters 56240\n",
            "End of epoch 190 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 191, iters: 60, time: 0.024, data: 0.001) G_GAN: 6.712 G_L1: 20.774 D_real: 0.060 D_fake: 0.003 \n",
            "(epoch: 191, iters: 160, time: 0.203, data: 0.001) G_GAN: 1.961 G_L1: 18.728 D_real: 0.715 D_fake: 0.067 \n",
            "(epoch: 191, iters: 260, time: 0.023, data: 0.001) G_GAN: 4.288 G_L1: 15.695 D_real: 0.116 D_fake: 0.028 \n",
            "End of epoch 191 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 192, iters: 64, time: 0.023, data: 0.001) G_GAN: 10.415 G_L1: 23.662 D_real: 0.007 D_fake: 0.000 \n",
            "(epoch: 192, iters: 164, time: 0.024, data: 0.001) G_GAN: 9.411 G_L1: 21.644 D_real: 0.015 D_fake: 0.001 \n",
            "(epoch: 192, iters: 264, time: 0.217, data: 0.001) G_GAN: 7.650 G_L1: 23.703 D_real: 0.000 D_fake: 0.020 \n",
            "End of epoch 192 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 193, iters: 68, time: 0.023, data: 0.001) G_GAN: 6.780 G_L1: 26.171 D_real: 0.908 D_fake: 0.001 \n",
            "(epoch: 193, iters: 168, time: 0.024, data: 0.001) G_GAN: 7.628 G_L1: 27.845 D_real: 0.055 D_fake: 0.001 \n",
            "(epoch: 193, iters: 268, time: 0.024, data: 0.001) G_GAN: 1.142 G_L1: 16.032 D_real: 0.753 D_fake: 0.122 \n",
            "End of epoch 193 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 194, iters: 72, time: 0.259, data: 0.001) G_GAN: 5.235 G_L1: 17.667 D_real: 0.189 D_fake: 0.005 \n",
            "(epoch: 194, iters: 172, time: 0.027, data: 0.001) G_GAN: 4.693 G_L1: 23.785 D_real: 0.005 D_fake: 0.055 \n",
            "(epoch: 194, iters: 272, time: 0.023, data: 0.001) G_GAN: 7.969 G_L1: 18.622 D_real: 0.005 D_fake: 2.592 \n",
            "End of epoch 194 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 195, iters: 76, time: 0.023, data: 0.001) G_GAN: 6.931 G_L1: 21.201 D_real: 0.013 D_fake: 0.005 \n",
            "(epoch: 195, iters: 176, time: 0.348, data: 0.001) G_GAN: 4.345 G_L1: 20.088 D_real: 0.077 D_fake: 0.033 \n",
            "(epoch: 195, iters: 276, time: 0.031, data: 0.001) G_GAN: 5.226 G_L1: 18.870 D_real: 0.123 D_fake: 0.025 \n",
            "saving the model at the end of epoch 195, iters 57720\n",
            "End of epoch 195 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 196, iters: 80, time: 0.025, data: 0.001) G_GAN: 5.095 G_L1: 18.738 D_real: 0.372 D_fake: 0.007 \n",
            "(epoch: 196, iters: 180, time: 0.023, data: 0.001) G_GAN: 4.672 G_L1: 29.982 D_real: 0.000 D_fake: 0.091 \n",
            "(epoch: 196, iters: 280, time: 0.272, data: 0.001) G_GAN: 6.831 G_L1: 52.354 D_real: 0.003 D_fake: 0.016 \n",
            "End of epoch 196 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 197, iters: 84, time: 0.031, data: 0.001) G_GAN: 5.750 G_L1: 22.376 D_real: 0.069 D_fake: 0.025 \n",
            "(epoch: 197, iters: 184, time: 0.026, data: 0.001) G_GAN: 4.011 G_L1: 19.900 D_real: 0.486 D_fake: 0.018 \n",
            "(epoch: 197, iters: 284, time: 0.026, data: 0.002) G_GAN: 4.888 G_L1: 19.932 D_real: 0.077 D_fake: 0.021 \n",
            "End of epoch 197 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 198, iters: 88, time: 0.229, data: 0.001) G_GAN: 4.114 G_L1: 27.889 D_real: 0.236 D_fake: 0.017 \n",
            "(epoch: 198, iters: 188, time: 0.025, data: 0.001) G_GAN: 7.372 G_L1: 24.019 D_real: 0.024 D_fake: 0.002 \n",
            "(epoch: 198, iters: 288, time: 0.029, data: 0.001) G_GAN: 5.077 G_L1: 17.965 D_real: 0.023 D_fake: 0.179 \n",
            "End of epoch 198 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 199, iters: 92, time: 0.022, data: 0.001) G_GAN: 2.819 G_L1: 15.282 D_real: 0.193 D_fake: 0.304 \n",
            "(epoch: 199, iters: 192, time: 0.264, data: 0.001) G_GAN: 3.665 G_L1: 17.563 D_real: 0.008 D_fake: 0.070 \n",
            "(epoch: 199, iters: 292, time: 0.021, data: 0.001) G_GAN: 3.896 G_L1: 14.456 D_real: 0.504 D_fake: 0.017 \n",
            "End of epoch 199 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 200, iters: 96, time: 0.029, data: 0.001) G_GAN: 6.192 G_L1: 16.304 D_real: 0.015 D_fake: 0.005 \n",
            "(epoch: 200, iters: 196, time: 0.026, data: 0.002) G_GAN: 4.121 G_L1: 17.149 D_real: 0.131 D_fake: 0.474 \n",
            "(epoch: 200, iters: 296, time: 0.214, data: 0.001) G_GAN: 7.266 G_L1: 17.368 D_real: 0.001 D_fake: 1.396 \n",
            "saving the model at the end of epoch 200, iters 59200\n",
            "End of epoch 200 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 201, iters: 100, time: 0.024, data: 0.103) G_GAN: 7.278 G_L1: 14.046 D_real: 0.182 D_fake: 0.003 \n",
            "(epoch: 201, iters: 200, time: 0.024, data: 0.002) G_GAN: 5.594 G_L1: 16.712 D_real: 0.007 D_fake: 0.021 \n",
            "End of epoch 201 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 202, iters: 4, time: 0.028, data: 0.001) G_GAN: 4.671 G_L1: 20.471 D_real: 0.005 D_fake: 0.115 \n",
            "(epoch: 202, iters: 104, time: 0.206, data: 0.001) G_GAN: 6.220 G_L1: 15.024 D_real: 0.756 D_fake: 0.002 \n",
            "(epoch: 202, iters: 204, time: 0.023, data: 0.001) G_GAN: 7.503 G_L1: 18.756 D_real: 0.061 D_fake: 0.001 \n",
            "End of epoch 202 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 203, iters: 8, time: 0.023, data: 0.001) G_GAN: 5.384 G_L1: 22.256 D_real: 0.052 D_fake: 0.044 \n",
            "(epoch: 203, iters: 108, time: 0.029, data: 0.000) G_GAN: 5.089 G_L1: 20.839 D_real: 0.001 D_fake: 0.122 \n",
            "(epoch: 203, iters: 208, time: 0.346, data: 0.001) G_GAN: 5.346 G_L1: 15.719 D_real: 0.003 D_fake: 0.016 \n",
            "saving the latest model (epoch 203, total_iters 60000)\n",
            "End of epoch 203 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 204, iters: 12, time: 0.024, data: 0.007) G_GAN: 7.498 G_L1: 22.669 D_real: 0.025 D_fake: 0.003 \n",
            "(epoch: 204, iters: 112, time: 0.023, data: 0.001) G_GAN: 4.515 G_L1: 17.573 D_real: 0.058 D_fake: 0.354 \n",
            "(epoch: 204, iters: 212, time: 0.023, data: 0.001) G_GAN: 6.024 G_L1: 14.736 D_real: 0.007 D_fake: 0.575 \n",
            "End of epoch 204 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 205, iters: 16, time: 0.274, data: 0.001) G_GAN: 3.869 G_L1: 21.221 D_real: 0.064 D_fake: 0.069 \n",
            "(epoch: 205, iters: 116, time: 0.023, data: 0.001) G_GAN: 5.815 G_L1: 23.052 D_real: 0.003 D_fake: 0.012 \n",
            "(epoch: 205, iters: 216, time: 0.023, data: 0.001) G_GAN: 5.151 G_L1: 16.563 D_real: 0.394 D_fake: 0.015 \n",
            "saving the model at the end of epoch 205, iters 60680\n",
            "End of epoch 205 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 206, iters: 20, time: 0.025, data: 0.001) G_GAN: 5.704 G_L1: 24.424 D_real: 0.020 D_fake: 0.663 \n",
            "(epoch: 206, iters: 120, time: 0.371, data: 0.001) G_GAN: 6.275 G_L1: 17.613 D_real: 0.021 D_fake: 0.008 \n",
            "(epoch: 206, iters: 220, time: 0.023, data: 0.002) G_GAN: 6.380 G_L1: 24.058 D_real: 2.110 D_fake: 0.001 \n",
            "End of epoch 206 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 207, iters: 24, time: 0.023, data: 0.001) G_GAN: 5.754 G_L1: 14.611 D_real: 0.122 D_fake: 0.822 \n",
            "(epoch: 207, iters: 124, time: 0.024, data: 0.001) G_GAN: 8.423 G_L1: 28.909 D_real: 0.037 D_fake: 0.004 \n",
            "(epoch: 207, iters: 224, time: 0.213, data: 0.001) G_GAN: 4.003 G_L1: 17.892 D_real: 0.348 D_fake: 0.010 \n",
            "End of epoch 207 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 208, iters: 28, time: 0.022, data: 0.001) G_GAN: 3.848 G_L1: 19.763 D_real: 0.029 D_fake: 0.088 \n",
            "(epoch: 208, iters: 128, time: 0.023, data: 0.001) G_GAN: 4.887 G_L1: 22.608 D_real: 0.009 D_fake: 0.123 \n",
            "(epoch: 208, iters: 228, time: 0.024, data: 0.001) G_GAN: 2.217 G_L1: 19.103 D_real: 1.629 D_fake: 0.025 \n",
            "End of epoch 208 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 209, iters: 32, time: 0.275, data: 0.001) G_GAN: 6.339 G_L1: 18.102 D_real: 0.073 D_fake: 0.003 \n",
            "(epoch: 209, iters: 132, time: 0.023, data: 0.001) G_GAN: 4.872 G_L1: 20.615 D_real: 0.005 D_fake: 0.378 \n",
            "(epoch: 209, iters: 232, time: 0.031, data: 0.001) G_GAN: 6.330 G_L1: 18.822 D_real: 0.130 D_fake: 0.868 \n",
            "End of epoch 209 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 210, iters: 36, time: 0.023, data: 0.002) G_GAN: 4.116 G_L1: 17.108 D_real: 0.002 D_fake: 0.389 \n",
            "(epoch: 210, iters: 136, time: 0.220, data: 0.001) G_GAN: 4.638 G_L1: 24.887 D_real: 0.001 D_fake: 0.063 \n",
            "(epoch: 210, iters: 236, time: 0.028, data: 0.001) G_GAN: 9.520 G_L1: 21.246 D_real: 0.000 D_fake: 1.497 \n",
            "saving the model at the end of epoch 210, iters 62160\n",
            "End of epoch 210 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 211, iters: 40, time: 0.024, data: 0.003) G_GAN: 6.385 G_L1: 19.480 D_real: 0.286 D_fake: 0.002 \n",
            "(epoch: 211, iters: 140, time: 0.023, data: 0.001) G_GAN: 5.921 G_L1: 19.287 D_real: 0.019 D_fake: 0.013 \n",
            "(epoch: 211, iters: 240, time: 0.238, data: 0.001) G_GAN: 5.992 G_L1: 18.935 D_real: 0.004 D_fake: 0.004 \n",
            "End of epoch 211 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 212, iters: 44, time: 0.032, data: 0.002) G_GAN: 4.534 G_L1: 20.861 D_real: 0.176 D_fake: 0.038 \n",
            "(epoch: 212, iters: 144, time: 0.024, data: 0.001) G_GAN: 5.709 G_L1: 17.116 D_real: 0.123 D_fake: 0.004 \n",
            "(epoch: 212, iters: 244, time: 0.024, data: 0.001) G_GAN: 4.311 G_L1: 16.768 D_real: 0.347 D_fake: 0.020 \n",
            "End of epoch 212 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 213, iters: 48, time: 0.254, data: 0.001) G_GAN: 4.561 G_L1: 15.855 D_real: 0.042 D_fake: 0.078 \n",
            "(epoch: 213, iters: 148, time: 0.025, data: 0.002) G_GAN: 3.857 G_L1: 24.879 D_real: 0.009 D_fake: 0.071 \n",
            "(epoch: 213, iters: 248, time: 0.031, data: 0.001) G_GAN: 4.003 G_L1: 17.672 D_real: 0.001 D_fake: 0.111 \n",
            "End of epoch 213 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 214, iters: 52, time: 0.024, data: 0.002) G_GAN: 5.348 G_L1: 22.767 D_real: 0.159 D_fake: 0.023 \n",
            "(epoch: 214, iters: 152, time: 0.307, data: 0.001) G_GAN: 7.968 G_L1: 20.089 D_real: 0.113 D_fake: 0.001 \n",
            "(epoch: 214, iters: 252, time: 0.023, data: 0.001) G_GAN: 5.260 G_L1: 16.850 D_real: 0.008 D_fake: 0.145 \n",
            "End of epoch 214 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 215, iters: 56, time: 0.024, data: 0.001) G_GAN: 5.464 G_L1: 18.265 D_real: 0.066 D_fake: 0.010 \n",
            "(epoch: 215, iters: 156, time: 0.024, data: 0.001) G_GAN: 4.701 G_L1: 17.722 D_real: 0.010 D_fake: 0.035 \n",
            "(epoch: 215, iters: 256, time: 0.224, data: 0.002) G_GAN: 6.245 G_L1: 13.767 D_real: 0.134 D_fake: 0.010 \n",
            "saving the model at the end of epoch 215, iters 63640\n",
            "End of epoch 215 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 216, iters: 60, time: 0.025, data: 0.001) G_GAN: 5.988 G_L1: 28.808 D_real: 0.015 D_fake: 0.010 \n",
            "(epoch: 216, iters: 160, time: 0.024, data: 0.002) G_GAN: 3.578 G_L1: 18.905 D_real: 0.349 D_fake: 0.092 \n",
            "(epoch: 216, iters: 260, time: 0.025, data: 0.001) G_GAN: 4.463 G_L1: 21.340 D_real: 0.058 D_fake: 0.097 \n",
            "End of epoch 216 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 217, iters: 64, time: 0.247, data: 0.001) G_GAN: 2.861 G_L1: 14.447 D_real: 0.364 D_fake: 0.062 \n",
            "(epoch: 217, iters: 164, time: 0.028, data: 0.002) G_GAN: 4.621 G_L1: 26.368 D_real: 0.009 D_fake: 0.106 \n",
            "(epoch: 217, iters: 264, time: 0.026, data: 0.001) G_GAN: 4.330 G_L1: 33.446 D_real: 0.053 D_fake: 0.087 \n",
            "End of epoch 217 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 218, iters: 68, time: 0.025, data: 0.002) G_GAN: 5.020 G_L1: 22.153 D_real: 0.154 D_fake: 0.012 \n",
            "(epoch: 218, iters: 168, time: 0.300, data: 0.001) G_GAN: 5.679 G_L1: 19.881 D_real: 0.069 D_fake: 0.014 \n",
            "(epoch: 218, iters: 268, time: 0.025, data: 0.002) G_GAN: 7.269 G_L1: 18.570 D_real: 0.220 D_fake: 0.003 \n",
            "End of epoch 218 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 219, iters: 72, time: 0.027, data: 0.001) G_GAN: 5.615 G_L1: 15.654 D_real: 0.354 D_fake: 0.005 \n",
            "(epoch: 219, iters: 172, time: 0.024, data: 0.002) G_GAN: 6.669 G_L1: 20.067 D_real: 0.105 D_fake: 1.072 \n",
            "(epoch: 219, iters: 272, time: 0.242, data: 0.002) G_GAN: 3.379 G_L1: 16.166 D_real: 0.183 D_fake: 0.055 \n",
            "End of epoch 219 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 220, iters: 76, time: 0.029, data: 0.002) G_GAN: 4.465 G_L1: 19.614 D_real: 0.626 D_fake: 0.006 \n",
            "(epoch: 220, iters: 176, time: 0.025, data: 0.001) G_GAN: 4.424 G_L1: 14.345 D_real: 0.317 D_fake: 0.004 \n",
            "saving the latest model (epoch 220, total_iters 65000)\n",
            "(epoch: 220, iters: 276, time: 0.024, data: 0.002) G_GAN: 4.708 G_L1: 17.510 D_real: 0.002 D_fake: 0.249 \n",
            "saving the model at the end of epoch 220, iters 65120\n",
            "End of epoch 220 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 221, iters: 80, time: 0.268, data: 0.001) G_GAN: 4.882 G_L1: 21.058 D_real: 0.016 D_fake: 0.026 \n",
            "(epoch: 221, iters: 180, time: 0.028, data: 0.002) G_GAN: 8.929 G_L1: 18.391 D_real: 0.195 D_fake: 0.001 \n",
            "(epoch: 221, iters: 280, time: 0.039, data: 0.001) G_GAN: 4.938 G_L1: 20.990 D_real: 0.023 D_fake: 0.061 \n",
            "End of epoch 221 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 222, iters: 84, time: 0.027, data: 0.001) G_GAN: 11.251 G_L1: 17.347 D_real: 0.003 D_fake: 1.882 \n",
            "(epoch: 222, iters: 184, time: 0.239, data: 0.001) G_GAN: 7.463 G_L1: 18.618 D_real: 0.291 D_fake: 0.002 \n",
            "(epoch: 222, iters: 284, time: 0.029, data: 0.002) G_GAN: 3.816 G_L1: 21.012 D_real: 0.850 D_fake: 0.003 \n",
            "End of epoch 222 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 223, iters: 88, time: 0.024, data: 0.001) G_GAN: 3.971 G_L1: 14.751 D_real: 0.066 D_fake: 0.093 \n",
            "(epoch: 223, iters: 188, time: 0.025, data: 0.001) G_GAN: 3.289 G_L1: 15.414 D_real: 0.167 D_fake: 0.041 \n",
            "(epoch: 223, iters: 288, time: 0.302, data: 0.001) G_GAN: 3.969 G_L1: 18.835 D_real: 0.748 D_fake: 0.019 \n",
            "End of epoch 223 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 224, iters: 92, time: 0.025, data: 0.002) G_GAN: 5.785 G_L1: 14.322 D_real: 0.056 D_fake: 0.505 \n",
            "(epoch: 224, iters: 192, time: 0.027, data: 0.001) G_GAN: 5.183 G_L1: 23.435 D_real: 0.006 D_fake: 0.012 \n",
            "(epoch: 224, iters: 292, time: 0.024, data: 0.002) G_GAN: 4.965 G_L1: 21.597 D_real: 0.007 D_fake: 0.031 \n",
            "End of epoch 224 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 225, iters: 96, time: 0.247, data: 0.001) G_GAN: 5.526 G_L1: 16.063 D_real: 0.037 D_fake: 0.037 \n",
            "(epoch: 225, iters: 196, time: 0.025, data: 0.001) G_GAN: 10.093 G_L1: 24.882 D_real: 0.010 D_fake: 1.447 \n",
            "(epoch: 225, iters: 296, time: 0.022, data: 0.002) G_GAN: 6.518 G_L1: 14.866 D_real: 0.101 D_fake: 0.808 \n",
            "saving the model at the end of epoch 225, iters 66600\n",
            "End of epoch 225 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 226, iters: 100, time: 0.031, data: 0.120) G_GAN: 8.577 G_L1: 16.858 D_real: 0.013 D_fake: 0.001 \n",
            "(epoch: 226, iters: 200, time: 0.241, data: 0.002) G_GAN: 9.399 G_L1: 17.097 D_real: 0.048 D_fake: 0.000 \n",
            "End of epoch 226 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 227, iters: 4, time: 0.030, data: 0.002) G_GAN: 9.609 G_L1: 21.865 D_real: 0.004 D_fake: 1.196 \n",
            "(epoch: 227, iters: 104, time: 0.023, data: 0.000) G_GAN: 5.979 G_L1: 25.151 D_real: 0.513 D_fake: 0.010 \n",
            "(epoch: 227, iters: 204, time: 0.026, data: 0.001) G_GAN: 4.676 G_L1: 24.967 D_real: 0.028 D_fake: 0.145 \n",
            "End of epoch 227 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 228, iters: 8, time: 0.311, data: 0.002) G_GAN: 4.178 G_L1: 16.800 D_real: 0.370 D_fake: 0.338 \n",
            "(epoch: 228, iters: 108, time: 0.025, data: 0.000) G_GAN: 5.891 G_L1: 19.916 D_real: 0.047 D_fake: 0.081 \n",
            "(epoch: 228, iters: 208, time: 0.024, data: 0.001) G_GAN: 5.606 G_L1: 24.547 D_real: 0.009 D_fake: 0.110 \n",
            "End of epoch 228 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 229, iters: 12, time: 0.024, data: 0.002) G_GAN: 6.629 G_L1: 18.460 D_real: 0.093 D_fake: 0.003 \n",
            "(epoch: 229, iters: 112, time: 0.381, data: 0.001) G_GAN: 2.738 G_L1: 21.178 D_real: 0.570 D_fake: 0.229 \n",
            "(epoch: 229, iters: 212, time: 0.026, data: 0.002) G_GAN: 4.497 G_L1: 16.590 D_real: 0.189 D_fake: 0.182 \n",
            "End of epoch 229 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 230, iters: 16, time: 0.024, data: 0.001) G_GAN: 9.572 G_L1: 19.111 D_real: 0.093 D_fake: 0.000 \n",
            "(epoch: 230, iters: 116, time: 0.025, data: 0.001) G_GAN: 5.485 G_L1: 22.133 D_real: 0.017 D_fake: 0.207 \n",
            "(epoch: 230, iters: 216, time: 0.237, data: 0.001) G_GAN: 6.828 G_L1: 20.007 D_real: 0.001 D_fake: 0.355 \n",
            "saving the model at the end of epoch 230, iters 68080\n",
            "End of epoch 230 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 231, iters: 20, time: 0.028, data: 0.001) G_GAN: 5.619 G_L1: 18.533 D_real: 0.075 D_fake: 0.014 \n",
            "(epoch: 231, iters: 120, time: 0.026, data: 0.001) G_GAN: 5.179 G_L1: 18.563 D_real: 0.031 D_fake: 0.343 \n",
            "(epoch: 231, iters: 220, time: 0.023, data: 0.001) G_GAN: 5.211 G_L1: 17.726 D_real: 0.019 D_fake: 0.131 \n",
            "End of epoch 231 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 232, iters: 24, time: 0.333, data: 0.001) G_GAN: 3.104 G_L1: 22.534 D_real: 0.526 D_fake: 0.016 \n",
            "(epoch: 232, iters: 124, time: 0.027, data: 0.001) G_GAN: 4.572 G_L1: 19.417 D_real: 0.001 D_fake: 0.024 \n",
            "(epoch: 232, iters: 224, time: 0.026, data: 0.002) G_GAN: 4.321 G_L1: 19.741 D_real: 0.008 D_fake: 0.103 \n",
            "End of epoch 232 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 233, iters: 28, time: 0.029, data: 0.001) G_GAN: 8.537 G_L1: 20.312 D_real: 0.002 D_fake: 1.692 \n",
            "(epoch: 233, iters: 128, time: 0.241, data: 0.001) G_GAN: 5.897 G_L1: 15.849 D_real: 1.220 D_fake: 0.002 \n",
            "(epoch: 233, iters: 228, time: 0.029, data: 0.001) G_GAN: 5.494 G_L1: 22.640 D_real: 0.015 D_fake: 0.182 \n",
            "End of epoch 233 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 234, iters: 32, time: 0.025, data: 0.001) G_GAN: 10.684 G_L1: 16.607 D_real: 0.001 D_fake: 2.397 \n",
            "(epoch: 234, iters: 132, time: 0.032, data: 0.001) G_GAN: 6.355 G_L1: 19.668 D_real: 0.016 D_fake: 0.850 \n",
            "(epoch: 234, iters: 232, time: 0.242, data: 0.001) G_GAN: 5.191 G_L1: 19.946 D_real: 0.002 D_fake: 0.214 \n",
            "End of epoch 234 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 235, iters: 36, time: 0.025, data: 0.001) G_GAN: 7.358 G_L1: 26.555 D_real: 0.013 D_fake: 0.004 \n",
            "(epoch: 235, iters: 136, time: 0.030, data: 0.001) G_GAN: 10.080 G_L1: 21.114 D_real: 0.107 D_fake: 0.000 \n",
            "(epoch: 235, iters: 236, time: 0.024, data: 0.001) G_GAN: 4.692 G_L1: 16.240 D_real: 0.031 D_fake: 0.440 \n",
            "saving the model at the end of epoch 235, iters 69560\n",
            "End of epoch 235 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 236, iters: 40, time: 0.283, data: 0.001) G_GAN: 4.268 G_L1: 20.177 D_real: 0.059 D_fake: 0.065 \n",
            "(epoch: 236, iters: 140, time: 0.024, data: 0.002) G_GAN: 5.850 G_L1: 21.551 D_real: 0.001 D_fake: 0.467 \n",
            "(epoch: 236, iters: 240, time: 0.024, data: 0.002) G_GAN: 5.764 G_L1: 19.788 D_real: 0.005 D_fake: 0.011 \n",
            "End of epoch 236 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 237, iters: 44, time: 0.031, data: 0.002) G_GAN: 5.879 G_L1: 15.117 D_real: 0.061 D_fake: 0.041 \n",
            "(epoch: 237, iters: 144, time: 0.317, data: 0.001) G_GAN: 4.860 G_L1: 20.060 D_real: 0.949 D_fake: 0.010 \n",
            "saving the latest model (epoch 237, total_iters 70000)\n",
            "(epoch: 237, iters: 244, time: 0.024, data: 0.002) G_GAN: 3.633 G_L1: 21.091 D_real: 0.049 D_fake: 0.148 \n",
            "End of epoch 237 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 238, iters: 48, time: 0.024, data: 0.001) G_GAN: 3.449 G_L1: 15.266 D_real: 0.124 D_fake: 0.022 \n",
            "(epoch: 238, iters: 148, time: 0.025, data: 0.001) G_GAN: 5.006 G_L1: 16.952 D_real: 0.026 D_fake: 0.409 \n",
            "(epoch: 238, iters: 248, time: 0.249, data: 0.001) G_GAN: 5.072 G_L1: 20.994 D_real: 0.001 D_fake: 0.044 \n",
            "End of epoch 238 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 239, iters: 52, time: 0.033, data: 0.001) G_GAN: 7.958 G_L1: 18.521 D_real: 0.002 D_fake: 0.009 \n",
            "(epoch: 239, iters: 152, time: 0.030, data: 0.002) G_GAN: 4.653 G_L1: 15.492 D_real: 0.016 D_fake: 0.232 \n",
            "(epoch: 239, iters: 252, time: 0.032, data: 0.002) G_GAN: 11.516 G_L1: 14.416 D_real: 0.102 D_fake: 2.054 \n",
            "End of epoch 239 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 240, iters: 56, time: 0.250, data: 0.002) G_GAN: 6.792 G_L1: 19.309 D_real: 0.014 D_fake: 0.028 \n",
            "(epoch: 240, iters: 156, time: 0.024, data: 0.002) G_GAN: 7.797 G_L1: 23.396 D_real: 0.010 D_fake: 0.007 \n",
            "(epoch: 240, iters: 256, time: 0.024, data: 0.002) G_GAN: 3.926 G_L1: 16.909 D_real: 0.154 D_fake: 0.130 \n",
            "saving the model at the end of epoch 240, iters 71040\n",
            "End of epoch 240 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 241, iters: 60, time: 0.025, data: 0.001) G_GAN: 5.090 G_L1: 18.630 D_real: 0.071 D_fake: 0.012 \n",
            "(epoch: 241, iters: 160, time: 0.304, data: 0.001) G_GAN: 4.837 G_L1: 20.902 D_real: 0.099 D_fake: 0.042 \n",
            "(epoch: 241, iters: 260, time: 0.024, data: 0.002) G_GAN: 3.887 G_L1: 12.532 D_real: 0.158 D_fake: 0.080 \n",
            "End of epoch 241 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 242, iters: 64, time: 0.025, data: 0.001) G_GAN: 4.100 G_L1: 17.157 D_real: 0.001 D_fake: 0.269 \n",
            "(epoch: 242, iters: 164, time: 0.023, data: 0.001) G_GAN: 8.169 G_L1: 24.269 D_real: 0.031 D_fake: 0.003 \n",
            "(epoch: 242, iters: 264, time: 0.248, data: 0.001) G_GAN: 3.881 G_L1: 16.059 D_real: 0.677 D_fake: 0.047 \n",
            "End of epoch 242 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 243, iters: 68, time: 0.025, data: 0.002) G_GAN: 5.505 G_L1: 31.954 D_real: 0.136 D_fake: 0.009 \n",
            "(epoch: 243, iters: 168, time: 0.026, data: 0.001) G_GAN: 5.623 G_L1: 17.811 D_real: 0.007 D_fake: 0.083 \n",
            "(epoch: 243, iters: 268, time: 0.024, data: 0.001) G_GAN: 5.110 G_L1: 23.466 D_real: 0.125 D_fake: 0.024 \n",
            "End of epoch 243 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 244, iters: 72, time: 0.280, data: 0.002) G_GAN: 5.809 G_L1: 18.464 D_real: 0.013 D_fake: 0.010 \n",
            "(epoch: 244, iters: 172, time: 0.028, data: 0.003) G_GAN: 9.068 G_L1: 15.248 D_real: 0.065 D_fake: 1.749 \n",
            "(epoch: 244, iters: 272, time: 0.028, data: 0.001) G_GAN: 4.425 G_L1: 18.742 D_real: 0.273 D_fake: 0.020 \n",
            "End of epoch 244 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 245, iters: 76, time: 0.025, data: 0.001) G_GAN: 4.904 G_L1: 17.324 D_real: 0.035 D_fake: 0.230 \n",
            "(epoch: 245, iters: 176, time: 0.334, data: 0.001) G_GAN: 5.771 G_L1: 19.410 D_real: 0.071 D_fake: 0.466 \n",
            "(epoch: 245, iters: 276, time: 0.025, data: 0.001) G_GAN: 5.491 G_L1: 20.394 D_real: 0.000 D_fake: 0.027 \n",
            "saving the model at the end of epoch 245, iters 72520\n",
            "End of epoch 245 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 246, iters: 80, time: 0.024, data: 0.001) G_GAN: 8.834 G_L1: 17.302 D_real: 0.620 D_fake: 0.000 \n",
            "(epoch: 246, iters: 180, time: 0.026, data: 0.001) G_GAN: 6.228 G_L1: 14.151 D_real: 0.349 D_fake: 0.002 \n",
            "(epoch: 246, iters: 280, time: 0.287, data: 0.001) G_GAN: 5.341 G_L1: 14.573 D_real: 0.061 D_fake: 0.010 \n",
            "End of epoch 246 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 247, iters: 84, time: 0.031, data: 0.002) G_GAN: 5.877 G_L1: 16.338 D_real: 0.013 D_fake: 0.427 \n",
            "(epoch: 247, iters: 184, time: 0.034, data: 0.002) G_GAN: 5.845 G_L1: 13.540 D_real: 0.173 D_fake: 0.005 \n",
            "(epoch: 247, iters: 284, time: 0.026, data: 0.002) G_GAN: 4.455 G_L1: 17.662 D_real: 0.010 D_fake: 0.181 \n",
            "End of epoch 247 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 248, iters: 88, time: 0.260, data: 0.001) G_GAN: 4.402 G_L1: 15.485 D_real: 0.010 D_fake: 0.242 \n",
            "(epoch: 248, iters: 188, time: 0.032, data: 0.001) G_GAN: 5.193 G_L1: 16.084 D_real: 0.017 D_fake: 0.026 \n",
            "(epoch: 248, iters: 288, time: 0.023, data: 0.002) G_GAN: 4.836 G_L1: 18.594 D_real: 0.006 D_fake: 0.215 \n",
            "End of epoch 248 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 249, iters: 92, time: 0.030, data: 0.001) G_GAN: 4.152 G_L1: 18.702 D_real: 0.036 D_fake: 0.188 \n",
            "(epoch: 249, iters: 192, time: 0.453, data: 0.002) G_GAN: 3.572 G_L1: 23.362 D_real: 0.080 D_fake: 0.043 \n",
            "(epoch: 249, iters: 292, time: 0.023, data: 0.001) G_GAN: 1.452 G_L1: 14.754 D_real: 2.190 D_fake: 0.020 \n",
            "End of epoch 249 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 250, iters: 96, time: 0.025, data: 0.002) G_GAN: 3.438 G_L1: 14.964 D_real: 0.124 D_fake: 0.231 \n",
            "(epoch: 250, iters: 196, time: 0.025, data: 0.001) G_GAN: 4.569 G_L1: 22.390 D_real: 0.013 D_fake: 0.222 \n",
            "(epoch: 250, iters: 296, time: 0.271, data: 0.001) G_GAN: 7.278 G_L1: 22.999 D_real: 0.007 D_fake: 0.004 \n",
            "saving the model at the end of epoch 250, iters 74000\n",
            "End of epoch 250 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 251, iters: 100, time: 0.030, data: 0.129) G_GAN: 5.085 G_L1: 16.680 D_real: 0.027 D_fake: 0.289 \n",
            "(epoch: 251, iters: 200, time: 0.025, data: 0.002) G_GAN: 9.148 G_L1: 25.403 D_real: 0.013 D_fake: 0.001 \n",
            "End of epoch 251 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 252, iters: 4, time: 0.039, data: 0.001) G_GAN: 4.153 G_L1: 20.055 D_real: 0.044 D_fake: 0.116 \n",
            "(epoch: 252, iters: 104, time: 0.282, data: 0.003) G_GAN: 7.103 G_L1: 23.416 D_real: 0.043 D_fake: 0.004 \n",
            "(epoch: 252, iters: 204, time: 0.024, data: 0.001) G_GAN: 5.191 G_L1: 21.129 D_real: 0.023 D_fake: 0.444 \n",
            "End of epoch 252 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 253, iters: 8, time: 0.024, data: 0.001) G_GAN: 5.214 G_L1: 21.652 D_real: 0.002 D_fake: 0.224 \n",
            "(epoch: 253, iters: 108, time: 0.026, data: 0.000) G_GAN: 6.479 G_L1: 15.845 D_real: 0.009 D_fake: 0.007 \n",
            "(epoch: 253, iters: 208, time: 0.334, data: 0.001) G_GAN: 3.965 G_L1: 14.031 D_real: 0.220 D_fake: 0.152 \n",
            "End of epoch 253 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 254, iters: 12, time: 0.024, data: 0.002) G_GAN: 4.760 G_L1: 16.293 D_real: 0.091 D_fake: 0.025 \n",
            "(epoch: 254, iters: 112, time: 0.024, data: 0.001) G_GAN: 9.270 G_L1: 29.543 D_real: 0.002 D_fake: 0.001 \n",
            "saving the latest model (epoch 254, total_iters 75000)\n",
            "(epoch: 254, iters: 212, time: 0.023, data: 0.001) G_GAN: 3.133 G_L1: 16.719 D_real: 0.338 D_fake: 0.038 \n",
            "End of epoch 254 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 255, iters: 16, time: 0.310, data: 0.002) G_GAN: 5.216 G_L1: 31.942 D_real: 0.621 D_fake: 0.004 \n",
            "(epoch: 255, iters: 116, time: 0.026, data: 0.002) G_GAN: 7.208 G_L1: 32.327 D_real: 0.001 D_fake: 0.003 \n",
            "(epoch: 255, iters: 216, time: 0.030, data: 0.001) G_GAN: 7.002 G_L1: 17.815 D_real: 0.001 D_fake: 0.912 \n",
            "saving the model at the end of epoch 255, iters 75480\n",
            "End of epoch 255 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 256, iters: 20, time: 0.028, data: 0.002) G_GAN: 3.263 G_L1: 17.216 D_real: 0.387 D_fake: 0.033 \n",
            "(epoch: 256, iters: 120, time: 0.262, data: 0.001) G_GAN: 4.887 G_L1: 18.266 D_real: 0.035 D_fake: 0.073 \n",
            "(epoch: 256, iters: 220, time: 0.024, data: 0.002) G_GAN: 4.437 G_L1: 17.477 D_real: 0.910 D_fake: 0.004 \n",
            "End of epoch 256 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 257, iters: 24, time: 0.026, data: 0.001) G_GAN: 4.675 G_L1: 21.945 D_real: 0.022 D_fake: 0.163 \n",
            "(epoch: 257, iters: 124, time: 0.025, data: 0.002) G_GAN: 2.169 G_L1: 17.689 D_real: 0.212 D_fake: 0.130 \n",
            "(epoch: 257, iters: 224, time: 0.341, data: 0.002) G_GAN: 8.264 G_L1: 22.469 D_real: 0.029 D_fake: 0.001 \n",
            "End of epoch 257 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 258, iters: 28, time: 0.029, data: 0.002) G_GAN: 3.839 G_L1: 14.644 D_real: 0.113 D_fake: 0.068 \n",
            "(epoch: 258, iters: 128, time: 0.023, data: 0.002) G_GAN: 4.396 G_L1: 18.999 D_real: 0.001 D_fake: 0.239 \n",
            "(epoch: 258, iters: 228, time: 0.026, data: 0.002) G_GAN: 6.824 G_L1: 16.406 D_real: 0.093 D_fake: 0.002 \n",
            "End of epoch 258 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 259, iters: 32, time: 0.271, data: 0.001) G_GAN: 7.490 G_L1: 17.642 D_real: 0.002 D_fake: 1.035 \n",
            "(epoch: 259, iters: 132, time: 0.023, data: 0.001) G_GAN: 5.723 G_L1: 24.621 D_real: 0.002 D_fake: 0.053 \n",
            "(epoch: 259, iters: 232, time: 0.024, data: 0.001) G_GAN: 6.808 G_L1: 19.403 D_real: 0.072 D_fake: 0.008 \n",
            "End of epoch 259 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 260, iters: 36, time: 0.026, data: 0.002) G_GAN: 5.997 G_L1: 18.387 D_real: 0.096 D_fake: 0.018 \n",
            "(epoch: 260, iters: 136, time: 0.267, data: 0.001) G_GAN: 5.562 G_L1: 20.085 D_real: 0.031 D_fake: 0.031 \n",
            "(epoch: 260, iters: 236, time: 0.025, data: 0.001) G_GAN: 4.374 G_L1: 14.410 D_real: 0.113 D_fake: 0.068 \n",
            "saving the model at the end of epoch 260, iters 76960\n",
            "End of epoch 260 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 261, iters: 40, time: 0.024, data: 0.001) G_GAN: 4.809 G_L1: 19.679 D_real: 0.068 D_fake: 0.038 \n",
            "(epoch: 261, iters: 140, time: 0.024, data: 0.002) G_GAN: 3.703 G_L1: 18.474 D_real: 0.061 D_fake: 0.032 \n",
            "(epoch: 261, iters: 240, time: 0.311, data: 0.001) G_GAN: 4.388 G_L1: 18.888 D_real: 0.058 D_fake: 0.031 \n",
            "End of epoch 261 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 262, iters: 44, time: 0.023, data: 0.001) G_GAN: 4.088 G_L1: 17.271 D_real: 0.003 D_fake: 0.091 \n",
            "(epoch: 262, iters: 144, time: 0.024, data: 0.001) G_GAN: 10.017 G_L1: 23.073 D_real: 0.000 D_fake: 1.389 \n",
            "(epoch: 262, iters: 244, time: 0.023, data: 0.001) G_GAN: 5.068 G_L1: 19.452 D_real: 0.013 D_fake: 0.032 \n",
            "End of epoch 262 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 263, iters: 48, time: 0.283, data: 0.001) G_GAN: 4.473 G_L1: 13.553 D_real: 0.051 D_fake: 0.055 \n",
            "(epoch: 263, iters: 148, time: 0.026, data: 0.001) G_GAN: 6.560 G_L1: 15.497 D_real: 0.110 D_fake: 0.044 \n",
            "(epoch: 263, iters: 248, time: 0.024, data: 0.001) G_GAN: 4.604 G_L1: 18.104 D_real: 0.015 D_fake: 0.040 \n",
            "End of epoch 263 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 264, iters: 52, time: 0.023, data: 0.001) G_GAN: 6.382 G_L1: 20.582 D_real: 0.006 D_fake: 0.004 \n",
            "(epoch: 264, iters: 152, time: 0.325, data: 0.001) G_GAN: 5.441 G_L1: 17.410 D_real: 0.046 D_fake: 0.019 \n",
            "(epoch: 264, iters: 252, time: 0.024, data: 0.002) G_GAN: 5.387 G_L1: 15.923 D_real: 0.036 D_fake: 0.439 \n",
            "End of epoch 264 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 265, iters: 56, time: 0.023, data: 0.001) G_GAN: 5.033 G_L1: 17.994 D_real: 0.093 D_fake: 0.074 \n",
            "(epoch: 265, iters: 156, time: 0.033, data: 0.001) G_GAN: 7.796 G_L1: 17.187 D_real: 0.093 D_fake: 0.001 \n",
            "(epoch: 265, iters: 256, time: 0.264, data: 0.001) G_GAN: 8.059 G_L1: 14.931 D_real: 0.017 D_fake: 0.856 \n",
            "saving the model at the end of epoch 265, iters 78440\n",
            "End of epoch 265 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 266, iters: 60, time: 0.023, data: 0.001) G_GAN: 7.173 G_L1: 21.493 D_real: 0.020 D_fake: 0.004 \n",
            "(epoch: 266, iters: 160, time: 0.023, data: 0.001) G_GAN: 6.624 G_L1: 35.727 D_real: 0.003 D_fake: 0.089 \n",
            "(epoch: 266, iters: 260, time: 0.024, data: 0.001) G_GAN: 4.777 G_L1: 19.443 D_real: 0.157 D_fake: 0.018 \n",
            "End of epoch 266 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 267, iters: 64, time: 0.269, data: 0.002) G_GAN: 6.115 G_L1: 15.099 D_real: 0.107 D_fake: 0.005 \n",
            "(epoch: 267, iters: 164, time: 0.023, data: 0.002) G_GAN: 4.122 G_L1: 16.842 D_real: 1.198 D_fake: 0.009 \n",
            "(epoch: 267, iters: 264, time: 0.029, data: 0.001) G_GAN: 5.888 G_L1: 16.957 D_real: 0.025 D_fake: 0.018 \n",
            "End of epoch 267 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 268, iters: 68, time: 0.024, data: 0.001) G_GAN: 6.641 G_L1: 17.275 D_real: 0.059 D_fake: 0.479 \n",
            "(epoch: 268, iters: 168, time: 0.318, data: 0.001) G_GAN: 5.881 G_L1: 17.653 D_real: 0.061 D_fake: 0.028 \n",
            "(epoch: 268, iters: 268, time: 0.026, data: 0.002) G_GAN: 3.492 G_L1: 16.278 D_real: 0.159 D_fake: 0.141 \n",
            "End of epoch 268 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 269, iters: 72, time: 0.024, data: 0.001) G_GAN: 4.858 G_L1: 19.430 D_real: 0.073 D_fake: 0.219 \n",
            "(epoch: 269, iters: 172, time: 0.023, data: 0.001) G_GAN: 3.455 G_L1: 14.882 D_real: 0.725 D_fake: 0.129 \n",
            "(epoch: 269, iters: 272, time: 0.302, data: 0.001) G_GAN: 5.034 G_L1: 21.861 D_real: 0.003 D_fake: 0.688 \n",
            "End of epoch 269 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 270, iters: 76, time: 0.023, data: 0.002) G_GAN: 4.588 G_L1: 22.684 D_real: 0.246 D_fake: 0.028 \n",
            "(epoch: 270, iters: 176, time: 0.024, data: 0.001) G_GAN: 5.683 G_L1: 16.650 D_real: 0.472 D_fake: 0.001 \n",
            "(epoch: 270, iters: 276, time: 0.023, data: 0.001) G_GAN: 5.602 G_L1: 21.661 D_real: 0.036 D_fake: 0.306 \n",
            "saving the model at the end of epoch 270, iters 79920\n",
            "End of epoch 270 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 271, iters: 80, time: 0.289, data: 0.001) G_GAN: 4.542 G_L1: 18.777 D_real: 0.005 D_fake: 0.085 \n",
            "saving the latest model (epoch 271, total_iters 80000)\n",
            "(epoch: 271, iters: 180, time: 0.024, data: 0.001) G_GAN: 4.982 G_L1: 20.184 D_real: 0.300 D_fake: 0.007 \n",
            "(epoch: 271, iters: 280, time: 0.024, data: 0.001) G_GAN: 5.046 G_L1: 16.909 D_real: 0.115 D_fake: 0.527 \n",
            "End of epoch 271 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 272, iters: 84, time: 0.023, data: 0.002) G_GAN: 5.445 G_L1: 15.202 D_real: 0.034 D_fake: 0.739 \n",
            "(epoch: 272, iters: 184, time: 0.323, data: 0.001) G_GAN: 4.280 G_L1: 18.354 D_real: 0.020 D_fake: 0.094 \n",
            "(epoch: 272, iters: 284, time: 0.024, data: 0.001) G_GAN: 6.237 G_L1: 16.536 D_real: 0.424 D_fake: 0.003 \n",
            "End of epoch 272 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 273, iters: 88, time: 0.023, data: 0.001) G_GAN: 6.051 G_L1: 23.609 D_real: 0.026 D_fake: 0.062 \n",
            "(epoch: 273, iters: 188, time: 0.024, data: 0.001) G_GAN: 5.948 G_L1: 18.930 D_real: 0.020 D_fake: 0.031 \n",
            "(epoch: 273, iters: 288, time: 0.266, data: 0.001) G_GAN: 7.904 G_L1: 16.599 D_real: 0.080 D_fake: 0.001 \n",
            "End of epoch 273 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 274, iters: 92, time: 0.024, data: 0.001) G_GAN: 10.172 G_L1: 18.320 D_real: 0.004 D_fake: 0.970 \n",
            "(epoch: 274, iters: 192, time: 0.030, data: 0.001) G_GAN: 5.530 G_L1: 18.299 D_real: 0.003 D_fake: 0.057 \n",
            "(epoch: 274, iters: 292, time: 0.022, data: 0.001) G_GAN: 5.083 G_L1: 18.836 D_real: 0.003 D_fake: 0.072 \n",
            "End of epoch 274 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 275, iters: 96, time: 0.418, data: 0.001) G_GAN: 6.059 G_L1: 16.555 D_real: 0.094 D_fake: 0.010 \n",
            "(epoch: 275, iters: 196, time: 0.024, data: 0.001) G_GAN: 6.236 G_L1: 22.725 D_real: 0.015 D_fake: 0.006 \n",
            "(epoch: 275, iters: 296, time: 0.023, data: 0.001) G_GAN: 4.789 G_L1: 18.942 D_real: 0.363 D_fake: 0.136 \n",
            "saving the model at the end of epoch 275, iters 81400\n",
            "End of epoch 275 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 276, iters: 100, time: 0.030, data: 0.130) G_GAN: 4.829 G_L1: 16.170 D_real: 0.004 D_fake: 0.060 \n",
            "(epoch: 276, iters: 200, time: 0.703, data: 0.001) G_GAN: 7.506 G_L1: 21.713 D_real: 0.467 D_fake: 0.001 \n",
            "End of epoch 276 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 277, iters: 4, time: 0.024, data: 0.002) G_GAN: 5.191 G_L1: 16.212 D_real: 0.014 D_fake: 0.328 \n",
            "(epoch: 277, iters: 104, time: 0.028, data: 0.000) G_GAN: 5.629 G_L1: 19.176 D_real: 0.018 D_fake: 0.566 \n",
            "(epoch: 277, iters: 204, time: 0.025, data: 0.001) G_GAN: 7.571 G_L1: 18.902 D_real: 0.759 D_fake: 0.003 \n",
            "End of epoch 277 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 278, iters: 8, time: 0.291, data: 0.002) G_GAN: 4.501 G_L1: 15.606 D_real: 0.047 D_fake: 0.042 \n",
            "(epoch: 278, iters: 108, time: 0.029, data: 0.001) G_GAN: 4.493 G_L1: 19.722 D_real: 0.813 D_fake: 0.003 \n",
            "(epoch: 278, iters: 208, time: 0.023, data: 0.001) G_GAN: 5.054 G_L1: 17.303 D_real: 0.003 D_fake: 0.075 \n",
            "End of epoch 278 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 279, iters: 12, time: 0.023, data: 0.001) G_GAN: 5.717 G_L1: 16.858 D_real: 0.009 D_fake: 0.027 \n",
            "(epoch: 279, iters: 112, time: 0.348, data: 0.001) G_GAN: 5.370 G_L1: 17.641 D_real: 0.049 D_fake: 0.011 \n",
            "(epoch: 279, iters: 212, time: 0.024, data: 0.002) G_GAN: 6.046 G_L1: 16.970 D_real: 0.124 D_fake: 0.003 \n",
            "End of epoch 279 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 280, iters: 16, time: 0.029, data: 0.001) G_GAN: 4.380 G_L1: 18.049 D_real: 0.081 D_fake: 0.109 \n",
            "(epoch: 280, iters: 116, time: 0.032, data: 0.001) G_GAN: 6.910 G_L1: 19.746 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 280, iters: 216, time: 0.305, data: 0.002) G_GAN: 4.902 G_L1: 16.095 D_real: 0.123 D_fake: 0.038 \n",
            "saving the model at the end of epoch 280, iters 82880\n",
            "End of epoch 280 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 281, iters: 20, time: 0.023, data: 0.002) G_GAN: 5.688 G_L1: 17.966 D_real: 0.001 D_fake: 0.772 \n",
            "(epoch: 281, iters: 120, time: 0.033, data: 0.001) G_GAN: 8.556 G_L1: 17.021 D_real: 0.006 D_fake: 0.002 \n",
            "(epoch: 281, iters: 220, time: 0.023, data: 0.001) G_GAN: 4.025 G_L1: 19.229 D_real: 0.158 D_fake: 0.098 \n",
            "End of epoch 281 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 282, iters: 24, time: 0.312, data: 0.001) G_GAN: 2.451 G_L1: 19.687 D_real: 0.712 D_fake: 0.049 \n",
            "(epoch: 282, iters: 124, time: 0.023, data: 0.001) G_GAN: 5.588 G_L1: 17.574 D_real: 0.009 D_fake: 0.036 \n",
            "(epoch: 282, iters: 224, time: 0.023, data: 0.001) G_GAN: 8.075 G_L1: 15.645 D_real: 0.102 D_fake: 0.597 \n",
            "End of epoch 282 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 283, iters: 28, time: 0.023, data: 0.001) G_GAN: 5.759 G_L1: 20.484 D_real: 0.175 D_fake: 0.014 \n",
            "(epoch: 283, iters: 128, time: 0.375, data: 0.001) G_GAN: 5.894 G_L1: 18.359 D_real: 0.058 D_fake: 0.563 \n",
            "(epoch: 283, iters: 228, time: 0.024, data: 0.001) G_GAN: 5.479 G_L1: 22.018 D_real: 0.089 D_fake: 0.179 \n",
            "End of epoch 283 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 284, iters: 32, time: 0.029, data: 0.001) G_GAN: 9.066 G_L1: 19.266 D_real: 0.005 D_fake: 0.982 \n",
            "(epoch: 284, iters: 132, time: 0.034, data: 0.001) G_GAN: 4.501 G_L1: 21.329 D_real: 0.588 D_fake: 0.016 \n",
            "(epoch: 284, iters: 232, time: 0.311, data: 0.001) G_GAN: 4.342 G_L1: 19.423 D_real: 0.026 D_fake: 0.110 \n",
            "End of epoch 284 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 285, iters: 36, time: 0.023, data: 0.002) G_GAN: 5.556 G_L1: 16.456 D_real: 0.030 D_fake: 0.652 \n",
            "(epoch: 285, iters: 136, time: 0.023, data: 0.001) G_GAN: 9.000 G_L1: 20.496 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 285, iters: 236, time: 0.024, data: 0.001) G_GAN: 6.844 G_L1: 20.339 D_real: 0.014 D_fake: 0.008 \n",
            "saving the model at the end of epoch 285, iters 84360\n",
            "End of epoch 285 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 286, iters: 40, time: 0.441, data: 0.001) G_GAN: 4.421 G_L1: 17.290 D_real: 0.002 D_fake: 0.082 \n",
            "(epoch: 286, iters: 140, time: 0.024, data: 0.002) G_GAN: 4.219 G_L1: 14.174 D_real: 0.103 D_fake: 0.066 \n",
            "(epoch: 286, iters: 240, time: 0.025, data: 0.001) G_GAN: 5.575 G_L1: 22.260 D_real: 0.026 D_fake: 0.063 \n",
            "End of epoch 286 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 287, iters: 44, time: 0.024, data: 0.001) G_GAN: 6.079 G_L1: 16.111 D_real: 0.233 D_fake: 0.049 \n",
            "(epoch: 287, iters: 144, time: 0.351, data: 0.002) G_GAN: 6.338 G_L1: 16.634 D_real: 0.001 D_fake: 0.807 \n",
            "(epoch: 287, iters: 244, time: 0.023, data: 0.002) G_GAN: 6.095 G_L1: 20.214 D_real: 0.000 D_fake: 0.005 \n",
            "End of epoch 287 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 288, iters: 48, time: 0.024, data: 0.001) G_GAN: 3.840 G_L1: 13.510 D_real: 0.651 D_fake: 0.026 \n",
            "saving the latest model (epoch 288, total_iters 85000)\n",
            "(epoch: 288, iters: 148, time: 0.024, data: 0.002) G_GAN: 3.589 G_L1: 19.649 D_real: 0.352 D_fake: 0.025 \n",
            "(epoch: 288, iters: 248, time: 0.292, data: 0.001) G_GAN: 4.367 G_L1: 18.416 D_real: 0.157 D_fake: 0.034 \n",
            "End of epoch 288 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 289, iters: 52, time: 0.023, data: 0.002) G_GAN: 5.263 G_L1: 15.029 D_real: 0.038 D_fake: 0.065 \n",
            "(epoch: 289, iters: 152, time: 0.024, data: 0.001) G_GAN: 4.761 G_L1: 21.577 D_real: 0.068 D_fake: 0.285 \n",
            "(epoch: 289, iters: 252, time: 0.024, data: 0.001) G_GAN: 7.214 G_L1: 20.670 D_real: 0.039 D_fake: 0.022 \n",
            "End of epoch 289 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 290, iters: 56, time: 0.345, data: 0.001) G_GAN: 4.054 G_L1: 15.729 D_real: 0.086 D_fake: 0.078 \n",
            "(epoch: 290, iters: 156, time: 0.024, data: 0.001) G_GAN: 2.769 G_L1: 15.831 D_real: 0.339 D_fake: 0.139 \n",
            "(epoch: 290, iters: 256, time: 0.025, data: 0.001) G_GAN: 3.769 G_L1: 25.538 D_real: 0.488 D_fake: 0.050 \n",
            "saving the model at the end of epoch 290, iters 85840\n",
            "End of epoch 290 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 291, iters: 60, time: 0.024, data: 0.001) G_GAN: 5.759 G_L1: 14.755 D_real: 0.014 D_fake: 0.017 \n",
            "(epoch: 291, iters: 160, time: 0.300, data: 0.001) G_GAN: 7.730 G_L1: 20.231 D_real: 0.014 D_fake: 0.004 \n",
            "(epoch: 291, iters: 260, time: 0.023, data: 0.001) G_GAN: 5.644 G_L1: 16.210 D_real: 0.031 D_fake: 0.057 \n",
            "End of epoch 291 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 292, iters: 64, time: 0.030, data: 0.001) G_GAN: 7.465 G_L1: 21.697 D_real: 0.084 D_fake: 0.004 \n",
            "(epoch: 292, iters: 164, time: 0.023, data: 0.001) G_GAN: 7.779 G_L1: 21.576 D_real: 0.159 D_fake: 0.002 \n",
            "(epoch: 292, iters: 264, time: 0.287, data: 0.001) G_GAN: 5.656 G_L1: 16.174 D_real: 0.057 D_fake: 0.689 \n",
            "End of epoch 292 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 293, iters: 68, time: 0.023, data: 0.002) G_GAN: 7.840 G_L1: 18.335 D_real: 0.008 D_fake: 0.002 \n",
            "(epoch: 293, iters: 168, time: 0.031, data: 0.001) G_GAN: 7.435 G_L1: 24.707 D_real: 0.000 D_fake: 0.009 \n",
            "(epoch: 293, iters: 268, time: 0.025, data: 0.001) G_GAN: 8.040 G_L1: 19.504 D_real: 0.026 D_fake: 0.001 \n",
            "End of epoch 293 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 294, iters: 72, time: 0.359, data: 0.001) G_GAN: 5.521 G_L1: 18.211 D_real: 0.016 D_fake: 0.020 \n",
            "(epoch: 294, iters: 172, time: 0.025, data: 0.002) G_GAN: 4.327 G_L1: 15.236 D_real: 0.037 D_fake: 0.041 \n",
            "(epoch: 294, iters: 272, time: 0.025, data: 0.001) G_GAN: 5.246 G_L1: 14.904 D_real: 0.056 D_fake: 0.049 \n",
            "End of epoch 294 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 295, iters: 76, time: 0.024, data: 0.002) G_GAN: 5.390 G_L1: 13.963 D_real: 0.024 D_fake: 0.017 \n",
            "(epoch: 295, iters: 176, time: 0.309, data: 0.001) G_GAN: 4.132 G_L1: 21.711 D_real: 0.021 D_fake: 0.066 \n",
            "(epoch: 295, iters: 276, time: 0.031, data: 0.001) G_GAN: 5.426 G_L1: 21.689 D_real: 0.008 D_fake: 0.032 \n",
            "saving the model at the end of epoch 295, iters 87320\n",
            "End of epoch 295 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 296, iters: 80, time: 0.027, data: 0.001) G_GAN: 3.448 G_L1: 20.259 D_real: 0.459 D_fake: 0.023 \n",
            "(epoch: 296, iters: 180, time: 0.023, data: 0.001) G_GAN: 9.513 G_L1: 26.624 D_real: 0.034 D_fake: 0.001 \n",
            "(epoch: 296, iters: 280, time: 0.440, data: 0.001) G_GAN: 7.040 G_L1: 16.073 D_real: 0.565 D_fake: 0.003 \n",
            "End of epoch 296 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 297, iters: 84, time: 0.030, data: 0.001) G_GAN: 11.260 G_L1: 29.517 D_real: 0.002 D_fake: 0.000 \n",
            "(epoch: 297, iters: 184, time: 0.024, data: 0.001) G_GAN: 6.968 G_L1: 24.902 D_real: 0.242 D_fake: 0.010 \n",
            "(epoch: 297, iters: 284, time: 0.023, data: 0.001) G_GAN: 3.586 G_L1: 18.180 D_real: 0.281 D_fake: 0.036 \n",
            "End of epoch 297 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 298, iters: 88, time: 0.315, data: 0.001) G_GAN: 6.700 G_L1: 15.698 D_real: 0.000 D_fake: 0.956 \n",
            "(epoch: 298, iters: 188, time: 0.025, data: 0.001) G_GAN: 5.039 G_L1: 15.308 D_real: 0.039 D_fake: 0.207 \n",
            "(epoch: 298, iters: 288, time: 0.024, data: 0.001) G_GAN: 5.228 G_L1: 17.362 D_real: 0.048 D_fake: 0.015 \n",
            "End of epoch 298 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 299, iters: 92, time: 0.023, data: 0.001) G_GAN: 4.095 G_L1: 15.944 D_real: 0.049 D_fake: 0.066 \n",
            "(epoch: 299, iters: 192, time: 0.290, data: 0.001) G_GAN: 5.786 G_L1: 18.911 D_real: 0.003 D_fake: 0.040 \n",
            "(epoch: 299, iters: 292, time: 0.023, data: 0.002) G_GAN: 7.004 G_L1: 17.130 D_real: 0.104 D_fake: 0.004 \n",
            "End of epoch 299 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 300, iters: 96, time: 0.023, data: 0.001) G_GAN: 7.327 G_L1: 15.970 D_real: 0.026 D_fake: 0.830 \n",
            "(epoch: 300, iters: 196, time: 0.024, data: 0.001) G_GAN: 3.835 G_L1: 13.740 D_real: 0.073 D_fake: 0.052 \n",
            "(epoch: 300, iters: 296, time: 0.354, data: 0.001) G_GAN: 5.316 G_L1: 16.545 D_real: 0.017 D_fake: 0.101 \n",
            "saving the model at the end of epoch 300, iters 88800\n",
            "End of epoch 300 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0001993\n",
            "(epoch: 301, iters: 100, time: 0.027, data: 0.110) G_GAN: 4.609 G_L1: 16.003 D_real: 0.033 D_fake: 0.344 \n",
            "(epoch: 301, iters: 200, time: 0.030, data: 0.001) G_GAN: 5.791 G_L1: 17.498 D_real: 0.019 D_fake: 0.538 \n",
            "End of epoch 301 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001987\n",
            "(epoch: 302, iters: 4, time: 0.031, data: 0.001) G_GAN: 2.006 G_L1: 15.551 D_real: 1.036 D_fake: 0.012 \n",
            "(epoch: 302, iters: 104, time: 0.322, data: 0.000) G_GAN: 7.418 G_L1: 18.191 D_real: 0.019 D_fake: 0.004 \n",
            "(epoch: 302, iters: 204, time: 0.024, data: 0.001) G_GAN: 5.610 G_L1: 17.641 D_real: 0.027 D_fake: 0.055 \n",
            "End of epoch 302 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001980\n",
            "(epoch: 303, iters: 8, time: 0.029, data: 0.001) G_GAN: 7.601 G_L1: 16.920 D_real: 0.487 D_fake: 0.001 \n",
            "(epoch: 303, iters: 108, time: 0.024, data: 0.000) G_GAN: 6.023 G_L1: 15.954 D_real: 0.011 D_fake: 0.326 \n",
            "(epoch: 303, iters: 208, time: 0.383, data: 0.001) G_GAN: 4.916 G_L1: 19.694 D_real: 0.225 D_fake: 0.022 \n",
            "End of epoch 303 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001973\n",
            "(epoch: 304, iters: 12, time: 0.029, data: 0.001) G_GAN: 4.084 G_L1: 15.379 D_real: 1.242 D_fake: 0.006 \n",
            "(epoch: 304, iters: 112, time: 0.024, data: 0.001) G_GAN: 9.722 G_L1: 20.433 D_real: 0.002 D_fake: 0.678 \n",
            "(epoch: 304, iters: 212, time: 0.024, data: 0.001) G_GAN: 5.812 G_L1: 18.665 D_real: 0.016 D_fake: 0.029 \n",
            "End of epoch 304 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001967\n",
            "(epoch: 305, iters: 16, time: 0.309, data: 0.001) G_GAN: 5.361 G_L1: 18.023 D_real: 0.263 D_fake: 0.007 \n",
            "saving the latest model (epoch 305, total_iters 90000)\n",
            "(epoch: 305, iters: 116, time: 0.030, data: 0.001) G_GAN: 8.744 G_L1: 26.795 D_real: 0.001 D_fake: 0.002 \n",
            "(epoch: 305, iters: 216, time: 0.024, data: 0.001) G_GAN: 5.425 G_L1: 14.531 D_real: 0.035 D_fake: 0.016 \n",
            "saving the model at the end of epoch 305, iters 90280\n",
            "End of epoch 305 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0001960\n",
            "(epoch: 306, iters: 20, time: 0.034, data: 0.001) G_GAN: 4.650 G_L1: 17.962 D_real: 0.089 D_fake: 0.082 \n",
            "(epoch: 306, iters: 120, time: 0.292, data: 0.002) G_GAN: 5.109 G_L1: 15.219 D_real: 0.524 D_fake: 0.003 \n",
            "(epoch: 306, iters: 220, time: 0.024, data: 0.001) G_GAN: 6.023 G_L1: 21.578 D_real: 0.021 D_fake: 0.276 \n",
            "End of epoch 306 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0001953\n",
            "(epoch: 307, iters: 24, time: 0.029, data: 0.001) G_GAN: 6.399 G_L1: 23.860 D_real: 0.000 D_fake: 0.024 \n",
            "(epoch: 307, iters: 124, time: 0.023, data: 0.001) G_GAN: 6.977 G_L1: 19.344 D_real: 0.064 D_fake: 0.526 \n",
            "(epoch: 307, iters: 224, time: 0.349, data: 0.001) G_GAN: 5.298 G_L1: 22.792 D_real: 0.012 D_fake: 0.093 \n",
            "End of epoch 307 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001947\n",
            "(epoch: 308, iters: 28, time: 0.031, data: 0.001) G_GAN: 7.698 G_L1: 19.330 D_real: 0.082 D_fake: 0.002 \n",
            "(epoch: 308, iters: 128, time: 0.024, data: 0.001) G_GAN: 4.576 G_L1: 16.279 D_real: 0.005 D_fake: 0.027 \n",
            "(epoch: 308, iters: 228, time: 0.023, data: 0.001) G_GAN: 3.411 G_L1: 16.286 D_real: 3.828 D_fake: 0.000 \n",
            "End of epoch 308 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001940\n",
            "(epoch: 309, iters: 32, time: 0.439, data: 0.001) G_GAN: 6.699 G_L1: 20.232 D_real: 0.036 D_fake: 0.005 \n",
            "(epoch: 309, iters: 132, time: 0.032, data: 0.002) G_GAN: 5.828 G_L1: 16.637 D_real: 0.130 D_fake: 0.022 \n",
            "(epoch: 309, iters: 232, time: 0.031, data: 0.002) G_GAN: 6.687 G_L1: 14.234 D_real: 0.130 D_fake: 0.005 \n",
            "End of epoch 309 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001934\n",
            "(epoch: 310, iters: 36, time: 0.024, data: 0.001) G_GAN: 3.926 G_L1: 17.656 D_real: 0.015 D_fake: 0.068 \n",
            "(epoch: 310, iters: 136, time: 0.348, data: 0.001) G_GAN: 6.357 G_L1: 20.751 D_real: 0.009 D_fake: 0.010 \n",
            "(epoch: 310, iters: 236, time: 0.033, data: 0.001) G_GAN: 8.000 G_L1: 14.090 D_real: 0.000 D_fake: 0.821 \n",
            "saving the model at the end of epoch 310, iters 91760\n",
            "End of epoch 310 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001927\n",
            "(epoch: 311, iters: 40, time: 0.023, data: 0.001) G_GAN: 4.264 G_L1: 16.389 D_real: 0.008 D_fake: 0.113 \n",
            "(epoch: 311, iters: 140, time: 0.024, data: 0.001) G_GAN: 5.049 G_L1: 17.308 D_real: 0.069 D_fake: 0.295 \n",
            "(epoch: 311, iters: 240, time: 0.313, data: 0.002) G_GAN: 5.073 G_L1: 15.683 D_real: 0.012 D_fake: 0.044 \n",
            "End of epoch 311 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001920\n",
            "(epoch: 312, iters: 44, time: 0.023, data: 0.001) G_GAN: 8.484 G_L1: 16.756 D_real: 0.001 D_fake: 1.030 \n",
            "(epoch: 312, iters: 144, time: 0.025, data: 0.001) G_GAN: 4.385 G_L1: 15.417 D_real: 0.142 D_fake: 0.184 \n",
            "(epoch: 312, iters: 244, time: 0.024, data: 0.002) G_GAN: 3.720 G_L1: 18.431 D_real: 0.025 D_fake: 0.030 \n",
            "End of epoch 312 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001914\n",
            "(epoch: 313, iters: 48, time: 0.304, data: 0.001) G_GAN: 4.139 G_L1: 16.418 D_real: 0.137 D_fake: 0.022 \n",
            "(epoch: 313, iters: 148, time: 0.023, data: 0.002) G_GAN: 8.867 G_L1: 21.108 D_real: 0.011 D_fake: 0.001 \n",
            "(epoch: 313, iters: 248, time: 0.023, data: 0.001) G_GAN: 4.868 G_L1: 19.586 D_real: 0.312 D_fake: 0.099 \n",
            "End of epoch 313 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001907\n",
            "(epoch: 314, iters: 52, time: 0.024, data: 0.001) G_GAN: 5.088 G_L1: 17.078 D_real: 0.004 D_fake: 0.018 \n",
            "(epoch: 314, iters: 152, time: 0.345, data: 0.001) G_GAN: 4.188 G_L1: 17.400 D_real: 0.067 D_fake: 0.063 \n",
            "(epoch: 314, iters: 252, time: 0.024, data: 0.001) G_GAN: 12.243 G_L1: 20.004 D_real: 1.003 D_fake: 0.000 \n",
            "End of epoch 314 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001900\n",
            "(epoch: 315, iters: 56, time: 0.025, data: 0.001) G_GAN: 3.949 G_L1: 17.090 D_real: 0.016 D_fake: 0.062 \n",
            "(epoch: 315, iters: 156, time: 0.023, data: 0.001) G_GAN: 6.724 G_L1: 15.487 D_real: 0.014 D_fake: 0.005 \n",
            "(epoch: 315, iters: 256, time: 0.292, data: 0.001) G_GAN: 5.118 G_L1: 17.928 D_real: 0.004 D_fake: 0.215 \n",
            "saving the model at the end of epoch 315, iters 93240\n",
            "End of epoch 315 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001894\n",
            "(epoch: 316, iters: 60, time: 0.027, data: 0.001) G_GAN: 5.434 G_L1: 22.883 D_real: 0.001 D_fake: 0.052 \n",
            "(epoch: 316, iters: 160, time: 0.024, data: 0.001) G_GAN: 9.668 G_L1: 15.511 D_real: 0.604 D_fake: 0.000 \n",
            "(epoch: 316, iters: 260, time: 0.041, data: 0.001) G_GAN: 5.431 G_L1: 15.422 D_real: 0.020 D_fake: 0.381 \n",
            "End of epoch 316 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001887\n",
            "(epoch: 317, iters: 64, time: 0.383, data: 0.005) G_GAN: 4.636 G_L1: 14.444 D_real: 0.004 D_fake: 0.301 \n",
            "(epoch: 317, iters: 164, time: 0.026, data: 0.002) G_GAN: 3.937 G_L1: 13.463 D_real: 0.041 D_fake: 0.074 \n",
            "(epoch: 317, iters: 264, time: 0.023, data: 0.002) G_GAN: 8.913 G_L1: 17.051 D_real: 0.120 D_fake: 0.001 \n",
            "End of epoch 317 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001880\n",
            "(epoch: 318, iters: 68, time: 0.025, data: 0.001) G_GAN: 2.666 G_L1: 15.781 D_real: 0.420 D_fake: 0.036 \n",
            "(epoch: 318, iters: 168, time: 0.300, data: 0.001) G_GAN: 6.497 G_L1: 17.118 D_real: 0.043 D_fake: 0.022 \n",
            "(epoch: 318, iters: 268, time: 0.024, data: 0.001) G_GAN: 5.636 G_L1: 15.836 D_real: 0.014 D_fake: 0.018 \n",
            "End of epoch 318 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001874\n",
            "(epoch: 319, iters: 72, time: 0.023, data: 0.001) G_GAN: 6.095 G_L1: 15.598 D_real: 0.011 D_fake: 0.014 \n",
            "(epoch: 319, iters: 172, time: 0.032, data: 0.001) G_GAN: 5.411 G_L1: 26.411 D_real: 0.002 D_fake: 0.057 \n",
            "(epoch: 319, iters: 272, time: 0.366, data: 0.001) G_GAN: 6.632 G_L1: 22.169 D_real: 0.011 D_fake: 0.096 \n",
            "End of epoch 319 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001867\n",
            "(epoch: 320, iters: 76, time: 0.023, data: 0.001) G_GAN: 6.307 G_L1: 15.590 D_real: 0.076 D_fake: 0.011 \n",
            "(epoch: 320, iters: 176, time: 0.028, data: 0.001) G_GAN: 3.595 G_L1: 18.262 D_real: 0.000 D_fake: 0.229 \n",
            "(epoch: 320, iters: 276, time: 0.026, data: 0.001) G_GAN: 8.707 G_L1: 25.480 D_real: 0.012 D_fake: 0.002 \n",
            "saving the model at the end of epoch 320, iters 94720\n",
            "End of epoch 320 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0001860\n",
            "(epoch: 321, iters: 80, time: 0.338, data: 0.001) G_GAN: 4.638 G_L1: 16.103 D_real: 0.001 D_fake: 0.119 \n",
            "(epoch: 321, iters: 180, time: 0.033, data: 0.001) G_GAN: 10.063 G_L1: 18.916 D_real: 0.483 D_fake: 0.001 \n",
            "(epoch: 321, iters: 280, time: 0.023, data: 0.001) G_GAN: 6.668 G_L1: 18.415 D_real: 0.011 D_fake: 0.327 \n",
            "saving the latest model (epoch 321, total_iters 95000)\n",
            "End of epoch 321 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0001854\n",
            "(epoch: 322, iters: 84, time: 0.023, data: 0.002) G_GAN: 5.274 G_L1: 19.041 D_real: 0.002 D_fake: 0.233 \n",
            "(epoch: 322, iters: 184, time: 0.393, data: 0.001) G_GAN: 6.021 G_L1: 15.861 D_real: 0.008 D_fake: 0.008 \n",
            "(epoch: 322, iters: 284, time: 0.024, data: 0.003) G_GAN: 5.167 G_L1: 21.957 D_real: 0.017 D_fake: 0.012 \n",
            "End of epoch 322 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001847\n",
            "(epoch: 323, iters: 88, time: 0.025, data: 0.001) G_GAN: 7.085 G_L1: 14.226 D_real: 0.070 D_fake: 0.010 \n",
            "(epoch: 323, iters: 188, time: 0.026, data: 0.001) G_GAN: 5.601 G_L1: 16.419 D_real: 0.040 D_fake: 0.364 \n",
            "(epoch: 323, iters: 288, time: 0.364, data: 0.002) G_GAN: 4.250 G_L1: 15.551 D_real: 0.429 D_fake: 0.015 \n",
            "End of epoch 323 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001841\n",
            "(epoch: 324, iters: 92, time: 0.028, data: 0.001) G_GAN: 6.471 G_L1: 15.906 D_real: 0.167 D_fake: 0.008 \n",
            "(epoch: 324, iters: 192, time: 0.023, data: 0.001) G_GAN: 5.283 G_L1: 12.803 D_real: 0.044 D_fake: 0.017 \n",
            "(epoch: 324, iters: 292, time: 0.022, data: 0.001) G_GAN: 7.243 G_L1: 13.303 D_real: 0.056 D_fake: 0.005 \n",
            "End of epoch 324 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001834\n",
            "(epoch: 325, iters: 96, time: 0.311, data: 0.001) G_GAN: 6.874 G_L1: 17.159 D_real: 0.048 D_fake: 0.003 \n",
            "(epoch: 325, iters: 196, time: 0.026, data: 0.001) G_GAN: 6.811 G_L1: 16.230 D_real: 0.310 D_fake: 0.005 \n",
            "(epoch: 325, iters: 296, time: 0.022, data: 0.001) G_GAN: 3.931 G_L1: 15.104 D_real: 0.032 D_fake: 0.149 \n",
            "saving the model at the end of epoch 325, iters 96200\n",
            "End of epoch 325 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0001827\n",
            "(epoch: 326, iters: 100, time: 0.024, data: 0.126) G_GAN: 4.913 G_L1: 19.300 D_real: 0.067 D_fake: 0.024 \n",
            "(epoch: 326, iters: 200, time: 0.649, data: 0.001) G_GAN: 4.961 G_L1: 15.413 D_real: 0.171 D_fake: 0.015 \n",
            "End of epoch 326 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001821\n",
            "(epoch: 327, iters: 4, time: 0.024, data: 0.005) G_GAN: 4.793 G_L1: 18.908 D_real: 0.643 D_fake: 0.003 \n",
            "(epoch: 327, iters: 104, time: 0.028, data: 0.000) G_GAN: 4.177 G_L1: 16.008 D_real: 0.267 D_fake: 0.008 \n",
            "(epoch: 327, iters: 204, time: 0.031, data: 0.002) G_GAN: 5.251 G_L1: 17.722 D_real: 0.002 D_fake: 0.020 \n",
            "End of epoch 327 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001814\n",
            "(epoch: 328, iters: 8, time: 0.315, data: 0.002) G_GAN: 5.351 G_L1: 16.008 D_real: 0.003 D_fake: 0.139 \n",
            "(epoch: 328, iters: 108, time: 0.023, data: 0.001) G_GAN: 3.860 G_L1: 21.637 D_real: 0.057 D_fake: 0.107 \n",
            "(epoch: 328, iters: 208, time: 0.023, data: 0.001) G_GAN: 6.764 G_L1: 17.252 D_real: 0.015 D_fake: 0.009 \n",
            "End of epoch 328 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001807\n",
            "(epoch: 329, iters: 12, time: 0.024, data: 0.001) G_GAN: 9.064 G_L1: 21.638 D_real: 0.204 D_fake: 0.001 \n",
            "(epoch: 329, iters: 112, time: 0.502, data: 0.001) G_GAN: 7.964 G_L1: 16.343 D_real: 0.001 D_fake: 0.003 \n",
            "(epoch: 329, iters: 212, time: 0.027, data: 0.001) G_GAN: 7.031 G_L1: 19.818 D_real: 0.048 D_fake: 0.007 \n",
            "End of epoch 329 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001801\n",
            "(epoch: 330, iters: 16, time: 0.024, data: 0.001) G_GAN: 4.166 G_L1: 14.342 D_real: 0.131 D_fake: 0.158 \n",
            "(epoch: 330, iters: 116, time: 0.023, data: 0.001) G_GAN: 7.709 G_L1: 16.895 D_real: 0.057 D_fake: 0.002 \n",
            "(epoch: 330, iters: 216, time: 0.344, data: 0.001) G_GAN: 8.383 G_L1: 18.510 D_real: 0.015 D_fake: 0.796 \n",
            "saving the model at the end of epoch 330, iters 97680\n",
            "End of epoch 330 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001794\n",
            "(epoch: 331, iters: 20, time: 0.028, data: 0.002) G_GAN: 5.766 G_L1: 16.086 D_real: 0.003 D_fake: 0.017 \n",
            "(epoch: 331, iters: 120, time: 0.024, data: 0.001) G_GAN: 3.144 G_L1: 14.750 D_real: 0.767 D_fake: 0.011 \n",
            "(epoch: 331, iters: 220, time: 0.025, data: 0.001) G_GAN: 5.988 G_L1: 25.121 D_real: 0.041 D_fake: 0.026 \n",
            "End of epoch 331 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001787\n",
            "(epoch: 332, iters: 24, time: 0.313, data: 0.001) G_GAN: 4.566 G_L1: 15.608 D_real: 0.078 D_fake: 0.256 \n",
            "(epoch: 332, iters: 124, time: 0.024, data: 0.002) G_GAN: 3.543 G_L1: 19.006 D_real: 0.755 D_fake: 0.007 \n",
            "(epoch: 332, iters: 224, time: 0.029, data: 0.001) G_GAN: 4.956 G_L1: 16.776 D_real: 0.187 D_fake: 0.300 \n",
            "End of epoch 332 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001781\n",
            "(epoch: 333, iters: 28, time: 0.025, data: 0.001) G_GAN: 6.041 G_L1: 17.920 D_real: 0.036 D_fake: 0.014 \n",
            "(epoch: 333, iters: 128, time: 0.379, data: 0.001) G_GAN: 6.594 G_L1: 21.747 D_real: 0.170 D_fake: 0.019 \n",
            "(epoch: 333, iters: 228, time: 0.030, data: 0.001) G_GAN: 5.488 G_L1: 15.498 D_real: 0.004 D_fake: 0.171 \n",
            "End of epoch 333 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001774\n",
            "(epoch: 334, iters: 32, time: 0.023, data: 0.001) G_GAN: 6.514 G_L1: 17.692 D_real: 0.022 D_fake: 0.069 \n",
            "(epoch: 334, iters: 132, time: 0.025, data: 0.001) G_GAN: 4.867 G_L1: 16.764 D_real: 0.018 D_fake: 0.018 \n",
            "(epoch: 334, iters: 232, time: 0.320, data: 0.001) G_GAN: 4.467 G_L1: 11.907 D_real: 0.020 D_fake: 0.094 \n",
            "End of epoch 334 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001767\n",
            "(epoch: 335, iters: 36, time: 0.025, data: 0.001) G_GAN: 5.206 G_L1: 15.391 D_real: 0.102 D_fake: 0.021 \n",
            "(epoch: 335, iters: 136, time: 0.023, data: 0.001) G_GAN: 4.857 G_L1: 13.784 D_real: 0.185 D_fake: 0.014 \n",
            "(epoch: 335, iters: 236, time: 0.029, data: 0.001) G_GAN: 5.479 G_L1: 16.684 D_real: 0.001 D_fake: 0.252 \n",
            "saving the model at the end of epoch 335, iters 99160\n",
            "End of epoch 335 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001761\n",
            "(epoch: 336, iters: 40, time: 0.368, data: 0.001) G_GAN: 4.864 G_L1: 16.827 D_real: 0.043 D_fake: 0.050 \n",
            "(epoch: 336, iters: 140, time: 0.029, data: 0.001) G_GAN: 8.597 G_L1: 15.361 D_real: 0.005 D_fake: 0.001 \n",
            "(epoch: 336, iters: 240, time: 0.023, data: 0.001) G_GAN: 7.495 G_L1: 19.594 D_real: 0.014 D_fake: 0.543 \n",
            "End of epoch 336 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001754\n",
            "(epoch: 337, iters: 44, time: 0.024, data: 0.001) G_GAN: 5.581 G_L1: 19.646 D_real: 0.023 D_fake: 0.069 \n",
            "(epoch: 337, iters: 144, time: 0.446, data: 0.001) G_GAN: 5.073 G_L1: 15.820 D_real: 0.001 D_fake: 0.457 \n",
            "(epoch: 337, iters: 244, time: 0.025, data: 0.001) G_GAN: 5.685 G_L1: 15.405 D_real: 0.019 D_fake: 0.005 \n",
            "End of epoch 337 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001748\n",
            "(epoch: 338, iters: 48, time: 0.023, data: 0.001) G_GAN: 6.048 G_L1: 17.558 D_real: 0.125 D_fake: 0.046 \n",
            "(epoch: 338, iters: 148, time: 0.029, data: 0.001) G_GAN: 5.237 G_L1: 19.125 D_real: 0.060 D_fake: 0.141 \n",
            "(epoch: 338, iters: 248, time: 0.369, data: 0.001) G_GAN: 5.701 G_L1: 25.405 D_real: 0.004 D_fake: 0.024 \n",
            "saving the latest model (epoch 338, total_iters 100000)\n",
            "End of epoch 338 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001741\n",
            "(epoch: 339, iters: 52, time: 0.030, data: 0.001) G_GAN: 4.964 G_L1: 15.088 D_real: 0.016 D_fake: 0.021 \n",
            "(epoch: 339, iters: 152, time: 0.023, data: 0.001) G_GAN: 7.163 G_L1: 15.044 D_real: 0.486 D_fake: 0.004 \n",
            "(epoch: 339, iters: 252, time: 0.023, data: 0.001) G_GAN: 6.048 G_L1: 16.536 D_real: 0.021 D_fake: 0.267 \n",
            "End of epoch 339 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001734\n",
            "(epoch: 340, iters: 56, time: 0.389, data: 0.001) G_GAN: 6.088 G_L1: 22.636 D_real: 0.005 D_fake: 0.010 \n",
            "(epoch: 340, iters: 156, time: 0.025, data: 0.002) G_GAN: 4.811 G_L1: 17.642 D_real: 0.016 D_fake: 0.060 \n",
            "(epoch: 340, iters: 256, time: 0.040, data: 0.001) G_GAN: 4.749 G_L1: 16.357 D_real: 0.007 D_fake: 0.208 \n",
            "saving the model at the end of epoch 340, iters 100640\n",
            "End of epoch 340 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001728\n",
            "(epoch: 341, iters: 60, time: 0.023, data: 0.001) G_GAN: 8.432 G_L1: 18.075 D_real: 0.103 D_fake: 0.001 \n",
            "(epoch: 341, iters: 160, time: 0.392, data: 0.001) G_GAN: 8.861 G_L1: 14.419 D_real: 0.005 D_fake: 0.002 \n",
            "(epoch: 341, iters: 260, time: 0.025, data: 0.001) G_GAN: 4.515 G_L1: 16.620 D_real: 0.609 D_fake: 0.028 \n",
            "End of epoch 341 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001721\n",
            "(epoch: 342, iters: 64, time: 0.024, data: 0.001) G_GAN: 5.851 G_L1: 19.708 D_real: 0.000 D_fake: 0.482 \n",
            "(epoch: 342, iters: 164, time: 0.027, data: 0.004) G_GAN: 5.330 G_L1: 19.751 D_real: 0.582 D_fake: 0.002 \n",
            "(epoch: 342, iters: 264, time: 0.469, data: 0.001) G_GAN: 5.945 G_L1: 19.447 D_real: 0.015 D_fake: 0.013 \n",
            "End of epoch 342 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001714\n",
            "(epoch: 343, iters: 68, time: 0.023, data: 0.002) G_GAN: 8.643 G_L1: 17.613 D_real: 0.001 D_fake: 0.003 \n",
            "(epoch: 343, iters: 168, time: 0.029, data: 0.001) G_GAN: 7.748 G_L1: 17.147 D_real: 0.072 D_fake: 0.002 \n",
            "(epoch: 343, iters: 268, time: 0.024, data: 0.001) G_GAN: 5.806 G_L1: 16.674 D_real: 0.052 D_fake: 0.034 \n",
            "End of epoch 343 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001708\n",
            "(epoch: 344, iters: 72, time: 0.390, data: 0.001) G_GAN: 8.094 G_L1: 18.726 D_real: 0.009 D_fake: 0.007 \n",
            "(epoch: 344, iters: 172, time: 0.029, data: 0.002) G_GAN: 6.912 G_L1: 21.434 D_real: 0.021 D_fake: 0.013 \n",
            "(epoch: 344, iters: 272, time: 0.030, data: 0.001) G_GAN: 5.791 G_L1: 16.123 D_real: 0.050 D_fake: 0.008 \n",
            "End of epoch 344 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001701\n",
            "(epoch: 345, iters: 76, time: 0.023, data: 0.001) G_GAN: 0.601 G_L1: 13.185 D_real: 1.830 D_fake: 0.023 \n",
            "(epoch: 345, iters: 176, time: 0.317, data: 0.002) G_GAN: 4.908 G_L1: 13.852 D_real: 0.070 D_fake: 0.113 \n",
            "(epoch: 345, iters: 276, time: 0.024, data: 0.001) G_GAN: 6.844 G_L1: 16.706 D_real: 0.014 D_fake: 0.056 \n",
            "saving the model at the end of epoch 345, iters 102120\n",
            "End of epoch 345 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0001694\n",
            "(epoch: 346, iters: 80, time: 0.023, data: 0.001) G_GAN: 5.230 G_L1: 16.635 D_real: 0.416 D_fake: 0.010 \n",
            "(epoch: 346, iters: 180, time: 0.023, data: 0.001) G_GAN: 5.819 G_L1: 17.025 D_real: 0.021 D_fake: 0.048 \n",
            "(epoch: 346, iters: 280, time: 0.325, data: 0.001) G_GAN: 6.652 G_L1: 19.858 D_real: 0.018 D_fake: 0.012 \n",
            "End of epoch 346 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001688\n",
            "(epoch: 347, iters: 84, time: 0.029, data: 0.001) G_GAN: 4.642 G_L1: 15.734 D_real: 0.003 D_fake: 0.027 \n",
            "(epoch: 347, iters: 184, time: 0.024, data: 0.001) G_GAN: 6.369 G_L1: 16.315 D_real: 0.004 D_fake: 0.808 \n",
            "(epoch: 347, iters: 284, time: 0.024, data: 0.001) G_GAN: 4.132 G_L1: 19.967 D_real: 0.366 D_fake: 0.122 \n",
            "End of epoch 347 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001681\n",
            "(epoch: 348, iters: 88, time: 0.390, data: 0.001) G_GAN: 4.399 G_L1: 20.889 D_real: 0.006 D_fake: 0.014 \n",
            "(epoch: 348, iters: 188, time: 0.025, data: 0.001) G_GAN: 8.101 G_L1: 25.045 D_real: 0.014 D_fake: 0.051 \n",
            "(epoch: 348, iters: 288, time: 0.023, data: 0.001) G_GAN: 7.143 G_L1: 19.239 D_real: 0.021 D_fake: 0.002 \n",
            "End of epoch 348 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001674\n",
            "(epoch: 349, iters: 92, time: 0.023, data: 0.001) G_GAN: 2.573 G_L1: 14.875 D_real: 0.761 D_fake: 0.114 \n",
            "(epoch: 349, iters: 192, time: 0.326, data: 0.001) G_GAN: 5.496 G_L1: 16.538 D_real: 0.326 D_fake: 0.008 \n",
            "(epoch: 349, iters: 292, time: 0.022, data: 0.001) G_GAN: 5.737 G_L1: 14.927 D_real: 0.033 D_fake: 0.039 \n",
            "End of epoch 349 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001668\n",
            "(epoch: 350, iters: 96, time: 0.030, data: 0.001) G_GAN: 5.673 G_L1: 19.952 D_real: 0.003 D_fake: 0.034 \n",
            "(epoch: 350, iters: 196, time: 0.023, data: 0.001) G_GAN: 4.612 G_L1: 16.657 D_real: 0.002 D_fake: 0.047 \n",
            "(epoch: 350, iters: 296, time: 0.396, data: 0.001) G_GAN: 7.650 G_L1: 17.765 D_real: 0.004 D_fake: 0.547 \n",
            "saving the model at the end of epoch 350, iters 103600\n",
            "End of epoch 350 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001661\n",
            "(epoch: 351, iters: 100, time: 0.025, data: 0.114) G_GAN: 7.328 G_L1: 18.794 D_real: 0.009 D_fake: 0.005 \n",
            "(epoch: 351, iters: 200, time: 0.113, data: 0.001) G_GAN: 6.494 G_L1: 16.812 D_real: 0.003 D_fake: 0.013 \n",
            "End of epoch 351 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001654\n",
            "(epoch: 352, iters: 4, time: 0.024, data: 0.002) G_GAN: 4.179 G_L1: 15.654 D_real: 0.135 D_fake: 0.135 \n",
            "(epoch: 352, iters: 104, time: 0.322, data: 0.000) G_GAN: 6.699 G_L1: 13.096 D_real: 0.076 D_fake: 0.579 \n",
            "(epoch: 352, iters: 204, time: 0.023, data: 0.002) G_GAN: 4.299 G_L1: 12.953 D_real: 0.036 D_fake: 0.153 \n",
            "End of epoch 352 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001648\n",
            "(epoch: 353, iters: 8, time: 0.023, data: 0.001) G_GAN: 6.356 G_L1: 13.736 D_real: 0.001 D_fake: 0.036 \n",
            "(epoch: 353, iters: 108, time: 0.023, data: 0.001) G_GAN: 9.326 G_L1: 14.057 D_real: 0.078 D_fake: 0.000 \n",
            "(epoch: 353, iters: 208, time: 0.373, data: 0.001) G_GAN: 3.778 G_L1: 16.245 D_real: 0.267 D_fake: 0.021 \n",
            "End of epoch 353 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001641\n",
            "(epoch: 354, iters: 12, time: 0.023, data: 0.001) G_GAN: 3.786 G_L1: 16.148 D_real: 0.213 D_fake: 0.232 \n",
            "(epoch: 354, iters: 112, time: 0.023, data: 0.001) G_GAN: 6.015 G_L1: 17.926 D_real: 0.002 D_fake: 0.614 \n",
            "(epoch: 354, iters: 212, time: 0.023, data: 0.001) G_GAN: 5.606 G_L1: 16.794 D_real: 0.009 D_fake: 0.305 \n",
            "End of epoch 354 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001635\n",
            "(epoch: 355, iters: 16, time: 0.483, data: 0.001) G_GAN: 5.545 G_L1: 14.179 D_real: 0.015 D_fake: 0.417 \n",
            "(epoch: 355, iters: 116, time: 0.024, data: 0.002) G_GAN: 6.002 G_L1: 13.848 D_real: 0.003 D_fake: 0.388 \n",
            "(epoch: 355, iters: 216, time: 0.032, data: 0.001) G_GAN: 2.554 G_L1: 12.207 D_real: 0.790 D_fake: 0.037 \n",
            "saving the latest model (epoch 355, total_iters 105000)\n",
            "saving the model at the end of epoch 355, iters 105080\n",
            "End of epoch 355 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001628\n",
            "(epoch: 356, iters: 20, time: 0.025, data: 0.001) G_GAN: 2.532 G_L1: 13.132 D_real: 1.246 D_fake: 0.013 \n",
            "(epoch: 356, iters: 120, time: 0.405, data: 0.001) G_GAN: 4.468 G_L1: 20.304 D_real: 0.062 D_fake: 0.155 \n",
            "(epoch: 356, iters: 220, time: 0.024, data: 0.002) G_GAN: 5.582 G_L1: 19.373 D_real: 0.002 D_fake: 0.054 \n",
            "End of epoch 356 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0001621\n",
            "(epoch: 357, iters: 24, time: 0.029, data: 0.001) G_GAN: 8.318 G_L1: 13.153 D_real: 0.003 D_fake: 0.973 \n",
            "(epoch: 357, iters: 124, time: 0.023, data: 0.001) G_GAN: 5.489 G_L1: 16.051 D_real: 0.004 D_fake: 0.020 \n",
            "(epoch: 357, iters: 224, time: 0.359, data: 0.001) G_GAN: 6.429 G_L1: 19.691 D_real: 0.008 D_fake: 0.405 \n",
            "End of epoch 357 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001615\n",
            "(epoch: 358, iters: 28, time: 0.028, data: 0.002) G_GAN: 4.608 G_L1: 16.342 D_real: 0.047 D_fake: 0.032 \n",
            "(epoch: 358, iters: 128, time: 0.023, data: 0.001) G_GAN: 7.852 G_L1: 21.355 D_real: 0.004 D_fake: 0.014 \n",
            "(epoch: 358, iters: 228, time: 0.029, data: 0.002) G_GAN: 3.046 G_L1: 15.738 D_real: 0.365 D_fake: 0.026 \n",
            "End of epoch 358 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001608\n",
            "(epoch: 359, iters: 32, time: 0.409, data: 0.001) G_GAN: 3.175 G_L1: 16.730 D_real: 0.098 D_fake: 0.051 \n",
            "(epoch: 359, iters: 132, time: 0.024, data: 0.002) G_GAN: 4.836 G_L1: 14.594 D_real: 0.178 D_fake: 0.008 \n",
            "(epoch: 359, iters: 232, time: 0.024, data: 0.001) G_GAN: 6.107 G_L1: 17.934 D_real: 0.001 D_fake: 0.631 \n",
            "End of epoch 359 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001601\n",
            "(epoch: 360, iters: 36, time: 0.028, data: 0.001) G_GAN: 7.912 G_L1: 18.043 D_real: 0.066 D_fake: 0.019 \n",
            "(epoch: 360, iters: 136, time: 0.368, data: 0.001) G_GAN: 7.068 G_L1: 17.184 D_real: 0.051 D_fake: 0.003 \n",
            "(epoch: 360, iters: 236, time: 0.023, data: 0.001) G_GAN: 6.833 G_L1: 13.205 D_real: 0.049 D_fake: 0.010 \n",
            "saving the model at the end of epoch 360, iters 106560\n",
            "End of epoch 360 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001595\n",
            "(epoch: 361, iters: 40, time: 0.024, data: 0.001) G_GAN: 3.921 G_L1: 14.867 D_real: 0.005 D_fake: 0.220 \n",
            "(epoch: 361, iters: 140, time: 0.023, data: 0.001) G_GAN: 6.059 G_L1: 17.363 D_real: 0.171 D_fake: 0.536 \n",
            "(epoch: 361, iters: 240, time: 0.407, data: 0.001) G_GAN: 4.515 G_L1: 17.190 D_real: 0.577 D_fake: 0.008 \n",
            "End of epoch 361 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0001588\n",
            "(epoch: 362, iters: 44, time: 0.023, data: 0.002) G_GAN: 4.568 G_L1: 16.550 D_real: 0.001 D_fake: 0.095 \n",
            "(epoch: 362, iters: 144, time: 0.029, data: 0.001) G_GAN: 4.087 G_L1: 15.218 D_real: 0.166 D_fake: 0.066 \n",
            "(epoch: 362, iters: 244, time: 0.024, data: 0.001) G_GAN: 6.958 G_L1: 22.528 D_real: 0.025 D_fake: 0.002 \n",
            "End of epoch 362 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001581\n",
            "(epoch: 363, iters: 48, time: 0.372, data: 0.001) G_GAN: 5.265 G_L1: 16.064 D_real: 0.128 D_fake: 0.023 \n",
            "(epoch: 363, iters: 148, time: 0.029, data: 0.002) G_GAN: 5.656 G_L1: 16.146 D_real: 0.039 D_fake: 0.069 \n",
            "(epoch: 363, iters: 248, time: 0.023, data: 0.001) G_GAN: 5.602 G_L1: 17.217 D_real: 0.002 D_fake: 0.051 \n",
            "End of epoch 363 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001575\n",
            "(epoch: 364, iters: 52, time: 0.031, data: 0.002) G_GAN: 4.855 G_L1: 17.641 D_real: 0.059 D_fake: 0.198 \n",
            "(epoch: 364, iters: 152, time: 0.396, data: 0.001) G_GAN: 4.489 G_L1: 14.543 D_real: 0.013 D_fake: 0.159 \n",
            "(epoch: 364, iters: 252, time: 0.029, data: 0.001) G_GAN: 5.989 G_L1: 13.018 D_real: 0.572 D_fake: 0.001 \n",
            "End of epoch 364 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001568\n",
            "(epoch: 365, iters: 56, time: 0.023, data: 0.002) G_GAN: 3.331 G_L1: 14.117 D_real: 0.784 D_fake: 0.004 \n",
            "(epoch: 365, iters: 156, time: 0.023, data: 0.001) G_GAN: 8.501 G_L1: 16.985 D_real: 0.041 D_fake: 0.001 \n",
            "(epoch: 365, iters: 256, time: 0.338, data: 0.001) G_GAN: 6.282 G_L1: 17.002 D_real: 2.315 D_fake: 0.001 \n",
            "saving the model at the end of epoch 365, iters 108040\n",
            "End of epoch 365 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0001561\n",
            "(epoch: 366, iters: 60, time: 0.028, data: 0.001) G_GAN: 4.780 G_L1: 16.451 D_real: 0.010 D_fake: 0.062 \n",
            "(epoch: 366, iters: 160, time: 0.026, data: 0.003) G_GAN: 7.338 G_L1: 17.016 D_real: 0.001 D_fake: 0.005 \n",
            "(epoch: 366, iters: 260, time: 0.058, data: 0.001) G_GAN: 7.987 G_L1: 13.670 D_real: 0.197 D_fake: 0.003 \n",
            "End of epoch 366 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001555\n",
            "(epoch: 367, iters: 64, time: 0.425, data: 0.002) G_GAN: 7.737 G_L1: 21.608 D_real: 0.176 D_fake: 0.002 \n",
            "(epoch: 367, iters: 164, time: 0.025, data: 0.002) G_GAN: 6.838 G_L1: 18.816 D_real: 0.687 D_fake: 0.001 \n",
            "(epoch: 367, iters: 264, time: 0.024, data: 0.002) G_GAN: 8.220 G_L1: 15.100 D_real: 0.015 D_fake: 0.700 \n",
            "End of epoch 367 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001548\n",
            "(epoch: 368, iters: 68, time: 0.026, data: 0.001) G_GAN: 5.460 G_L1: 14.293 D_real: 0.128 D_fake: 0.025 \n",
            "(epoch: 368, iters: 168, time: 0.380, data: 0.001) G_GAN: 7.881 G_L1: 19.690 D_real: 0.047 D_fake: 0.002 \n",
            "(epoch: 368, iters: 268, time: 0.023, data: 0.001) G_GAN: 4.319 G_L1: 17.365 D_real: 0.028 D_fake: 0.149 \n",
            "End of epoch 368 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001542\n",
            "(epoch: 369, iters: 72, time: 0.024, data: 0.001) G_GAN: 5.426 G_L1: 16.943 D_real: 0.007 D_fake: 0.020 \n",
            "(epoch: 369, iters: 172, time: 0.030, data: 0.002) G_GAN: 6.418 G_L1: 14.680 D_real: 0.018 D_fake: 0.026 \n",
            "(epoch: 369, iters: 272, time: 0.402, data: 0.001) G_GAN: 4.268 G_L1: 16.150 D_real: 0.128 D_fake: 0.024 \n",
            "End of epoch 369 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001535\n",
            "(epoch: 370, iters: 76, time: 0.030, data: 0.001) G_GAN: 10.034 G_L1: 18.131 D_real: 0.007 D_fake: 0.001 \n",
            "(epoch: 370, iters: 176, time: 0.026, data: 0.001) G_GAN: 6.824 G_L1: 17.801 D_real: 0.575 D_fake: 0.000 \n",
            "(epoch: 370, iters: 276, time: 0.025, data: 0.001) G_GAN: 7.028 G_L1: 19.994 D_real: 0.041 D_fake: 0.007 \n",
            "saving the model at the end of epoch 370, iters 109520\n",
            "End of epoch 370 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001528\n",
            "(epoch: 371, iters: 80, time: 0.373, data: 0.001) G_GAN: 5.442 G_L1: 12.632 D_real: 0.000 D_fake: 0.464 \n",
            "(epoch: 371, iters: 180, time: 0.023, data: 0.001) G_GAN: 5.450 G_L1: 18.539 D_real: 0.036 D_fake: 0.067 \n",
            "(epoch: 371, iters: 280, time: 0.029, data: 0.001) G_GAN: 4.671 G_L1: 15.678 D_real: 0.004 D_fake: 0.060 \n",
            "End of epoch 371 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001522\n",
            "(epoch: 372, iters: 84, time: 0.025, data: 0.002) G_GAN: 5.675 G_L1: 17.534 D_real: 0.013 D_fake: 0.322 \n",
            "(epoch: 372, iters: 184, time: 0.418, data: 0.001) G_GAN: 5.392 G_L1: 13.550 D_real: 0.001 D_fake: 0.023 \n",
            "saving the latest model (epoch 372, total_iters 110000)\n",
            "(epoch: 372, iters: 284, time: 0.024, data: 0.001) G_GAN: 5.259 G_L1: 16.412 D_real: 0.033 D_fake: 0.047 \n",
            "End of epoch 372 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0001515\n",
            "(epoch: 373, iters: 88, time: 0.023, data: 0.001) G_GAN: 3.840 G_L1: 14.600 D_real: 0.028 D_fake: 0.107 \n",
            "(epoch: 373, iters: 188, time: 0.025, data: 0.001) G_GAN: 5.139 G_L1: 18.746 D_real: 0.005 D_fake: 0.032 \n",
            "(epoch: 373, iters: 288, time: 0.344, data: 0.001) G_GAN: 8.765 G_L1: 14.115 D_real: 0.000 D_fake: 2.711 \n",
            "End of epoch 373 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001508\n",
            "(epoch: 374, iters: 92, time: 0.023, data: 0.001) G_GAN: 7.097 G_L1: 19.909 D_real: 0.100 D_fake: 0.006 \n",
            "(epoch: 374, iters: 192, time: 0.024, data: 0.001) G_GAN: 6.918 G_L1: 13.982 D_real: 0.221 D_fake: 0.004 \n",
            "(epoch: 374, iters: 292, time: 0.022, data: 0.001) G_GAN: 6.315 G_L1: 12.865 D_real: 0.044 D_fake: 0.007 \n",
            "End of epoch 374 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001502\n",
            "(epoch: 375, iters: 96, time: 0.411, data: 0.001) G_GAN: 6.242 G_L1: 13.081 D_real: 0.028 D_fake: 0.006 \n",
            "(epoch: 375, iters: 196, time: 0.028, data: 0.002) G_GAN: 7.515 G_L1: 16.681 D_real: 0.007 D_fake: 0.804 \n",
            "(epoch: 375, iters: 296, time: 0.031, data: 0.001) G_GAN: 5.357 G_L1: 17.994 D_real: 0.181 D_fake: 0.092 \n",
            "saving the model at the end of epoch 375, iters 111000\n",
            "End of epoch 375 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001495\n",
            "(epoch: 376, iters: 100, time: 0.037, data: 0.111) G_GAN: 4.528 G_L1: 18.912 D_real: 0.069 D_fake: 0.076 \n",
            "(epoch: 376, iters: 200, time: 0.606, data: 0.001) G_GAN: 6.970 G_L1: 12.996 D_real: 0.001 D_fake: 0.009 \n",
            "End of epoch 376 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001488\n",
            "(epoch: 377, iters: 4, time: 0.024, data: 0.003) G_GAN: 4.057 G_L1: 17.570 D_real: 0.017 D_fake: 0.067 \n",
            "(epoch: 377, iters: 104, time: 0.024, data: 0.000) G_GAN: 4.543 G_L1: 13.749 D_real: 0.003 D_fake: 0.056 \n",
            "(epoch: 377, iters: 204, time: 0.024, data: 0.001) G_GAN: 5.591 G_L1: 16.792 D_real: 0.003 D_fake: 0.193 \n",
            "End of epoch 377 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001482\n",
            "(epoch: 378, iters: 8, time: 0.432, data: 0.001) G_GAN: 6.906 G_L1: 16.139 D_real: 0.030 D_fake: 0.033 \n",
            "(epoch: 378, iters: 108, time: 0.029, data: 0.002) G_GAN: 5.001 G_L1: 14.495 D_real: 0.045 D_fake: 0.047 \n",
            "(epoch: 378, iters: 208, time: 0.024, data: 0.002) G_GAN: 4.952 G_L1: 17.120 D_real: 0.116 D_fake: 0.025 \n",
            "End of epoch 378 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001475\n",
            "(epoch: 379, iters: 12, time: 0.030, data: 0.001) G_GAN: 9.241 G_L1: 15.937 D_real: 0.211 D_fake: 0.000 \n",
            "(epoch: 379, iters: 112, time: 0.389, data: 0.001) G_GAN: 3.847 G_L1: 15.210 D_real: 0.003 D_fake: 0.018 \n",
            "(epoch: 379, iters: 212, time: 0.031, data: 0.002) G_GAN: 7.396 G_L1: 17.257 D_real: 0.125 D_fake: 0.606 \n",
            "End of epoch 379 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001468\n",
            "(epoch: 380, iters: 16, time: 0.023, data: 0.002) G_GAN: 5.848 G_L1: 14.879 D_real: 0.003 D_fake: 0.377 \n",
            "(epoch: 380, iters: 116, time: 0.024, data: 0.001) G_GAN: 6.812 G_L1: 19.474 D_real: 0.002 D_fake: 0.008 \n",
            "(epoch: 380, iters: 216, time: 0.425, data: 0.001) G_GAN: 4.326 G_L1: 15.098 D_real: 0.014 D_fake: 0.048 \n",
            "saving the model at the end of epoch 380, iters 112480\n",
            "End of epoch 380 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001462\n",
            "(epoch: 381, iters: 20, time: 0.024, data: 0.002) G_GAN: 5.299 G_L1: 14.756 D_real: 0.194 D_fake: 0.008 \n",
            "(epoch: 381, iters: 120, time: 0.024, data: 0.001) G_GAN: 8.139 G_L1: 15.289 D_real: 0.001 D_fake: 0.003 \n",
            "(epoch: 381, iters: 220, time: 0.025, data: 0.001) G_GAN: 3.559 G_L1: 16.480 D_real: 0.433 D_fake: 0.058 \n",
            "End of epoch 381 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001455\n",
            "(epoch: 382, iters: 24, time: 0.368, data: 0.001) G_GAN: 5.668 G_L1: 14.582 D_real: 0.266 D_fake: 0.028 \n",
            "(epoch: 382, iters: 124, time: 0.023, data: 0.002) G_GAN: 7.265 G_L1: 17.801 D_real: 0.143 D_fake: 0.002 \n",
            "(epoch: 382, iters: 224, time: 0.023, data: 0.001) G_GAN: 4.854 G_L1: 16.979 D_real: 0.001 D_fake: 0.105 \n",
            "End of epoch 382 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001449\n",
            "(epoch: 383, iters: 28, time: 0.024, data: 0.001) G_GAN: 5.170 G_L1: 14.228 D_real: 0.075 D_fake: 0.076 \n",
            "(epoch: 383, iters: 128, time: 0.451, data: 0.001) G_GAN: 6.905 G_L1: 14.888 D_real: 0.128 D_fake: 0.004 \n",
            "(epoch: 383, iters: 228, time: 0.029, data: 0.002) G_GAN: 3.751 G_L1: 13.987 D_real: 0.008 D_fake: 0.084 \n",
            "End of epoch 383 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001442\n",
            "(epoch: 384, iters: 32, time: 0.024, data: 0.001) G_GAN: 4.957 G_L1: 18.412 D_real: 0.001 D_fake: 0.050 \n",
            "(epoch: 384, iters: 132, time: 0.026, data: 0.001) G_GAN: 8.373 G_L1: 14.434 D_real: 0.022 D_fake: 0.352 \n",
            "(epoch: 384, iters: 232, time: 0.354, data: 0.001) G_GAN: 6.013 G_L1: 20.615 D_real: 0.002 D_fake: 0.009 \n",
            "End of epoch 384 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001435\n",
            "(epoch: 385, iters: 36, time: 0.024, data: 0.001) G_GAN: 5.470 G_L1: 17.039 D_real: 0.084 D_fake: 0.234 \n",
            "(epoch: 385, iters: 136, time: 0.024, data: 0.001) G_GAN: 9.459 G_L1: 17.610 D_real: 0.186 D_fake: 0.001 \n",
            "(epoch: 385, iters: 236, time: 0.023, data: 0.001) G_GAN: 4.661 G_L1: 16.841 D_real: 0.012 D_fake: 0.063 \n",
            "saving the model at the end of epoch 385, iters 113960\n",
            "End of epoch 385 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001429\n",
            "(epoch: 386, iters: 40, time: 0.596, data: 0.002) G_GAN: 11.673 G_L1: 18.235 D_real: 0.259 D_fake: 0.000 \n",
            "(epoch: 386, iters: 140, time: 0.024, data: 0.002) G_GAN: 9.854 G_L1: 17.117 D_real: 0.029 D_fake: 0.000 \n",
            "(epoch: 386, iters: 240, time: 0.024, data: 0.001) G_GAN: 4.341 G_L1: 21.554 D_real: 0.001 D_fake: 0.044 \n",
            "End of epoch 386 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0001422\n",
            "(epoch: 387, iters: 44, time: 0.023, data: 0.001) G_GAN: 7.063 G_L1: 13.534 D_real: 0.016 D_fake: 0.003 \n",
            "(epoch: 387, iters: 144, time: 0.363, data: 0.001) G_GAN: 4.482 G_L1: 15.025 D_real: 0.223 D_fake: 0.047 \n",
            "(epoch: 387, iters: 244, time: 0.023, data: 0.002) G_GAN: 5.120 G_L1: 17.332 D_real: 0.005 D_fake: 0.048 \n",
            "End of epoch 387 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001415\n",
            "(epoch: 388, iters: 48, time: 0.023, data: 0.001) G_GAN: 7.206 G_L1: 17.779 D_real: 0.029 D_fake: 0.002 \n",
            "(epoch: 388, iters: 148, time: 0.025, data: 0.001) G_GAN: 4.534 G_L1: 13.847 D_real: 0.077 D_fake: 0.123 \n",
            "(epoch: 388, iters: 248, time: 0.434, data: 0.001) G_GAN: 5.950 G_L1: 17.522 D_real: 0.027 D_fake: 0.009 \n",
            "End of epoch 388 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001409\n",
            "(epoch: 389, iters: 52, time: 0.024, data: 0.001) G_GAN: 4.273 G_L1: 15.668 D_real: 0.299 D_fake: 0.028 \n",
            "(epoch: 389, iters: 152, time: 0.032, data: 0.001) G_GAN: 7.412 G_L1: 17.705 D_real: 0.015 D_fake: 0.006 \n",
            "saving the latest model (epoch 389, total_iters 115000)\n",
            "(epoch: 389, iters: 252, time: 0.023, data: 0.001) G_GAN: 7.251 G_L1: 15.949 D_real: 0.007 D_fake: 0.006 \n",
            "End of epoch 389 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001402\n",
            "(epoch: 390, iters: 56, time: 0.360, data: 0.001) G_GAN: 7.070 G_L1: 17.049 D_real: 0.109 D_fake: 0.005 \n",
            "(epoch: 390, iters: 156, time: 0.024, data: 0.001) G_GAN: 5.339 G_L1: 22.084 D_real: 0.001 D_fake: 0.015 \n",
            "(epoch: 390, iters: 256, time: 0.023, data: 0.001) G_GAN: 8.430 G_L1: 19.261 D_real: 0.000 D_fake: 0.005 \n",
            "saving the model at the end of epoch 390, iters 115440\n",
            "End of epoch 390 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001395\n",
            "(epoch: 391, iters: 60, time: 0.031, data: 0.001) G_GAN: 6.562 G_L1: 16.193 D_real: 0.001 D_fake: 0.495 \n",
            "(epoch: 391, iters: 160, time: 0.515, data: 0.002) G_GAN: 4.608 G_L1: 12.798 D_real: 0.003 D_fake: 0.455 \n",
            "(epoch: 391, iters: 260, time: 0.025, data: 0.001) G_GAN: 5.572 G_L1: 14.924 D_real: 0.303 D_fake: 0.011 \n",
            "End of epoch 391 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001389\n",
            "(epoch: 392, iters: 64, time: 0.024, data: 0.002) G_GAN: 5.795 G_L1: 17.836 D_real: 0.001 D_fake: 0.415 \n",
            "(epoch: 392, iters: 164, time: 0.029, data: 0.001) G_GAN: 6.313 G_L1: 15.051 D_real: 0.027 D_fake: 0.125 \n",
            "(epoch: 392, iters: 264, time: 0.368, data: 0.001) G_GAN: 9.134 G_L1: 26.730 D_real: 0.010 D_fake: 0.005 \n",
            "End of epoch 392 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001382\n",
            "(epoch: 393, iters: 68, time: 0.024, data: 0.002) G_GAN: 6.897 G_L1: 20.276 D_real: 0.001 D_fake: 0.004 \n",
            "(epoch: 393, iters: 168, time: 0.024, data: 0.001) G_GAN: 5.395 G_L1: 18.759 D_real: 0.005 D_fake: 0.023 \n",
            "(epoch: 393, iters: 268, time: 0.025, data: 0.001) G_GAN: 5.735 G_L1: 21.209 D_real: 0.000 D_fake: 0.381 \n",
            "End of epoch 393 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001375\n",
            "(epoch: 394, iters: 72, time: 0.477, data: 0.001) G_GAN: 5.551 G_L1: 13.851 D_real: 0.002 D_fake: 0.027 \n",
            "(epoch: 394, iters: 172, time: 0.029, data: 0.002) G_GAN: 6.038 G_L1: 15.340 D_real: 0.001 D_fake: 0.297 \n",
            "(epoch: 394, iters: 272, time: 0.030, data: 0.001) G_GAN: 9.268 G_L1: 22.636 D_real: 0.004 D_fake: 0.000 \n",
            "End of epoch 394 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001369\n",
            "(epoch: 395, iters: 76, time: 0.024, data: 0.001) G_GAN: 4.846 G_L1: 16.983 D_real: 0.185 D_fake: 0.015 \n",
            "(epoch: 395, iters: 176, time: 0.367, data: 0.002) G_GAN: 6.575 G_L1: 17.843 D_real: 0.003 D_fake: 0.009 \n",
            "(epoch: 395, iters: 276, time: 0.024, data: 0.001) G_GAN: 7.505 G_L1: 19.905 D_real: 0.015 D_fake: 0.005 \n",
            "saving the model at the end of epoch 395, iters 116920\n",
            "End of epoch 395 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001362\n",
            "(epoch: 396, iters: 80, time: 0.028, data: 0.001) G_GAN: 3.867 G_L1: 15.104 D_real: 0.001 D_fake: 0.153 \n",
            "(epoch: 396, iters: 180, time: 0.024, data: 0.002) G_GAN: 7.763 G_L1: 24.452 D_real: 0.001 D_fake: 0.002 \n",
            "(epoch: 396, iters: 280, time: 0.471, data: 0.001) G_GAN: 5.265 G_L1: 16.451 D_real: 0.010 D_fake: 0.093 \n",
            "End of epoch 396 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001355\n",
            "(epoch: 397, iters: 84, time: 0.023, data: 0.001) G_GAN: 5.533 G_L1: 14.320 D_real: 0.087 D_fake: 0.068 \n",
            "(epoch: 397, iters: 184, time: 0.023, data: 0.001) G_GAN: 5.187 G_L1: 15.557 D_real: 0.080 D_fake: 0.022 \n",
            "(epoch: 397, iters: 284, time: 0.023, data: 0.001) G_GAN: 5.578 G_L1: 12.775 D_real: 0.191 D_fake: 0.044 \n",
            "End of epoch 397 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001349\n",
            "(epoch: 398, iters: 88, time: 0.381, data: 0.002) G_GAN: 4.438 G_L1: 15.672 D_real: 1.802 D_fake: 0.001 \n",
            "(epoch: 398, iters: 188, time: 0.029, data: 0.001) G_GAN: 4.894 G_L1: 15.246 D_real: 0.003 D_fake: 0.132 \n",
            "(epoch: 398, iters: 288, time: 0.023, data: 0.001) G_GAN: 4.986 G_L1: 17.448 D_real: 0.027 D_fake: 0.250 \n",
            "End of epoch 398 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001342\n",
            "(epoch: 399, iters: 92, time: 0.029, data: 0.001) G_GAN: 6.926 G_L1: 17.859 D_real: 0.114 D_fake: 0.005 \n",
            "(epoch: 399, iters: 192, time: 0.423, data: 0.002) G_GAN: 6.641 G_L1: 16.241 D_real: 0.154 D_fake: 0.002 \n",
            "(epoch: 399, iters: 292, time: 0.022, data: 0.001) G_GAN: 6.226 G_L1: 19.625 D_real: 0.002 D_fake: 0.005 \n",
            "End of epoch 399 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001336\n",
            "(epoch: 400, iters: 96, time: 0.029, data: 0.002) G_GAN: 6.928 G_L1: 15.352 D_real: 0.007 D_fake: 0.003 \n",
            "(epoch: 400, iters: 196, time: 0.023, data: 0.001) G_GAN: 4.399 G_L1: 15.515 D_real: 0.046 D_fake: 0.060 \n",
            "(epoch: 400, iters: 296, time: 0.378, data: 0.001) G_GAN: 5.323 G_L1: 16.228 D_real: 0.055 D_fake: 0.163 \n",
            "saving the model at the end of epoch 400, iters 118400\n",
            "End of epoch 400 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001329\n",
            "(epoch: 401, iters: 100, time: 0.029, data: 0.107) G_GAN: 5.494 G_L1: 14.927 D_real: 0.709 D_fake: 0.002 \n",
            "(epoch: 401, iters: 200, time: 0.030, data: 0.001) G_GAN: 5.326 G_L1: 17.901 D_real: 0.001 D_fake: 0.031 \n",
            "End of epoch 401 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001322\n",
            "(epoch: 402, iters: 4, time: 0.024, data: 0.001) G_GAN: 5.052 G_L1: 14.442 D_real: 0.140 D_fake: 0.019 \n",
            "(epoch: 402, iters: 104, time: 0.549, data: 0.000) G_GAN: 4.415 G_L1: 16.307 D_real: 0.569 D_fake: 0.030 \n",
            "(epoch: 402, iters: 204, time: 0.024, data: 0.001) G_GAN: 2.137 G_L1: 12.838 D_real: 2.326 D_fake: 0.003 \n",
            "End of epoch 402 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0001316\n",
            "(epoch: 403, iters: 8, time: 0.030, data: 0.001) G_GAN: 4.732 G_L1: 16.854 D_real: 0.002 D_fake: 0.301 \n",
            "(epoch: 403, iters: 108, time: 0.023, data: 0.000) G_GAN: 6.061 G_L1: 19.431 D_real: 0.002 D_fake: 0.044 \n",
            "(epoch: 403, iters: 208, time: 0.371, data: 0.001) G_GAN: 5.117 G_L1: 15.064 D_real: 0.071 D_fake: 0.117 \n",
            "End of epoch 403 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001309\n",
            "(epoch: 404, iters: 12, time: 0.023, data: 0.003) G_GAN: 6.025 G_L1: 15.495 D_real: 0.005 D_fake: 0.359 \n",
            "(epoch: 404, iters: 112, time: 0.023, data: 0.002) G_GAN: 9.290 G_L1: 15.364 D_real: 0.003 D_fake: 1.264 \n",
            "(epoch: 404, iters: 212, time: 0.037, data: 0.001) G_GAN: 6.003 G_L1: 25.600 D_real: 0.010 D_fake: 0.015 \n",
            "End of epoch 404 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001302\n",
            "(epoch: 405, iters: 16, time: 0.434, data: 0.002) G_GAN: 5.054 G_L1: 15.254 D_real: 0.005 D_fake: 0.048 \n",
            "(epoch: 405, iters: 116, time: 0.023, data: 0.001) G_GAN: 5.709 G_L1: 15.871 D_real: 0.027 D_fake: 0.017 \n",
            "(epoch: 405, iters: 216, time: 0.024, data: 0.001) G_GAN: 4.642 G_L1: 15.685 D_real: 0.298 D_fake: 0.017 \n",
            "saving the model at the end of epoch 405, iters 119880\n",
            "End of epoch 405 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0001296\n",
            "(epoch: 406, iters: 20, time: 0.023, data: 0.001) G_GAN: 5.980 G_L1: 14.308 D_real: 0.004 D_fake: 0.366 \n",
            "(epoch: 406, iters: 120, time: 0.422, data: 0.001) G_GAN: 5.937 G_L1: 15.715 D_real: 0.003 D_fake: 0.017 \n",
            "saving the latest model (epoch 406, total_iters 120000)\n",
            "(epoch: 406, iters: 220, time: 0.024, data: 0.002) G_GAN: 4.404 G_L1: 15.067 D_real: 0.021 D_fake: 0.025 \n",
            "End of epoch 406 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0001289\n",
            "(epoch: 407, iters: 24, time: 0.024, data: 0.001) G_GAN: 5.371 G_L1: 13.229 D_real: 0.660 D_fake: 0.003 \n",
            "(epoch: 407, iters: 124, time: 0.025, data: 0.002) G_GAN: 7.572 G_L1: 17.594 D_real: 0.078 D_fake: 0.006 \n",
            "(epoch: 407, iters: 224, time: 0.370, data: 0.001) G_GAN: 4.471 G_L1: 13.206 D_real: 0.139 D_fake: 0.043 \n",
            "End of epoch 407 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001282\n",
            "(epoch: 408, iters: 28, time: 0.029, data: 0.001) G_GAN: 6.048 G_L1: 17.636 D_real: 0.003 D_fake: 0.027 \n",
            "(epoch: 408, iters: 128, time: 0.023, data: 0.001) G_GAN: 4.911 G_L1: 16.523 D_real: 0.049 D_fake: 0.330 \n",
            "(epoch: 408, iters: 228, time: 0.023, data: 0.001) G_GAN: 4.838 G_L1: 18.009 D_real: 0.365 D_fake: 0.015 \n",
            "End of epoch 408 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001276\n",
            "(epoch: 409, iters: 32, time: 0.456, data: 0.001) G_GAN: 3.824 G_L1: 18.906 D_real: 0.056 D_fake: 0.182 \n",
            "(epoch: 409, iters: 132, time: 0.024, data: 0.001) G_GAN: 6.177 G_L1: 15.902 D_real: 0.022 D_fake: 0.012 \n",
            "(epoch: 409, iters: 232, time: 0.033, data: 0.001) G_GAN: 4.142 G_L1: 15.783 D_real: 0.190 D_fake: 0.013 \n",
            "End of epoch 409 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001269\n",
            "(epoch: 410, iters: 36, time: 0.024, data: 0.001) G_GAN: 13.874 G_L1: 20.435 D_real: 0.004 D_fake: 0.000 \n",
            "(epoch: 410, iters: 136, time: 0.366, data: 0.001) G_GAN: 7.326 G_L1: 31.349 D_real: 0.002 D_fake: 0.010 \n",
            "(epoch: 410, iters: 236, time: 0.029, data: 0.001) G_GAN: 8.483 G_L1: 19.113 D_real: 0.001 D_fake: 0.019 \n",
            "saving the model at the end of epoch 410, iters 121360\n",
            "End of epoch 410 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001262\n",
            "(epoch: 411, iters: 40, time: 0.023, data: 0.001) G_GAN: 5.014 G_L1: 13.814 D_real: 0.002 D_fake: 0.119 \n",
            "(epoch: 411, iters: 140, time: 0.023, data: 0.001) G_GAN: 5.516 G_L1: 14.574 D_real: 0.013 D_fake: 0.063 \n",
            "(epoch: 411, iters: 240, time: 0.444, data: 0.001) G_GAN: 8.301 G_L1: 16.327 D_real: 0.044 D_fake: 0.007 \n",
            "End of epoch 411 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0001256\n",
            "(epoch: 412, iters: 44, time: 0.023, data: 0.001) G_GAN: 5.199 G_L1: 13.316 D_real: 0.014 D_fake: 0.048 \n",
            "(epoch: 412, iters: 144, time: 0.025, data: 0.001) G_GAN: 4.528 G_L1: 15.229 D_real: 0.169 D_fake: 0.032 \n",
            "(epoch: 412, iters: 244, time: 0.025, data: 0.001) G_GAN: 5.045 G_L1: 14.977 D_real: 0.052 D_fake: 0.024 \n",
            "End of epoch 412 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001249\n",
            "(epoch: 413, iters: 48, time: 0.395, data: 0.001) G_GAN: 4.570 G_L1: 16.379 D_real: 0.002 D_fake: 0.047 \n",
            "(epoch: 413, iters: 148, time: 0.025, data: 0.001) G_GAN: 2.324 G_L1: 14.102 D_real: 0.772 D_fake: 0.029 \n",
            "(epoch: 413, iters: 248, time: 0.024, data: 0.001) G_GAN: 7.329 G_L1: 16.442 D_real: 0.005 D_fake: 0.014 \n",
            "End of epoch 413 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001243\n",
            "(epoch: 414, iters: 52, time: 0.024, data: 0.001) G_GAN: 7.135 G_L1: 17.041 D_real: 0.001 D_fake: 0.003 \n",
            "(epoch: 414, iters: 152, time: 0.485, data: 0.001) G_GAN: 6.934 G_L1: 19.385 D_real: 0.007 D_fake: 0.007 \n",
            "(epoch: 414, iters: 252, time: 0.023, data: 0.002) G_GAN: 7.308 G_L1: 15.155 D_real: 0.321 D_fake: 0.001 \n",
            "End of epoch 414 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001236\n",
            "(epoch: 415, iters: 56, time: 0.024, data: 0.001) G_GAN: 8.060 G_L1: 18.018 D_real: 0.002 D_fake: 0.661 \n",
            "(epoch: 415, iters: 156, time: 0.024, data: 0.001) G_GAN: 5.874 G_L1: 14.017 D_real: 0.002 D_fake: 0.004 \n",
            "(epoch: 415, iters: 256, time: 0.377, data: 0.002) G_GAN: 5.928 G_L1: 18.102 D_real: 0.103 D_fake: 0.037 \n",
            "saving the model at the end of epoch 415, iters 122840\n",
            "End of epoch 415 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001229\n",
            "(epoch: 416, iters: 60, time: 0.024, data: 0.001) G_GAN: 5.753 G_L1: 16.263 D_real: 0.004 D_fake: 0.026 \n",
            "(epoch: 416, iters: 160, time: 0.030, data: 0.001) G_GAN: 2.956 G_L1: 16.182 D_real: 0.026 D_fake: 0.098 \n",
            "End of epoch 416 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001223\n",
            "(epoch: 417, iters: 64, time: 0.451, data: 0.001) G_GAN: 3.748 G_L1: 13.740 D_real: 0.262 D_fake: 0.142 \n",
            "(epoch: 417, iters: 164, time: 0.023, data: 0.002) G_GAN: 5.907 G_L1: 16.807 D_real: 0.131 D_fake: 0.009 \n",
            "(epoch: 417, iters: 264, time: 0.031, data: 0.001) G_GAN: 7.759 G_L1: 17.588 D_real: 0.047 D_fake: 0.002 \n",
            "End of epoch 417 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001216\n",
            "(epoch: 418, iters: 68, time: 0.024, data: 0.001) G_GAN: 5.020 G_L1: 14.669 D_real: 0.015 D_fake: 0.062 \n",
            "(epoch: 418, iters: 168, time: 0.383, data: 0.001) G_GAN: 4.949 G_L1: 18.696 D_real: 0.001 D_fake: 0.124 \n",
            "(epoch: 418, iters: 268, time: 0.023, data: 0.001) G_GAN: 4.243 G_L1: 12.770 D_real: 0.011 D_fake: 0.083 \n",
            "End of epoch 418 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001209\n",
            "(epoch: 419, iters: 72, time: 0.026, data: 0.001) G_GAN: 9.393 G_L1: 15.255 D_real: 0.081 D_fake: 0.001 \n",
            "(epoch: 419, iters: 172, time: 0.024, data: 0.001) G_GAN: 8.931 G_L1: 19.490 D_real: 0.040 D_fake: 0.000 \n",
            "(epoch: 419, iters: 272, time: 0.433, data: 0.001) G_GAN: 5.949 G_L1: 14.068 D_real: 0.004 D_fake: 0.185 \n",
            "End of epoch 419 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001203\n",
            "(epoch: 420, iters: 76, time: 0.024, data: 0.001) G_GAN: 9.967 G_L1: 12.965 D_real: 0.000 D_fake: 1.340 \n",
            "(epoch: 420, iters: 176, time: 0.023, data: 0.001) G_GAN: 5.018 G_L1: 11.995 D_real: 0.022 D_fake: 0.048 \n",
            "(epoch: 420, iters: 276, time: 0.030, data: 0.001) G_GAN: 6.011 G_L1: 19.835 D_real: 0.001 D_fake: 0.020 \n",
            "saving the model at the end of epoch 420, iters 124320\n",
            "End of epoch 420 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001196\n",
            "(epoch: 421, iters: 80, time: 0.443, data: 0.001) G_GAN: 9.010 G_L1: 15.466 D_real: 0.082 D_fake: 0.000 \n",
            "(epoch: 421, iters: 180, time: 0.024, data: 0.001) G_GAN: 7.876 G_L1: 16.500 D_real: 0.006 D_fake: 0.005 \n",
            "(epoch: 421, iters: 280, time: 0.026, data: 0.001) G_GAN: 5.368 G_L1: 14.952 D_real: 0.182 D_fake: 0.011 \n",
            "End of epoch 421 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001189\n",
            "(epoch: 422, iters: 84, time: 0.023, data: 0.001) G_GAN: 6.446 G_L1: 16.310 D_real: 0.001 D_fake: 0.007 \n",
            "(epoch: 422, iters: 184, time: 0.400, data: 0.001) G_GAN: 7.493 G_L1: 17.074 D_real: 0.005 D_fake: 0.001 \n",
            "(epoch: 422, iters: 284, time: 0.029, data: 0.002) G_GAN: 5.732 G_L1: 14.279 D_real: 0.012 D_fake: 0.019 \n",
            "End of epoch 422 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0001183\n",
            "(epoch: 423, iters: 88, time: 0.023, data: 0.001) G_GAN: 8.070 G_L1: 17.078 D_real: 0.089 D_fake: 0.009 \n",
            "saving the latest model (epoch 423, total_iters 125000)\n",
            "(epoch: 423, iters: 188, time: 0.024, data: 0.001) G_GAN: 4.548 G_L1: 12.787 D_real: 0.002 D_fake: 0.193 \n",
            "(epoch: 423, iters: 288, time: 0.434, data: 0.001) G_GAN: 5.546 G_L1: 15.313 D_real: 0.019 D_fake: 0.351 \n",
            "End of epoch 423 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001176\n",
            "(epoch: 424, iters: 92, time: 0.023, data: 0.001) G_GAN: 6.792 G_L1: 15.337 D_real: 0.003 D_fake: 0.005 \n",
            "(epoch: 424, iters: 192, time: 0.024, data: 0.001) G_GAN: 5.834 G_L1: 18.015 D_real: 0.040 D_fake: 0.019 \n",
            "(epoch: 424, iters: 292, time: 0.028, data: 0.001) G_GAN: 6.352 G_L1: 15.322 D_real: 0.004 D_fake: 0.010 \n",
            "End of epoch 424 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001169\n",
            "(epoch: 425, iters: 96, time: 0.401, data: 0.001) G_GAN: 5.433 G_L1: 15.586 D_real: 0.000 D_fake: 0.204 \n",
            "(epoch: 425, iters: 196, time: 0.024, data: 0.001) G_GAN: 5.229 G_L1: 16.297 D_real: 0.007 D_fake: 0.035 \n",
            "(epoch: 425, iters: 296, time: 0.022, data: 0.001) G_GAN: 6.489 G_L1: 15.597 D_real: 0.296 D_fake: 0.003 \n",
            "saving the model at the end of epoch 425, iters 125800\n",
            "End of epoch 425 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0001163\n",
            "(epoch: 426, iters: 100, time: 0.023, data: 0.125) G_GAN: 6.956 G_L1: 18.517 D_real: 0.003 D_fake: 0.826 \n",
            "(epoch: 426, iters: 200, time: 0.490, data: 0.001) G_GAN: 4.569 G_L1: 14.913 D_real: 0.289 D_fake: 0.198 \n",
            "End of epoch 426 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0001156\n",
            "(epoch: 427, iters: 4, time: 0.025, data: 0.002) G_GAN: 6.204 G_L1: 16.263 D_real: 0.276 D_fake: 0.004 \n",
            "(epoch: 427, iters: 104, time: 0.023, data: 0.000) G_GAN: 5.111 G_L1: 13.542 D_real: 0.019 D_fake: 0.029 \n",
            "(epoch: 427, iters: 204, time: 0.029, data: 0.001) G_GAN: 4.484 G_L1: 17.511 D_real: 0.002 D_fake: 0.060 \n",
            "End of epoch 427 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001150\n",
            "(epoch: 428, iters: 8, time: 0.401, data: 0.001) G_GAN: 6.265 G_L1: 11.302 D_real: 0.450 D_fake: 0.002 \n",
            "(epoch: 428, iters: 108, time: 0.023, data: 0.000) G_GAN: 4.461 G_L1: 16.038 D_real: 0.002 D_fake: 0.066 \n",
            "(epoch: 428, iters: 208, time: 0.025, data: 0.001) G_GAN: 4.934 G_L1: 12.161 D_real: 0.051 D_fake: 0.040 \n",
            "End of epoch 428 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001143\n",
            "(epoch: 429, iters: 12, time: 0.032, data: 0.001) G_GAN: 6.162 G_L1: 13.896 D_real: 0.027 D_fake: 0.005 \n",
            "(epoch: 429, iters: 112, time: 0.462, data: 0.001) G_GAN: 10.876 G_L1: 27.693 D_real: 0.005 D_fake: 0.000 \n",
            "(epoch: 429, iters: 212, time: 0.023, data: 0.002) G_GAN: 7.269 G_L1: 17.010 D_real: 0.001 D_fake: 0.002 \n",
            "End of epoch 429 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001136\n",
            "(epoch: 430, iters: 16, time: 0.026, data: 0.001) G_GAN: 6.098 G_L1: 19.157 D_real: 0.214 D_fake: 0.027 \n",
            "(epoch: 430, iters: 116, time: 0.025, data: 0.001) G_GAN: 5.576 G_L1: 15.399 D_real: 0.011 D_fake: 0.015 \n",
            "(epoch: 430, iters: 216, time: 0.457, data: 0.002) G_GAN: 9.318 G_L1: 17.089 D_real: 0.000 D_fake: 0.003 \n",
            "saving the model at the end of epoch 430, iters 127280\n",
            "End of epoch 430 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001130\n",
            "(epoch: 431, iters: 20, time: 0.023, data: 0.002) G_GAN: 9.177 G_L1: 21.842 D_real: 0.015 D_fake: 0.001 \n",
            "(epoch: 431, iters: 120, time: 0.024, data: 0.001) G_GAN: 8.024 G_L1: 17.458 D_real: 0.003 D_fake: 0.001 \n",
            "(epoch: 431, iters: 220, time: 0.042, data: 0.001) G_GAN: 5.555 G_L1: 18.332 D_real: 0.000 D_fake: 0.255 \n",
            "End of epoch 431 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001123\n",
            "(epoch: 432, iters: 24, time: 0.402, data: 0.002) G_GAN: 6.397 G_L1: 18.588 D_real: 0.001 D_fake: 0.013 \n",
            "(epoch: 432, iters: 124, time: 0.024, data: 0.001) G_GAN: 4.927 G_L1: 14.987 D_real: 0.057 D_fake: 0.169 \n",
            "(epoch: 432, iters: 224, time: 0.033, data: 0.001) G_GAN: 5.263 G_L1: 15.329 D_real: 0.047 D_fake: 0.021 \n",
            "End of epoch 432 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001116\n",
            "(epoch: 433, iters: 28, time: 0.024, data: 0.001) G_GAN: 5.320 G_L1: 16.169 D_real: 0.007 D_fake: 0.061 \n",
            "(epoch: 433, iters: 128, time: 0.436, data: 0.001) G_GAN: 8.337 G_L1: 18.387 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 433, iters: 228, time: 0.023, data: 0.001) G_GAN: 4.958 G_L1: 13.749 D_real: 0.228 D_fake: 0.224 \n",
            "End of epoch 433 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001110\n",
            "(epoch: 434, iters: 32, time: 0.023, data: 0.001) G_GAN: 5.342 G_L1: 14.264 D_real: 0.018 D_fake: 0.135 \n",
            "(epoch: 434, iters: 132, time: 0.024, data: 0.002) G_GAN: 3.064 G_L1: 14.903 D_real: 0.250 D_fake: 0.100 \n",
            "(epoch: 434, iters: 232, time: 0.420, data: 0.001) G_GAN: 10.418 G_L1: 19.074 D_real: 0.001 D_fake: 0.000 \n",
            "End of epoch 434 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001103\n",
            "(epoch: 435, iters: 36, time: 0.024, data: 0.001) G_GAN: 7.694 G_L1: 13.585 D_real: 0.033 D_fake: 0.001 \n",
            "(epoch: 435, iters: 136, time: 0.030, data: 0.001) G_GAN: 5.445 G_L1: 13.841 D_real: 0.071 D_fake: 0.020 \n",
            "(epoch: 435, iters: 236, time: 0.025, data: 0.001) G_GAN: 7.572 G_L1: 12.568 D_real: 0.003 D_fake: 0.003 \n",
            "saving the model at the end of epoch 435, iters 128760\n",
            "End of epoch 435 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001096\n",
            "(epoch: 436, iters: 40, time: 0.451, data: 0.002) G_GAN: 5.361 G_L1: 16.812 D_real: 0.004 D_fake: 0.082 \n",
            "(epoch: 436, iters: 140, time: 0.024, data: 0.001) G_GAN: 5.019 G_L1: 14.070 D_real: 0.003 D_fake: 0.021 \n",
            "(epoch: 436, iters: 240, time: 0.028, data: 0.004) G_GAN: 4.311 G_L1: 15.674 D_real: 0.016 D_fake: 0.100 \n",
            "End of epoch 436 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0001090\n",
            "(epoch: 437, iters: 44, time: 0.029, data: 0.002) G_GAN: 7.754 G_L1: 15.277 D_real: 0.122 D_fake: 0.002 \n",
            "(epoch: 437, iters: 144, time: 0.457, data: 0.001) G_GAN: 4.676 G_L1: 16.908 D_real: 0.019 D_fake: 0.084 \n",
            "(epoch: 437, iters: 244, time: 0.023, data: 0.002) G_GAN: 7.072 G_L1: 16.347 D_real: 0.033 D_fake: 0.009 \n",
            "End of epoch 437 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001083\n",
            "(epoch: 438, iters: 48, time: 0.023, data: 0.001) G_GAN: 4.551 G_L1: 16.857 D_real: 0.076 D_fake: 0.071 \n",
            "(epoch: 438, iters: 148, time: 0.025, data: 0.002) G_GAN: 5.230 G_L1: 14.726 D_real: 0.001 D_fake: 0.151 \n",
            "(epoch: 438, iters: 248, time: 0.495, data: 0.001) G_GAN: 5.921 G_L1: 14.302 D_real: 0.007 D_fake: 0.018 \n",
            "End of epoch 438 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001076\n",
            "(epoch: 439, iters: 52, time: 0.024, data: 0.002) G_GAN: 5.177 G_L1: 13.375 D_real: 0.026 D_fake: 0.018 \n",
            "(epoch: 439, iters: 152, time: 0.025, data: 0.001) G_GAN: 5.947 G_L1: 19.213 D_real: 0.276 D_fake: 0.020 \n",
            "(epoch: 439, iters: 252, time: 0.025, data: 0.002) G_GAN: 7.768 G_L1: 13.432 D_real: 0.960 D_fake: 0.000 \n",
            "End of epoch 439 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001070\n",
            "(epoch: 440, iters: 56, time: 0.452, data: 0.002) G_GAN: 7.777 G_L1: 15.741 D_real: 0.001 D_fake: 0.757 \n",
            "saving the latest model (epoch 440, total_iters 130000)\n",
            "(epoch: 440, iters: 156, time: 0.028, data: 0.002) G_GAN: 4.153 G_L1: 13.012 D_real: 0.899 D_fake: 0.002 \n",
            "(epoch: 440, iters: 256, time: 0.025, data: 0.004) G_GAN: 5.280 G_L1: 15.737 D_real: 0.001 D_fake: 0.054 \n",
            "saving the model at the end of epoch 440, iters 130240\n",
            "End of epoch 440 / 600 \t Time Taken: 10 sec\n",
            "learning rate = 0.0001063\n",
            "(epoch: 441, iters: 60, time: 0.029, data: 0.001) G_GAN: 4.757 G_L1: 16.035 D_real: 0.053 D_fake: 0.017 \n",
            "(epoch: 441, iters: 160, time: 0.424, data: 0.001) G_GAN: 4.669 G_L1: 15.111 D_real: 0.061 D_fake: 0.046 \n",
            "(epoch: 441, iters: 260, time: 0.024, data: 0.002) G_GAN: 5.368 G_L1: 15.466 D_real: 0.004 D_fake: 0.160 \n",
            "End of epoch 441 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0001056\n",
            "(epoch: 442, iters: 64, time: 0.023, data: 0.001) G_GAN: 5.444 G_L1: 17.871 D_real: 0.002 D_fake: 0.027 \n",
            "(epoch: 442, iters: 164, time: 0.024, data: 0.001) G_GAN: 4.031 G_L1: 15.734 D_real: 0.183 D_fake: 0.121 \n",
            "(epoch: 442, iters: 264, time: 0.463, data: 0.001) G_GAN: 7.012 G_L1: 17.562 D_real: 0.030 D_fake: 0.101 \n",
            "End of epoch 442 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001050\n",
            "(epoch: 443, iters: 68, time: 0.024, data: 0.002) G_GAN: 6.562 G_L1: 16.066 D_real: 0.047 D_fake: 0.002 \n",
            "(epoch: 443, iters: 168, time: 0.029, data: 0.002) G_GAN: 7.292 G_L1: 18.433 D_real: 0.160 D_fake: 0.002 \n",
            "(epoch: 443, iters: 268, time: 0.024, data: 0.001) G_GAN: 5.932 G_L1: 17.803 D_real: 0.005 D_fake: 0.014 \n",
            "End of epoch 443 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001043\n",
            "(epoch: 444, iters: 72, time: 0.428, data: 0.001) G_GAN: 9.456 G_L1: 13.739 D_real: 0.013 D_fake: 0.000 \n",
            "(epoch: 444, iters: 172, time: 0.024, data: 0.002) G_GAN: 4.355 G_L1: 19.348 D_real: 0.111 D_fake: 0.044 \n",
            "(epoch: 444, iters: 272, time: 0.030, data: 0.001) G_GAN: 5.657 G_L1: 16.040 D_real: 0.019 D_fake: 0.027 \n",
            "End of epoch 444 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001037\n",
            "(epoch: 445, iters: 76, time: 0.024, data: 0.001) G_GAN: 9.533 G_L1: 25.912 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 445, iters: 176, time: 0.466, data: 0.001) G_GAN: 6.626 G_L1: 15.762 D_real: 0.007 D_fake: 0.006 \n",
            "(epoch: 445, iters: 276, time: 0.024, data: 0.001) G_GAN: 5.651 G_L1: 15.776 D_real: 0.002 D_fake: 0.031 \n",
            "saving the model at the end of epoch 445, iters 131720\n",
            "End of epoch 445 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0001030\n",
            "(epoch: 446, iters: 80, time: 0.024, data: 0.001) G_GAN: 8.221 G_L1: 15.394 D_real: 0.039 D_fake: 0.001 \n",
            "(epoch: 446, iters: 180, time: 0.024, data: 0.001) G_GAN: 5.250 G_L1: 16.223 D_real: 0.127 D_fake: 0.015 \n",
            "(epoch: 446, iters: 280, time: 0.455, data: 0.001) G_GAN: 5.246 G_L1: 17.107 D_real: 0.000 D_fake: 0.018 \n",
            "End of epoch 446 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0001023\n",
            "(epoch: 447, iters: 84, time: 0.029, data: 0.001) G_GAN: 5.541 G_L1: 17.051 D_real: 0.008 D_fake: 0.021 \n",
            "(epoch: 447, iters: 184, time: 0.024, data: 0.001) G_GAN: 6.316 G_L1: 17.152 D_real: 0.003 D_fake: 0.006 \n",
            "(epoch: 447, iters: 284, time: 0.023, data: 0.002) G_GAN: 4.318 G_L1: 14.004 D_real: 0.290 D_fake: 0.044 \n",
            "End of epoch 447 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001017\n",
            "(epoch: 448, iters: 88, time: 0.423, data: 0.001) G_GAN: 5.901 G_L1: 12.850 D_real: 0.000 D_fake: 0.083 \n",
            "(epoch: 448, iters: 188, time: 0.023, data: 0.001) G_GAN: 7.094 G_L1: 15.629 D_real: 0.011 D_fake: 0.012 \n",
            "(epoch: 448, iters: 288, time: 0.024, data: 0.001) G_GAN: 6.755 G_L1: 17.333 D_real: 0.005 D_fake: 0.022 \n",
            "End of epoch 448 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001010\n",
            "(epoch: 449, iters: 92, time: 0.023, data: 0.002) G_GAN: 5.584 G_L1: 16.356 D_real: 0.003 D_fake: 0.015 \n",
            "(epoch: 449, iters: 192, time: 0.490, data: 0.002) G_GAN: 4.846 G_L1: 12.594 D_real: 0.036 D_fake: 0.016 \n",
            "(epoch: 449, iters: 292, time: 0.023, data: 0.002) G_GAN: 6.566 G_L1: 15.522 D_real: 0.030 D_fake: 0.006 \n",
            "End of epoch 449 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001003\n",
            "(epoch: 450, iters: 96, time: 0.024, data: 0.001) G_GAN: 7.312 G_L1: 14.108 D_real: 0.014 D_fake: 0.002 \n",
            "(epoch: 450, iters: 196, time: 0.024, data: 0.001) G_GAN: 1.475 G_L1: 13.087 D_real: 0.431 D_fake: 0.093 \n",
            "(epoch: 450, iters: 296, time: 0.410, data: 0.001) G_GAN: 4.885 G_L1: 18.491 D_real: 0.044 D_fake: 0.033 \n",
            "saving the model at the end of epoch 450, iters 133200\n",
            "End of epoch 450 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000997\n",
            "(epoch: 451, iters: 100, time: 0.023, data: 0.112) G_GAN: 5.818 G_L1: 19.928 D_real: 0.068 D_fake: 0.011 \n",
            "(epoch: 451, iters: 200, time: 0.024, data: 0.001) G_GAN: 5.216 G_L1: 15.392 D_real: 0.009 D_fake: 0.217 \n",
            "End of epoch 451 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000990\n",
            "(epoch: 452, iters: 4, time: 0.039, data: 0.002) G_GAN: 5.683 G_L1: 16.558 D_real: 0.002 D_fake: 0.046 \n",
            "(epoch: 452, iters: 104, time: 0.448, data: 0.003) G_GAN: 7.223 G_L1: 14.555 D_real: 0.003 D_fake: 0.003 \n",
            "(epoch: 452, iters: 204, time: 0.024, data: 0.002) G_GAN: 5.422 G_L1: 17.529 D_real: 0.017 D_fake: 0.069 \n",
            "End of epoch 452 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0000983\n",
            "(epoch: 453, iters: 8, time: 0.023, data: 0.001) G_GAN: 5.162 G_L1: 15.980 D_real: 0.075 D_fake: 0.016 \n",
            "(epoch: 453, iters: 108, time: 0.023, data: 0.001) G_GAN: 5.850 G_L1: 16.271 D_real: 0.085 D_fake: 0.007 \n",
            "(epoch: 453, iters: 208, time: 0.472, data: 0.001) G_GAN: 5.005 G_L1: 16.205 D_real: 0.010 D_fake: 0.028 \n",
            "End of epoch 453 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000977\n",
            "(epoch: 454, iters: 12, time: 0.030, data: 0.001) G_GAN: 5.009 G_L1: 17.069 D_real: 0.011 D_fake: 0.038 \n",
            "(epoch: 454, iters: 112, time: 0.024, data: 0.001) G_GAN: 7.128 G_L1: 14.956 D_real: 0.023 D_fake: 0.022 \n",
            "(epoch: 454, iters: 212, time: 0.023, data: 0.001) G_GAN: 7.295 G_L1: 16.097 D_real: 0.001 D_fake: 0.002 \n",
            "End of epoch 454 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000970\n",
            "(epoch: 455, iters: 16, time: 0.427, data: 0.001) G_GAN: 6.426 G_L1: 13.497 D_real: 0.010 D_fake: 0.010 \n",
            "(epoch: 455, iters: 116, time: 0.023, data: 0.001) G_GAN: 7.654 G_L1: 15.716 D_real: 0.001 D_fake: 0.002 \n",
            "(epoch: 455, iters: 216, time: 0.023, data: 0.001) G_GAN: 11.075 G_L1: 21.749 D_real: 0.002 D_fake: 0.000 \n",
            "saving the model at the end of epoch 455, iters 134680\n",
            "End of epoch 455 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000963\n",
            "(epoch: 456, iters: 20, time: 0.023, data: 0.001) G_GAN: 8.115 G_L1: 13.282 D_real: 0.004 D_fake: 0.008 \n",
            "(epoch: 456, iters: 120, time: 0.497, data: 0.001) G_GAN: 5.789 G_L1: 16.803 D_real: 0.018 D_fake: 0.024 \n",
            "(epoch: 456, iters: 220, time: 0.024, data: 0.002) G_GAN: 8.411 G_L1: 18.197 D_real: 0.035 D_fake: 0.001 \n",
            "End of epoch 456 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0000957\n",
            "(epoch: 457, iters: 24, time: 0.025, data: 0.001) G_GAN: 7.376 G_L1: 14.773 D_real: 0.069 D_fake: 0.004 \n",
            "saving the latest model (epoch 457, total_iters 135000)\n",
            "(epoch: 457, iters: 124, time: 0.023, data: 0.001) G_GAN: 7.770 G_L1: 18.468 D_real: 0.051 D_fake: 0.003 \n",
            "(epoch: 457, iters: 224, time: 0.558, data: 0.001) G_GAN: 6.306 G_L1: 18.370 D_real: 0.013 D_fake: 0.595 \n",
            "End of epoch 457 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000950\n",
            "(epoch: 458, iters: 28, time: 0.023, data: 0.002) G_GAN: 7.523 G_L1: 17.649 D_real: 0.005 D_fake: 0.005 \n",
            "(epoch: 458, iters: 128, time: 0.023, data: 0.001) G_GAN: 5.874 G_L1: 15.202 D_real: 0.004 D_fake: 0.096 \n",
            "(epoch: 458, iters: 228, time: 0.024, data: 0.002) G_GAN: 7.186 G_L1: 19.375 D_real: 0.002 D_fake: 0.006 \n",
            "End of epoch 458 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000944\n",
            "(epoch: 459, iters: 32, time: 0.455, data: 0.001) G_GAN: 6.947 G_L1: 14.795 D_real: 0.042 D_fake: 0.005 \n",
            "(epoch: 459, iters: 132, time: 0.023, data: 0.001) G_GAN: 7.573 G_L1: 17.289 D_real: 0.002 D_fake: 0.006 \n",
            "(epoch: 459, iters: 232, time: 0.024, data: 0.001) G_GAN: 6.713 G_L1: 15.711 D_real: 0.078 D_fake: 0.009 \n",
            "End of epoch 459 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000937\n",
            "(epoch: 460, iters: 36, time: 0.025, data: 0.001) G_GAN: 5.593 G_L1: 16.159 D_real: 0.152 D_fake: 0.016 \n",
            "(epoch: 460, iters: 136, time: 0.467, data: 0.001) G_GAN: 5.769 G_L1: 14.052 D_real: 0.002 D_fake: 0.019 \n",
            "(epoch: 460, iters: 236, time: 0.023, data: 0.002) G_GAN: 7.853 G_L1: 14.287 D_real: 0.003 D_fake: 0.002 \n",
            "saving the model at the end of epoch 460, iters 136160\n",
            "End of epoch 460 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000930\n",
            "(epoch: 461, iters: 40, time: 0.023, data: 0.002) G_GAN: 5.829 G_L1: 13.788 D_real: 0.017 D_fake: 0.014 \n",
            "(epoch: 461, iters: 140, time: 0.025, data: 0.002) G_GAN: 6.983 G_L1: 15.180 D_real: 0.001 D_fake: 0.011 \n",
            "(epoch: 461, iters: 240, time: 0.605, data: 0.001) G_GAN: 6.919 G_L1: 15.784 D_real: 0.010 D_fake: 0.006 \n",
            "End of epoch 461 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000924\n",
            "(epoch: 462, iters: 44, time: 0.028, data: 0.006) G_GAN: 5.559 G_L1: 13.379 D_real: 0.002 D_fake: 0.021 \n",
            "(epoch: 462, iters: 144, time: 0.025, data: 0.001) G_GAN: 10.401 G_L1: 21.585 D_real: 0.014 D_fake: 0.001 \n",
            "(epoch: 462, iters: 244, time: 0.023, data: 0.001) G_GAN: 4.977 G_L1: 15.051 D_real: 0.020 D_fake: 0.128 \n",
            "End of epoch 462 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000917\n",
            "(epoch: 463, iters: 48, time: 0.478, data: 0.001) G_GAN: 5.983 G_L1: 15.093 D_real: 0.069 D_fake: 0.026 \n",
            "(epoch: 463, iters: 148, time: 0.029, data: 0.002) G_GAN: 4.964 G_L1: 19.124 D_real: 0.004 D_fake: 0.095 \n",
            "(epoch: 463, iters: 248, time: 0.025, data: 0.001) G_GAN: 8.679 G_L1: 14.266 D_real: 0.002 D_fake: 0.002 \n",
            "End of epoch 463 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000910\n",
            "(epoch: 464, iters: 52, time: 0.024, data: 0.001) G_GAN: 5.203 G_L1: 14.918 D_real: 0.015 D_fake: 0.088 \n",
            "(epoch: 464, iters: 152, time: 0.435, data: 0.001) G_GAN: 4.470 G_L1: 16.821 D_real: 0.153 D_fake: 0.029 \n",
            "(epoch: 464, iters: 252, time: 0.024, data: 0.002) G_GAN: 7.106 G_L1: 14.124 D_real: 0.039 D_fake: 0.005 \n",
            "End of epoch 464 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000904\n",
            "(epoch: 465, iters: 56, time: 0.028, data: 0.002) G_GAN: 7.518 G_L1: 17.433 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 465, iters: 156, time: 0.023, data: 0.001) G_GAN: 4.218 G_L1: 14.967 D_real: 0.004 D_fake: 0.077 \n",
            "(epoch: 465, iters: 256, time: 0.482, data: 0.001) G_GAN: 7.928 G_L1: 22.861 D_real: 0.006 D_fake: 0.004 \n",
            "saving the model at the end of epoch 465, iters 137640\n",
            "End of epoch 465 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0000897\n",
            "(epoch: 466, iters: 60, time: 0.023, data: 0.001) G_GAN: 12.252 G_L1: 13.307 D_real: 0.005 D_fake: 2.717 \n",
            "(epoch: 466, iters: 160, time: 0.023, data: 0.001) G_GAN: 6.463 G_L1: 19.548 D_real: 0.012 D_fake: 0.008 \n",
            "(epoch: 466, iters: 260, time: 0.041, data: 0.001) G_GAN: 4.973 G_L1: 15.510 D_real: 0.208 D_fake: 0.308 \n",
            "End of epoch 466 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000890\n",
            "(epoch: 467, iters: 64, time: 0.461, data: 0.003) G_GAN: 6.005 G_L1: 12.699 D_real: 0.001 D_fake: 0.007 \n",
            "(epoch: 467, iters: 164, time: 0.023, data: 0.001) G_GAN: 5.399 G_L1: 13.844 D_real: 0.026 D_fake: 0.042 \n",
            "(epoch: 467, iters: 264, time: 0.025, data: 0.001) G_GAN: 4.708 G_L1: 13.808 D_real: 0.370 D_fake: 0.008 \n",
            "End of epoch 467 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000884\n",
            "(epoch: 468, iters: 68, time: 0.023, data: 0.001) G_GAN: 8.388 G_L1: 17.956 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 468, iters: 168, time: 0.421, data: 0.001) G_GAN: 5.255 G_L1: 17.680 D_real: 0.001 D_fake: 0.028 \n",
            "(epoch: 468, iters: 268, time: 0.024, data: 0.001) G_GAN: 7.761 G_L1: 16.335 D_real: 0.000 D_fake: 0.911 \n",
            "End of epoch 468 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000877\n",
            "(epoch: 469, iters: 72, time: 0.027, data: 0.001) G_GAN: 9.126 G_L1: 17.798 D_real: 0.005 D_fake: 0.000 \n",
            "(epoch: 469, iters: 172, time: 0.023, data: 0.001) G_GAN: 4.821 G_L1: 14.067 D_real: 0.465 D_fake: 0.010 \n",
            "(epoch: 469, iters: 272, time: 0.611, data: 0.001) G_GAN: 6.227 G_L1: 16.501 D_real: 0.020 D_fake: 0.006 \n",
            "End of epoch 469 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000870\n",
            "(epoch: 470, iters: 76, time: 0.024, data: 0.001) G_GAN: 10.627 G_L1: 13.506 D_real: 0.154 D_fake: 0.000 \n",
            "(epoch: 470, iters: 176, time: 0.023, data: 0.001) G_GAN: 8.870 G_L1: 13.983 D_real: 0.060 D_fake: 0.000 \n",
            "(epoch: 470, iters: 276, time: 0.023, data: 0.001) G_GAN: 6.523 G_L1: 15.637 D_real: 0.001 D_fake: 0.012 \n",
            "saving the model at the end of epoch 470, iters 139120\n",
            "End of epoch 470 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000864\n",
            "(epoch: 471, iters: 80, time: 0.473, data: 0.001) G_GAN: 6.197 G_L1: 14.879 D_real: 0.075 D_fake: 0.006 \n",
            "(epoch: 471, iters: 180, time: 0.024, data: 0.001) G_GAN: 6.116 G_L1: 15.799 D_real: 0.020 D_fake: 0.007 \n",
            "(epoch: 471, iters: 280, time: 0.024, data: 0.001) G_GAN: 6.997 G_L1: 17.203 D_real: 0.004 D_fake: 0.053 \n",
            "End of epoch 471 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000857\n",
            "(epoch: 472, iters: 84, time: 0.023, data: 0.001) G_GAN: 6.106 G_L1: 15.569 D_real: 0.028 D_fake: 0.008 \n",
            "(epoch: 472, iters: 184, time: 0.441, data: 0.002) G_GAN: 10.491 G_L1: 18.983 D_real: 0.133 D_fake: 0.000 \n",
            "(epoch: 472, iters: 284, time: 0.024, data: 0.001) G_GAN: 3.233 G_L1: 15.965 D_real: 0.363 D_fake: 0.099 \n",
            "End of epoch 472 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000850\n",
            "(epoch: 473, iters: 88, time: 0.024, data: 0.001) G_GAN: 10.949 G_L1: 19.735 D_real: 0.033 D_fake: 0.000 \n",
            "(epoch: 473, iters: 188, time: 0.024, data: 0.001) G_GAN: 5.098 G_L1: 16.464 D_real: 0.008 D_fake: 0.037 \n",
            "(epoch: 473, iters: 288, time: 0.452, data: 0.001) G_GAN: 4.680 G_L1: 15.931 D_real: 0.035 D_fake: 0.074 \n",
            "saving the latest model (epoch 473, total_iters 140000)\n",
            "End of epoch 473 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000844\n",
            "(epoch: 474, iters: 92, time: 0.023, data: 0.001) G_GAN: 5.974 G_L1: 16.545 D_real: 0.001 D_fake: 0.091 \n",
            "(epoch: 474, iters: 192, time: 0.023, data: 0.001) G_GAN: 6.741 G_L1: 17.905 D_real: 0.001 D_fake: 0.011 \n",
            "(epoch: 474, iters: 292, time: 0.027, data: 0.001) G_GAN: 6.821 G_L1: 11.887 D_real: 0.040 D_fake: 0.003 \n",
            "End of epoch 474 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000837\n",
            "(epoch: 475, iters: 96, time: 0.460, data: 0.001) G_GAN: 7.770 G_L1: 17.089 D_real: 0.103 D_fake: 0.001 \n",
            "(epoch: 475, iters: 196, time: 0.028, data: 0.001) G_GAN: 4.573 G_L1: 16.728 D_real: 0.236 D_fake: 0.024 \n",
            "(epoch: 475, iters: 296, time: 0.025, data: 0.002) G_GAN: 8.807 G_L1: 19.327 D_real: 0.054 D_fake: 0.001 \n",
            "saving the model at the end of epoch 475, iters 140600\n",
            "End of epoch 475 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0000831\n",
            "(epoch: 476, iters: 100, time: 0.024, data: 0.129) G_GAN: 9.060 G_L1: 23.520 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 476, iters: 200, time: 0.583, data: 0.001) G_GAN: 7.176 G_L1: 14.485 D_real: 0.431 D_fake: 0.002 \n",
            "End of epoch 476 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000824\n",
            "(epoch: 477, iters: 4, time: 0.038, data: 0.001) G_GAN: 11.415 G_L1: 16.252 D_real: 0.035 D_fake: 0.000 \n",
            "(epoch: 477, iters: 104, time: 0.024, data: 0.000) G_GAN: 6.875 G_L1: 16.179 D_real: 0.000 D_fake: 0.006 \n",
            "(epoch: 477, iters: 204, time: 0.024, data: 0.001) G_GAN: 7.422 G_L1: 14.743 D_real: 0.112 D_fake: 0.006 \n",
            "End of epoch 477 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000817\n",
            "(epoch: 478, iters: 8, time: 0.482, data: 0.001) G_GAN: 5.798 G_L1: 17.869 D_real: 0.009 D_fake: 0.008 \n",
            "(epoch: 478, iters: 108, time: 0.024, data: 0.001) G_GAN: 7.162 G_L1: 16.395 D_real: 0.005 D_fake: 0.009 \n",
            "(epoch: 478, iters: 208, time: 0.029, data: 0.001) G_GAN: 6.543 G_L1: 16.737 D_real: 0.019 D_fake: 0.009 \n",
            "End of epoch 478 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000811\n",
            "(epoch: 479, iters: 12, time: 0.023, data: 0.001) G_GAN: 9.308 G_L1: 12.785 D_real: 0.005 D_fake: 0.003 \n",
            "(epoch: 479, iters: 112, time: 0.432, data: 0.001) G_GAN: 5.219 G_L1: 17.051 D_real: 0.012 D_fake: 0.028 \n",
            "(epoch: 479, iters: 212, time: 0.023, data: 0.002) G_GAN: 4.585 G_L1: 14.049 D_real: 0.004 D_fake: 0.098 \n",
            "End of epoch 479 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000804\n",
            "(epoch: 480, iters: 16, time: 0.023, data: 0.001) G_GAN: 6.191 G_L1: 13.074 D_real: 0.017 D_fake: 0.018 \n",
            "(epoch: 480, iters: 116, time: 0.028, data: 0.001) G_GAN: 6.462 G_L1: 14.653 D_real: 0.073 D_fake: 0.013 \n",
            "(epoch: 480, iters: 216, time: 0.479, data: 0.002) G_GAN: 7.661 G_L1: 15.687 D_real: 0.040 D_fake: 0.002 \n",
            "saving the model at the end of epoch 480, iters 142080\n",
            "End of epoch 480 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000797\n",
            "(epoch: 481, iters: 20, time: 0.023, data: 0.002) G_GAN: 4.451 G_L1: 15.618 D_real: 0.021 D_fake: 0.078 \n",
            "(epoch: 481, iters: 120, time: 0.027, data: 0.001) G_GAN: 8.252 G_L1: 15.965 D_real: 0.089 D_fake: 0.001 \n",
            "(epoch: 481, iters: 220, time: 0.024, data: 0.001) G_GAN: 6.840 G_L1: 14.322 D_real: 0.026 D_fake: 0.004 \n",
            "End of epoch 481 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000791\n",
            "(epoch: 482, iters: 24, time: 0.507, data: 0.001) G_GAN: 9.379 G_L1: 15.893 D_real: 0.009 D_fake: 0.002 \n",
            "(epoch: 482, iters: 124, time: 0.024, data: 0.001) G_GAN: 8.477 G_L1: 16.979 D_real: 0.058 D_fake: 0.002 \n",
            "(epoch: 482, iters: 224, time: 0.023, data: 0.001) G_GAN: 4.709 G_L1: 13.385 D_real: 0.035 D_fake: 0.143 \n",
            "End of epoch 482 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000784\n",
            "(epoch: 483, iters: 28, time: 0.024, data: 0.001) G_GAN: 4.382 G_L1: 12.624 D_real: 0.003 D_fake: 0.100 \n",
            "(epoch: 483, iters: 128, time: 0.420, data: 0.001) G_GAN: 4.530 G_L1: 17.651 D_real: 0.032 D_fake: 0.046 \n",
            "(epoch: 483, iters: 228, time: 0.023, data: 0.001) G_GAN: 8.390 G_L1: 13.077 D_real: 0.044 D_fake: 0.001 \n",
            "End of epoch 483 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000777\n",
            "(epoch: 484, iters: 32, time: 0.030, data: 0.001) G_GAN: 7.740 G_L1: 15.241 D_real: 0.008 D_fake: 0.010 \n",
            "(epoch: 484, iters: 132, time: 0.025, data: 0.001) G_GAN: 6.650 G_L1: 14.012 D_real: 0.107 D_fake: 0.002 \n",
            "(epoch: 484, iters: 232, time: 0.503, data: 0.001) G_GAN: 10.877 G_L1: 13.345 D_real: 0.139 D_fake: 0.000 \n",
            "End of epoch 484 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000771\n",
            "(epoch: 485, iters: 36, time: 0.024, data: 0.002) G_GAN: 5.401 G_L1: 15.291 D_real: 0.013 D_fake: 0.010 \n",
            "(epoch: 485, iters: 136, time: 0.042, data: 0.001) G_GAN: 6.452 G_L1: 14.274 D_real: 0.009 D_fake: 0.014 \n",
            "(epoch: 485, iters: 236, time: 0.030, data: 0.001) G_GAN: 8.113 G_L1: 16.759 D_real: 0.017 D_fake: 0.003 \n",
            "saving the model at the end of epoch 485, iters 143560\n",
            "End of epoch 485 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000764\n",
            "(epoch: 486, iters: 40, time: 0.534, data: 0.002) G_GAN: 5.840 G_L1: 14.652 D_real: 0.010 D_fake: 0.011 \n",
            "(epoch: 486, iters: 140, time: 0.029, data: 0.001) G_GAN: 5.402 G_L1: 14.721 D_real: 0.023 D_fake: 0.303 \n",
            "(epoch: 486, iters: 240, time: 0.023, data: 0.001) G_GAN: 5.357 G_L1: 16.058 D_real: 0.022 D_fake: 0.062 \n",
            "End of epoch 486 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0000757\n",
            "(epoch: 487, iters: 44, time: 0.023, data: 0.001) G_GAN: 7.448 G_L1: 14.279 D_real: 0.050 D_fake: 0.006 \n",
            "(epoch: 487, iters: 144, time: 0.429, data: 0.001) G_GAN: 9.002 G_L1: 15.296 D_real: 0.004 D_fake: 0.001 \n",
            "(epoch: 487, iters: 244, time: 0.023, data: 0.001) G_GAN: 5.884 G_L1: 12.495 D_real: 0.229 D_fake: 0.004 \n",
            "End of epoch 487 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000751\n",
            "(epoch: 488, iters: 48, time: 0.024, data: 0.001) G_GAN: 5.519 G_L1: 13.326 D_real: 0.009 D_fake: 0.018 \n",
            "(epoch: 488, iters: 148, time: 0.024, data: 0.001) G_GAN: 6.062 G_L1: 24.296 D_real: 0.000 D_fake: 0.014 \n",
            "(epoch: 488, iters: 248, time: 0.473, data: 0.001) G_GAN: 9.993 G_L1: 15.349 D_real: 0.136 D_fake: 0.001 \n",
            "End of epoch 488 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000744\n",
            "(epoch: 489, iters: 52, time: 0.023, data: 0.001) G_GAN: 9.725 G_L1: 14.062 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 489, iters: 152, time: 0.030, data: 0.001) G_GAN: 7.554 G_L1: 13.751 D_real: 1.030 D_fake: 0.000 \n",
            "(epoch: 489, iters: 252, time: 0.023, data: 0.001) G_GAN: 7.659 G_L1: 16.808 D_real: 0.010 D_fake: 0.628 \n",
            "End of epoch 489 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000738\n",
            "(epoch: 490, iters: 56, time: 0.483, data: 0.001) G_GAN: 9.937 G_L1: 16.043 D_real: 0.198 D_fake: 0.000 \n",
            "(epoch: 490, iters: 156, time: 0.023, data: 0.001) G_GAN: 7.851 G_L1: 15.988 D_real: 0.022 D_fake: 0.001 \n",
            "(epoch: 490, iters: 256, time: 0.023, data: 0.001) G_GAN: 6.359 G_L1: 14.609 D_real: 0.029 D_fake: 0.017 \n",
            "saving the latest model (epoch 490, total_iters 145000)\n",
            "saving the model at the end of epoch 490, iters 145040\n",
            "End of epoch 490 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000731\n",
            "(epoch: 491, iters: 60, time: 0.023, data: 0.001) G_GAN: 11.000 G_L1: 27.130 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 491, iters: 160, time: 0.573, data: 0.001) G_GAN: 6.443 G_L1: 15.644 D_real: 0.008 D_fake: 0.007 \n",
            "(epoch: 491, iters: 260, time: 0.024, data: 0.001) G_GAN: 7.542 G_L1: 15.328 D_real: 0.022 D_fake: 0.011 \n",
            "End of epoch 491 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000724\n",
            "(epoch: 492, iters: 64, time: 0.029, data: 0.001) G_GAN: 5.270 G_L1: 15.267 D_real: 0.032 D_fake: 0.018 \n",
            "(epoch: 492, iters: 164, time: 0.024, data: 0.001) G_GAN: 7.827 G_L1: 12.627 D_real: 0.028 D_fake: 0.003 \n",
            "(epoch: 492, iters: 264, time: 0.486, data: 0.001) G_GAN: 7.328 G_L1: 15.497 D_real: 0.006 D_fake: 0.009 \n",
            "End of epoch 492 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000718\n",
            "(epoch: 493, iters: 68, time: 0.023, data: 0.001) G_GAN: 6.679 G_L1: 15.067 D_real: 0.030 D_fake: 0.005 \n",
            "(epoch: 493, iters: 168, time: 0.023, data: 0.001) G_GAN: 5.541 G_L1: 13.316 D_real: 0.023 D_fake: 0.031 \n",
            "(epoch: 493, iters: 268, time: 0.030, data: 0.001) G_GAN: 10.547 G_L1: 19.550 D_real: 0.016 D_fake: 0.000 \n",
            "End of epoch 493 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000711\n",
            "(epoch: 494, iters: 72, time: 0.444, data: 0.001) G_GAN: 8.550 G_L1: 14.737 D_real: 0.006 D_fake: 0.001 \n",
            "(epoch: 494, iters: 172, time: 0.024, data: 0.002) G_GAN: 11.479 G_L1: 18.589 D_real: 0.046 D_fake: 0.000 \n",
            "(epoch: 494, iters: 272, time: 0.022, data: 0.001) G_GAN: 5.201 G_L1: 16.566 D_real: 0.003 D_fake: 0.036 \n",
            "End of epoch 494 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000704\n",
            "(epoch: 495, iters: 76, time: 0.023, data: 0.001) G_GAN: 8.421 G_L1: 15.834 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 495, iters: 176, time: 0.475, data: 0.001) G_GAN: 5.301 G_L1: 15.901 D_real: 0.000 D_fake: 0.030 \n",
            "(epoch: 495, iters: 276, time: 0.023, data: 0.001) G_GAN: 5.866 G_L1: 13.567 D_real: 0.037 D_fake: 0.008 \n",
            "saving the model at the end of epoch 495, iters 146520\n",
            "End of epoch 495 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000698\n",
            "(epoch: 496, iters: 80, time: 0.026, data: 0.001) G_GAN: 4.337 G_L1: 19.507 D_real: 0.124 D_fake: 0.022 \n",
            "(epoch: 496, iters: 180, time: 0.023, data: 0.002) G_GAN: 6.550 G_L1: 17.581 D_real: 0.017 D_fake: 0.062 \n",
            "(epoch: 496, iters: 280, time: 0.621, data: 0.001) G_GAN: 3.799 G_L1: 16.064 D_real: 0.213 D_fake: 0.046 \n",
            "End of epoch 496 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0000691\n",
            "(epoch: 497, iters: 84, time: 0.023, data: 0.001) G_GAN: 7.545 G_L1: 13.641 D_real: 0.016 D_fake: 0.004 \n",
            "(epoch: 497, iters: 184, time: 0.028, data: 0.002) G_GAN: 7.203 G_L1: 13.793 D_real: 0.093 D_fake: 0.018 \n",
            "(epoch: 497, iters: 284, time: 0.032, data: 0.001) G_GAN: 7.099 G_L1: 15.635 D_real: 0.000 D_fake: 0.003 \n",
            "End of epoch 497 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000684\n",
            "(epoch: 498, iters: 88, time: 0.494, data: 0.001) G_GAN: 6.489 G_L1: 16.635 D_real: 0.036 D_fake: 0.010 \n",
            "(epoch: 498, iters: 188, time: 0.024, data: 0.002) G_GAN: 5.327 G_L1: 13.333 D_real: 0.001 D_fake: 0.020 \n",
            "(epoch: 498, iters: 288, time: 0.023, data: 0.001) G_GAN: 5.563 G_L1: 15.031 D_real: 0.046 D_fake: 0.021 \n",
            "End of epoch 498 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000678\n",
            "(epoch: 499, iters: 92, time: 0.031, data: 0.001) G_GAN: 8.529 G_L1: 18.738 D_real: 0.001 D_fake: 0.002 \n",
            "(epoch: 499, iters: 192, time: 0.482, data: 0.001) G_GAN: 8.484 G_L1: 16.534 D_real: 0.021 D_fake: 0.002 \n",
            "(epoch: 499, iters: 292, time: 0.023, data: 0.001) G_GAN: 5.424 G_L1: 15.017 D_real: 0.000 D_fake: 0.199 \n",
            "End of epoch 499 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000671\n",
            "(epoch: 500, iters: 96, time: 0.025, data: 0.001) G_GAN: 5.763 G_L1: 21.421 D_real: 0.003 D_fake: 0.056 \n",
            "(epoch: 500, iters: 196, time: 0.026, data: 0.001) G_GAN: 8.558 G_L1: 18.997 D_real: 0.002 D_fake: 0.006 \n",
            "(epoch: 500, iters: 296, time: 0.517, data: 0.001) G_GAN: 5.458 G_L1: 14.250 D_real: 0.002 D_fake: 0.033 \n",
            "saving the model at the end of epoch 500, iters 148000\n",
            "End of epoch 500 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000664\n",
            "(epoch: 501, iters: 100, time: 0.025, data: 0.104) G_GAN: 8.105 G_L1: 14.317 D_real: 0.156 D_fake: 0.001 \n",
            "(epoch: 501, iters: 200, time: 0.024, data: 0.001) G_GAN: 6.455 G_L1: 12.797 D_real: 0.059 D_fake: 0.009 \n",
            "End of epoch 501 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000658\n",
            "(epoch: 502, iters: 4, time: 0.034, data: 0.001) G_GAN: 7.996 G_L1: 16.936 D_real: 0.006 D_fake: 0.010 \n",
            "(epoch: 502, iters: 104, time: 0.459, data: 0.000) G_GAN: 8.369 G_L1: 14.828 D_real: 0.028 D_fake: 0.002 \n",
            "(epoch: 502, iters: 204, time: 0.024, data: 0.001) G_GAN: 5.292 G_L1: 15.322 D_real: 0.000 D_fake: 0.206 \n",
            "End of epoch 502 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0000651\n",
            "(epoch: 503, iters: 8, time: 0.024, data: 0.001) G_GAN: 5.143 G_L1: 12.945 D_real: 0.018 D_fake: 0.019 \n",
            "(epoch: 503, iters: 108, time: 0.023, data: 0.001) G_GAN: 5.326 G_L1: 13.214 D_real: 0.001 D_fake: 0.025 \n",
            "(epoch: 503, iters: 208, time: 0.539, data: 0.001) G_GAN: 4.568 G_L1: 13.799 D_real: 0.002 D_fake: 0.098 \n",
            "End of epoch 503 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000645\n",
            "(epoch: 504, iters: 12, time: 0.023, data: 0.002) G_GAN: 9.881 G_L1: 20.069 D_real: 0.020 D_fake: 0.000 \n",
            "(epoch: 504, iters: 112, time: 0.023, data: 0.001) G_GAN: 5.800 G_L1: 13.921 D_real: 0.330 D_fake: 0.006 \n",
            "(epoch: 504, iters: 212, time: 0.030, data: 0.001) G_GAN: 5.318 G_L1: 16.981 D_real: 0.003 D_fake: 0.031 \n",
            "End of epoch 504 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000638\n",
            "(epoch: 505, iters: 16, time: 0.508, data: 0.001) G_GAN: 4.300 G_L1: 11.533 D_real: 0.003 D_fake: 0.047 \n",
            "(epoch: 505, iters: 116, time: 0.029, data: 0.001) G_GAN: 5.910 G_L1: 14.022 D_real: 0.005 D_fake: 0.010 \n",
            "(epoch: 505, iters: 216, time: 0.024, data: 0.002) G_GAN: 6.340 G_L1: 13.734 D_real: 0.045 D_fake: 0.015 \n",
            "saving the model at the end of epoch 505, iters 149480\n",
            "End of epoch 505 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0000631\n",
            "(epoch: 506, iters: 20, time: 0.025, data: 0.001) G_GAN: 8.085 G_L1: 17.649 D_real: 0.019 D_fake: 0.012 \n",
            "(epoch: 506, iters: 120, time: 0.491, data: 0.001) G_GAN: 8.004 G_L1: 19.384 D_real: 0.019 D_fake: 0.002 \n",
            "(epoch: 506, iters: 220, time: 0.023, data: 0.002) G_GAN: 6.228 G_L1: 16.309 D_real: 0.007 D_fake: 0.009 \n",
            "End of epoch 506 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0000625\n",
            "(epoch: 507, iters: 24, time: 0.034, data: 0.001) G_GAN: 7.446 G_L1: 12.931 D_real: 0.001 D_fake: 0.002 \n",
            "(epoch: 507, iters: 124, time: 0.024, data: 0.001) G_GAN: 7.359 G_L1: 12.693 D_real: 0.028 D_fake: 1.460 \n",
            "(epoch: 507, iters: 224, time: 0.481, data: 0.002) G_GAN: 7.769 G_L1: 14.350 D_real: 0.035 D_fake: 0.001 \n",
            "saving the latest model (epoch 507, total_iters 150000)\n",
            "End of epoch 507 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000618\n",
            "(epoch: 508, iters: 28, time: 0.029, data: 0.002) G_GAN: 6.578 G_L1: 13.790 D_real: 0.011 D_fake: 0.009 \n",
            "(epoch: 508, iters: 128, time: 0.024, data: 0.002) G_GAN: 5.970 G_L1: 17.286 D_real: 0.002 D_fake: 0.028 \n",
            "(epoch: 508, iters: 228, time: 0.025, data: 0.001) G_GAN: 6.109 G_L1: 14.643 D_real: 0.001 D_fake: 0.010 \n",
            "End of epoch 508 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000611\n",
            "(epoch: 509, iters: 32, time: 0.507, data: 0.002) G_GAN: 7.781 G_L1: 20.947 D_real: 0.077 D_fake: 0.008 \n",
            "(epoch: 509, iters: 132, time: 0.024, data: 0.001) G_GAN: 4.668 G_L1: 13.858 D_real: 0.033 D_fake: 0.048 \n",
            "(epoch: 509, iters: 232, time: 0.024, data: 0.001) G_GAN: 6.510 G_L1: 17.143 D_real: 0.032 D_fake: 0.007 \n",
            "End of epoch 509 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000605\n",
            "(epoch: 510, iters: 36, time: 0.024, data: 0.001) G_GAN: 9.409 G_L1: 15.127 D_real: 0.014 D_fake: 0.002 \n",
            "(epoch: 510, iters: 136, time: 0.457, data: 0.001) G_GAN: 4.116 G_L1: 13.369 D_real: 0.005 D_fake: 0.068 \n",
            "(epoch: 510, iters: 236, time: 0.025, data: 0.002) G_GAN: 8.218 G_L1: 15.583 D_real: 0.007 D_fake: 0.001 \n",
            "saving the model at the end of epoch 510, iters 150960\n",
            "End of epoch 510 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000598\n",
            "(epoch: 511, iters: 40, time: 0.024, data: 0.001) G_GAN: 5.762 G_L1: 15.032 D_real: 0.000 D_fake: 0.032 \n",
            "(epoch: 511, iters: 140, time: 0.024, data: 0.001) G_GAN: 5.581 G_L1: 12.958 D_real: 0.040 D_fake: 0.016 \n",
            "(epoch: 511, iters: 240, time: 0.706, data: 0.001) G_GAN: 5.538 G_L1: 14.885 D_real: 0.010 D_fake: 0.020 \n",
            "End of epoch 511 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0000591\n",
            "(epoch: 512, iters: 44, time: 0.024, data: 0.001) G_GAN: 6.689 G_L1: 14.406 D_real: 0.000 D_fake: 0.006 \n",
            "(epoch: 512, iters: 144, time: 0.027, data: 0.001) G_GAN: 6.638 G_L1: 14.900 D_real: 0.007 D_fake: 0.003 \n",
            "(epoch: 512, iters: 244, time: 0.025, data: 0.001) G_GAN: 6.728 G_L1: 13.688 D_real: 0.000 D_fake: 0.014 \n",
            "End of epoch 512 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000585\n",
            "(epoch: 513, iters: 48, time: 0.500, data: 0.002) G_GAN: 7.132 G_L1: 15.321 D_real: 0.003 D_fake: 0.006 \n",
            "(epoch: 513, iters: 148, time: 0.025, data: 0.001) G_GAN: 7.612 G_L1: 14.178 D_real: 0.010 D_fake: 0.004 \n",
            "(epoch: 513, iters: 248, time: 0.024, data: 0.001) G_GAN: 6.829 G_L1: 14.536 D_real: 0.019 D_fake: 0.034 \n",
            "End of epoch 513 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000578\n",
            "(epoch: 514, iters: 52, time: 0.023, data: 0.001) G_GAN: 6.140 G_L1: 18.659 D_real: 0.023 D_fake: 0.018 \n",
            "(epoch: 514, iters: 152, time: 0.504, data: 0.001) G_GAN: 9.167 G_L1: 13.604 D_real: 0.006 D_fake: 0.001 \n",
            "(epoch: 514, iters: 252, time: 0.029, data: 0.001) G_GAN: 4.271 G_L1: 14.894 D_real: 0.034 D_fake: 0.111 \n",
            "End of epoch 514 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000571\n",
            "(epoch: 515, iters: 56, time: 0.023, data: 0.001) G_GAN: 4.515 G_L1: 13.992 D_real: 0.011 D_fake: 0.137 \n",
            "(epoch: 515, iters: 156, time: 0.035, data: 0.001) G_GAN: 5.666 G_L1: 13.363 D_real: 0.007 D_fake: 0.011 \n",
            "(epoch: 515, iters: 256, time: 0.463, data: 0.002) G_GAN: 8.609 G_L1: 15.156 D_real: 0.001 D_fake: 0.003 \n",
            "saving the model at the end of epoch 515, iters 152440\n",
            "End of epoch 515 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000565\n",
            "(epoch: 516, iters: 60, time: 0.023, data: 0.001) G_GAN: 5.361 G_L1: 18.521 D_real: 0.356 D_fake: 0.026 \n",
            "(epoch: 516, iters: 160, time: 0.025, data: 0.001) G_GAN: 8.687 G_L1: 15.805 D_real: 0.001 D_fake: 0.002 \n",
            "(epoch: 516, iters: 260, time: 0.023, data: 0.001) G_GAN: 6.786 G_L1: 14.584 D_real: 0.008 D_fake: 0.008 \n",
            "End of epoch 516 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000558\n",
            "(epoch: 517, iters: 64, time: 0.529, data: 0.001) G_GAN: 9.129 G_L1: 12.898 D_real: 0.005 D_fake: 0.001 \n",
            "(epoch: 517, iters: 164, time: 0.024, data: 0.002) G_GAN: 10.025 G_L1: 16.232 D_real: 0.307 D_fake: 0.000 \n",
            "(epoch: 517, iters: 264, time: 0.028, data: 0.001) G_GAN: 6.892 G_L1: 17.853 D_real: 0.000 D_fake: 0.007 \n",
            "End of epoch 517 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0000551\n",
            "(epoch: 518, iters: 68, time: 0.029, data: 0.001) G_GAN: 5.428 G_L1: 14.960 D_real: 0.175 D_fake: 0.008 \n",
            "(epoch: 518, iters: 168, time: 0.494, data: 0.001) G_GAN: 7.057 G_L1: 14.738 D_real: 0.009 D_fake: 0.581 \n",
            "(epoch: 518, iters: 268, time: 0.028, data: 0.001) G_GAN: 7.444 G_L1: 13.405 D_real: 0.319 D_fake: 0.002 \n",
            "End of epoch 518 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000545\n",
            "(epoch: 519, iters: 72, time: 0.023, data: 0.001) G_GAN: 7.209 G_L1: 17.889 D_real: 0.002 D_fake: 0.003 \n",
            "(epoch: 519, iters: 172, time: 0.024, data: 0.001) G_GAN: 5.008 G_L1: 12.887 D_real: 0.002 D_fake: 0.027 \n",
            "(epoch: 519, iters: 272, time: 0.483, data: 0.001) G_GAN: 5.977 G_L1: 17.369 D_real: 0.023 D_fake: 0.435 \n",
            "End of epoch 519 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000538\n",
            "(epoch: 520, iters: 76, time: 0.024, data: 0.002) G_GAN: 5.377 G_L1: 12.822 D_real: 0.001 D_fake: 0.021 \n",
            "(epoch: 520, iters: 176, time: 0.029, data: 0.001) G_GAN: 7.317 G_L1: 14.987 D_real: 0.013 D_fake: 0.006 \n",
            "(epoch: 520, iters: 276, time: 0.024, data: 0.001) G_GAN: 5.646 G_L1: 14.587 D_real: 0.006 D_fake: 0.031 \n",
            "saving the model at the end of epoch 520, iters 153920\n",
            "End of epoch 520 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0000532\n",
            "(epoch: 521, iters: 80, time: 0.522, data: 0.001) G_GAN: 9.681 G_L1: 14.444 D_real: 0.072 D_fake: 0.000 \n",
            "(epoch: 521, iters: 180, time: 0.024, data: 0.001) G_GAN: 7.072 G_L1: 17.445 D_real: 0.108 D_fake: 0.019 \n",
            "(epoch: 521, iters: 280, time: 0.025, data: 0.001) G_GAN: 4.473 G_L1: 15.126 D_real: 0.013 D_fake: 0.034 \n",
            "End of epoch 521 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000525\n",
            "(epoch: 522, iters: 84, time: 0.023, data: 0.001) G_GAN: 6.943 G_L1: 14.238 D_real: 0.203 D_fake: 0.002 \n",
            "(epoch: 522, iters: 184, time: 0.497, data: 0.001) G_GAN: 9.180 G_L1: 12.842 D_real: 0.074 D_fake: 0.001 \n",
            "(epoch: 522, iters: 284, time: 0.024, data: 0.002) G_GAN: 12.463 G_L1: 18.541 D_real: 0.003 D_fake: 0.000 \n",
            "End of epoch 522 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000518\n",
            "(epoch: 523, iters: 88, time: 0.023, data: 0.001) G_GAN: 7.393 G_L1: 15.412 D_real: 0.008 D_fake: 0.011 \n",
            "(epoch: 523, iters: 188, time: 0.024, data: 0.001) G_GAN: 5.716 G_L1: 16.013 D_real: 0.001 D_fake: 0.033 \n",
            "(epoch: 523, iters: 288, time: 0.479, data: 0.001) G_GAN: 6.163 G_L1: 14.518 D_real: 0.009 D_fake: 0.011 \n",
            "End of epoch 523 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000512\n",
            "(epoch: 524, iters: 92, time: 0.024, data: 0.001) G_GAN: 6.301 G_L1: 15.881 D_real: 0.001 D_fake: 0.474 \n",
            "(epoch: 524, iters: 192, time: 0.024, data: 0.001) G_GAN: 7.988 G_L1: 14.118 D_real: 0.009 D_fake: 0.607 \n",
            "saving the latest model (epoch 524, total_iters 155000)\n",
            "(epoch: 524, iters: 292, time: 0.022, data: 0.002) G_GAN: 6.079 G_L1: 15.555 D_real: 0.004 D_fake: 0.013 \n",
            "End of epoch 524 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000505\n",
            "(epoch: 525, iters: 96, time: 0.515, data: 0.001) G_GAN: 6.581 G_L1: 15.053 D_real: 0.036 D_fake: 0.006 \n",
            "(epoch: 525, iters: 196, time: 0.023, data: 0.001) G_GAN: 10.055 G_L1: 13.126 D_real: 0.107 D_fake: 0.000 \n",
            "(epoch: 525, iters: 296, time: 0.027, data: 0.001) G_GAN: 5.007 G_L1: 13.717 D_real: 0.005 D_fake: 0.026 \n",
            "saving the model at the end of epoch 525, iters 155400\n",
            "End of epoch 525 / 600 \t Time Taken: 10 sec\n",
            "learning rate = 0.0000498\n",
            "(epoch: 526, iters: 100, time: 0.031, data: 0.117) G_GAN: 7.199 G_L1: 14.735 D_real: 0.020 D_fake: 0.005 \n",
            "(epoch: 526, iters: 200, time: 1.128, data: 0.001) G_GAN: 8.031 G_L1: 15.397 D_real: 0.029 D_fake: 0.002 \n",
            "End of epoch 526 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0000492\n",
            "(epoch: 527, iters: 4, time: 0.034, data: 0.001) G_GAN: 8.679 G_L1: 17.289 D_real: 0.018 D_fake: 0.001 \n",
            "(epoch: 527, iters: 104, time: 0.029, data: 0.000) G_GAN: 8.664 G_L1: 15.520 D_real: 0.007 D_fake: 0.001 \n",
            "(epoch: 527, iters: 204, time: 0.031, data: 0.001) G_GAN: 5.165 G_L1: 17.462 D_real: 0.000 D_fake: 0.222 \n",
            "End of epoch 527 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000485\n",
            "(epoch: 528, iters: 8, time: 0.489, data: 0.001) G_GAN: 5.272 G_L1: 14.032 D_real: 0.003 D_fake: 0.138 \n",
            "(epoch: 528, iters: 108, time: 0.023, data: 0.000) G_GAN: 5.723 G_L1: 14.772 D_real: 0.006 D_fake: 0.026 \n",
            "(epoch: 528, iters: 208, time: 0.023, data: 0.001) G_GAN: 5.310 G_L1: 14.208 D_real: 0.016 D_fake: 0.231 \n",
            "End of epoch 528 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000478\n",
            "(epoch: 529, iters: 12, time: 0.024, data: 0.001) G_GAN: 6.844 G_L1: 16.039 D_real: 0.107 D_fake: 0.016 \n",
            "(epoch: 529, iters: 112, time: 0.530, data: 0.001) G_GAN: 7.399 G_L1: 15.822 D_real: 0.001 D_fake: 0.006 \n",
            "(epoch: 529, iters: 212, time: 0.023, data: 0.001) G_GAN: 8.199 G_L1: 18.000 D_real: 0.033 D_fake: 0.011 \n",
            "End of epoch 529 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000472\n",
            "(epoch: 530, iters: 16, time: 0.023, data: 0.001) G_GAN: 6.983 G_L1: 15.740 D_real: 0.020 D_fake: 0.010 \n",
            "(epoch: 530, iters: 116, time: 0.023, data: 0.001) G_GAN: 7.014 G_L1: 11.876 D_real: 0.088 D_fake: 0.003 \n",
            "(epoch: 530, iters: 216, time: 0.514, data: 0.001) G_GAN: 9.956 G_L1: 15.088 D_real: 0.008 D_fake: 0.001 \n",
            "saving the model at the end of epoch 530, iters 156880\n",
            "End of epoch 530 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000465\n",
            "(epoch: 531, iters: 20, time: 0.025, data: 0.001) G_GAN: 7.736 G_L1: 13.597 D_real: 0.007 D_fake: 0.002 \n",
            "(epoch: 531, iters: 120, time: 0.024, data: 0.001) G_GAN: 7.076 G_L1: 13.935 D_real: 0.024 D_fake: 0.003 \n",
            "(epoch: 531, iters: 220, time: 0.023, data: 0.001) G_GAN: 4.762 G_L1: 13.291 D_real: 0.006 D_fake: 0.111 \n",
            "End of epoch 531 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000458\n",
            "(epoch: 532, iters: 24, time: 0.547, data: 0.001) G_GAN: 8.551 G_L1: 14.932 D_real: 0.011 D_fake: 0.001 \n",
            "(epoch: 532, iters: 124, time: 0.023, data: 0.001) G_GAN: 7.589 G_L1: 14.007 D_real: 0.005 D_fake: 0.004 \n",
            "(epoch: 532, iters: 224, time: 0.024, data: 0.001) G_GAN: 6.923 G_L1: 14.740 D_real: 0.009 D_fake: 0.010 \n",
            "End of epoch 532 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000452\n",
            "(epoch: 533, iters: 28, time: 0.022, data: 0.001) G_GAN: 5.095 G_L1: 14.414 D_real: 0.001 D_fake: 0.035 \n",
            "(epoch: 533, iters: 128, time: 0.470, data: 0.001) G_GAN: 5.038 G_L1: 19.881 D_real: 0.006 D_fake: 0.036 \n",
            "(epoch: 533, iters: 228, time: 0.023, data: 0.002) G_GAN: 5.107 G_L1: 15.395 D_real: 0.010 D_fake: 0.074 \n",
            "End of epoch 533 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000445\n",
            "(epoch: 534, iters: 32, time: 0.026, data: 0.001) G_GAN: 7.013 G_L1: 15.850 D_real: 0.002 D_fake: 0.031 \n",
            "(epoch: 534, iters: 132, time: 0.024, data: 0.001) G_GAN: 9.715 G_L1: 15.075 D_real: 0.028 D_fake: 0.000 \n",
            "(epoch: 534, iters: 232, time: 0.529, data: 0.001) G_GAN: 5.951 G_L1: 16.150 D_real: 0.000 D_fake: 0.026 \n",
            "End of epoch 534 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000439\n",
            "(epoch: 535, iters: 36, time: 0.024, data: 0.001) G_GAN: 5.436 G_L1: 15.318 D_real: 0.002 D_fake: 0.272 \n",
            "(epoch: 535, iters: 136, time: 0.023, data: 0.001) G_GAN: 9.550 G_L1: 20.449 D_real: 0.047 D_fake: 0.000 \n",
            "(epoch: 535, iters: 236, time: 0.024, data: 0.001) G_GAN: 5.573 G_L1: 12.091 D_real: 0.011 D_fake: 0.321 \n",
            "saving the model at the end of epoch 535, iters 158360\n",
            "End of epoch 535 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000432\n",
            "(epoch: 536, iters: 40, time: 0.526, data: 0.001) G_GAN: 8.374 G_L1: 13.329 D_real: 0.004 D_fake: 0.001 \n",
            "(epoch: 536, iters: 140, time: 0.027, data: 0.001) G_GAN: 4.379 G_L1: 15.927 D_real: 0.003 D_fake: 0.126 \n",
            "(epoch: 536, iters: 240, time: 0.023, data: 0.001) G_GAN: 5.663 G_L1: 15.774 D_real: 0.003 D_fake: 0.266 \n",
            "End of epoch 536 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0000425\n",
            "(epoch: 537, iters: 44, time: 0.023, data: 0.001) G_GAN: 5.516 G_L1: 14.409 D_real: 0.136 D_fake: 0.016 \n",
            "(epoch: 537, iters: 144, time: 0.501, data: 0.001) G_GAN: 5.099 G_L1: 16.942 D_real: 0.024 D_fake: 0.171 \n",
            "(epoch: 537, iters: 244, time: 0.024, data: 0.002) G_GAN: 8.080 G_L1: 13.669 D_real: 0.004 D_fake: 0.001 \n",
            "End of epoch 537 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000419\n",
            "(epoch: 538, iters: 48, time: 0.023, data: 0.001) G_GAN: 5.755 G_L1: 14.003 D_real: 0.006 D_fake: 0.022 \n",
            "(epoch: 538, iters: 148, time: 0.024, data: 0.001) G_GAN: 6.516 G_L1: 13.070 D_real: 0.002 D_fake: 0.760 \n",
            "(epoch: 538, iters: 248, time: 0.524, data: 0.001) G_GAN: 6.230 G_L1: 13.103 D_real: 0.102 D_fake: 0.007 \n",
            "End of epoch 538 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000412\n",
            "(epoch: 539, iters: 52, time: 0.024, data: 0.002) G_GAN: 6.213 G_L1: 13.314 D_real: 0.036 D_fake: 0.037 \n",
            "(epoch: 539, iters: 152, time: 0.024, data: 0.001) G_GAN: 10.009 G_L1: 18.557 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 539, iters: 252, time: 0.023, data: 0.001) G_GAN: 7.488 G_L1: 15.182 D_real: 0.057 D_fake: 0.008 \n",
            "End of epoch 539 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000405\n",
            "(epoch: 540, iters: 56, time: 0.520, data: 0.001) G_GAN: 5.156 G_L1: 14.476 D_real: 0.007 D_fake: 0.050 \n",
            "(epoch: 540, iters: 156, time: 0.032, data: 0.001) G_GAN: 6.898 G_L1: 17.610 D_real: 0.001 D_fake: 0.013 \n",
            "(epoch: 540, iters: 256, time: 0.023, data: 0.001) G_GAN: 5.239 G_L1: 10.890 D_real: 0.009 D_fake: 0.365 \n",
            "saving the model at the end of epoch 540, iters 159840\n",
            "End of epoch 540 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0000399\n",
            "(epoch: 541, iters: 60, time: 0.024, data: 0.001) G_GAN: 4.745 G_L1: 16.386 D_real: 0.077 D_fake: 0.025 \n",
            "(epoch: 541, iters: 160, time: 0.531, data: 0.001) G_GAN: 9.973 G_L1: 15.769 D_real: 0.003 D_fake: 0.001 \n",
            "saving the latest model (epoch 541, total_iters 160000)\n",
            "(epoch: 541, iters: 260, time: 0.023, data: 0.002) G_GAN: 9.219 G_L1: 14.906 D_real: 0.018 D_fake: 0.001 \n",
            "End of epoch 541 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0000392\n",
            "(epoch: 542, iters: 64, time: 0.032, data: 0.001) G_GAN: 7.694 G_L1: 14.643 D_real: 0.001 D_fake: 0.002 \n",
            "(epoch: 542, iters: 164, time: 0.025, data: 0.001) G_GAN: 7.297 G_L1: 16.812 D_real: 0.011 D_fake: 0.004 \n",
            "(epoch: 542, iters: 264, time: 0.475, data: 0.001) G_GAN: 4.523 G_L1: 14.974 D_real: 0.003 D_fake: 0.047 \n",
            "End of epoch 542 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000385\n",
            "(epoch: 543, iters: 68, time: 0.023, data: 0.001) G_GAN: 7.913 G_L1: 12.873 D_real: 0.012 D_fake: 0.002 \n",
            "(epoch: 543, iters: 168, time: 0.024, data: 0.001) G_GAN: 6.440 G_L1: 17.894 D_real: 0.013 D_fake: 0.009 \n",
            "(epoch: 543, iters: 268, time: 0.024, data: 0.001) G_GAN: 6.084 G_L1: 14.714 D_real: 0.010 D_fake: 0.006 \n",
            "End of epoch 543 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000379\n",
            "(epoch: 544, iters: 72, time: 0.518, data: 0.001) G_GAN: 7.118 G_L1: 14.717 D_real: 0.008 D_fake: 0.008 \n",
            "(epoch: 544, iters: 172, time: 0.024, data: 0.002) G_GAN: 7.980 G_L1: 15.805 D_real: 0.001 D_fake: 0.007 \n",
            "(epoch: 544, iters: 272, time: 0.024, data: 0.001) G_GAN: 8.887 G_L1: 18.769 D_real: 0.001 D_fake: 0.001 \n",
            "End of epoch 544 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000372\n",
            "(epoch: 545, iters: 76, time: 0.023, data: 0.001) G_GAN: 8.596 G_L1: 13.989 D_real: 0.010 D_fake: 0.002 \n",
            "(epoch: 545, iters: 176, time: 0.535, data: 0.001) G_GAN: 8.360 G_L1: 19.862 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 545, iters: 276, time: 0.023, data: 0.002) G_GAN: 8.515 G_L1: 13.534 D_real: 0.013 D_fake: 0.001 \n",
            "saving the model at the end of epoch 545, iters 161320\n",
            "End of epoch 545 / 600 \t Time Taken: 10 sec\n",
            "learning rate = 0.0000365\n",
            "(epoch: 546, iters: 80, time: 0.023, data: 0.001) G_GAN: 6.913 G_L1: 11.054 D_real: 0.044 D_fake: 0.004 \n",
            "(epoch: 546, iters: 180, time: 0.030, data: 0.001) G_GAN: 6.331 G_L1: 13.685 D_real: 0.000 D_fake: 0.005 \n",
            "(epoch: 546, iters: 280, time: 0.478, data: 0.001) G_GAN: 5.237 G_L1: 13.981 D_real: 0.003 D_fake: 0.023 \n",
            "End of epoch 546 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0000359\n",
            "(epoch: 547, iters: 84, time: 0.023, data: 0.001) G_GAN: 5.981 G_L1: 12.694 D_real: 0.017 D_fake: 0.015 \n",
            "(epoch: 547, iters: 184, time: 0.031, data: 0.001) G_GAN: 5.351 G_L1: 12.437 D_real: 0.015 D_fake: 0.020 \n",
            "(epoch: 547, iters: 284, time: 0.032, data: 0.001) G_GAN: 7.650 G_L1: 15.110 D_real: 0.000 D_fake: 0.006 \n",
            "End of epoch 547 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000352\n",
            "(epoch: 548, iters: 88, time: 0.569, data: 0.002) G_GAN: 8.268 G_L1: 15.495 D_real: 0.002 D_fake: 0.002 \n",
            "(epoch: 548, iters: 188, time: 0.031, data: 0.002) G_GAN: 7.621 G_L1: 15.764 D_real: 0.012 D_fake: 0.002 \n",
            "(epoch: 548, iters: 288, time: 0.025, data: 0.002) G_GAN: 8.210 G_L1: 14.232 D_real: 0.016 D_fake: 0.002 \n",
            "End of epoch 548 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000346\n",
            "(epoch: 549, iters: 92, time: 0.023, data: 0.001) G_GAN: 10.110 G_L1: 15.749 D_real: 0.038 D_fake: 0.000 \n",
            "(epoch: 549, iters: 192, time: 0.717, data: 0.001) G_GAN: 7.564 G_L1: 14.272 D_real: 0.006 D_fake: 0.003 \n",
            "(epoch: 549, iters: 292, time: 0.022, data: 0.002) G_GAN: 6.489 G_L1: 16.964 D_real: 0.002 D_fake: 0.008 \n",
            "End of epoch 549 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000339\n",
            "(epoch: 550, iters: 96, time: 0.023, data: 0.001) G_GAN: 6.016 G_L1: 16.268 D_real: 0.153 D_fake: 0.005 \n",
            "(epoch: 550, iters: 196, time: 0.027, data: 0.001) G_GAN: 7.584 G_L1: 17.105 D_real: 0.139 D_fake: 0.001 \n",
            "(epoch: 550, iters: 296, time: 0.545, data: 0.001) G_GAN: 10.348 G_L1: 18.275 D_real: 0.017 D_fake: 0.001 \n",
            "saving the model at the end of epoch 550, iters 162800\n",
            "End of epoch 550 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0000332\n",
            "(epoch: 551, iters: 100, time: 0.024, data: 0.130) G_GAN: 5.666 G_L1: 14.986 D_real: 0.001 D_fake: 0.014 \n",
            "(epoch: 551, iters: 200, time: 0.025, data: 0.001) G_GAN: 9.383 G_L1: 12.525 D_real: 0.016 D_fake: 0.000 \n",
            "End of epoch 551 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000326\n",
            "(epoch: 552, iters: 4, time: 0.024, data: 0.001) G_GAN: 8.968 G_L1: 12.349 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 552, iters: 104, time: 0.497, data: 0.000) G_GAN: 5.310 G_L1: 14.127 D_real: 0.003 D_fake: 0.035 \n",
            "(epoch: 552, iters: 204, time: 0.023, data: 0.001) G_GAN: 7.839 G_L1: 18.682 D_real: 0.012 D_fake: 0.003 \n",
            "End of epoch 552 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000319\n",
            "(epoch: 553, iters: 8, time: 0.024, data: 0.001) G_GAN: 7.538 G_L1: 13.010 D_real: 0.011 D_fake: 0.004 \n",
            "(epoch: 553, iters: 108, time: 0.023, data: 0.002) G_GAN: 10.002 G_L1: 16.016 D_real: 0.087 D_fake: 0.000 \n",
            "(epoch: 553, iters: 208, time: 0.524, data: 0.001) G_GAN: 4.758 G_L1: 16.090 D_real: 0.022 D_fake: 0.123 \n",
            "End of epoch 553 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000312\n",
            "(epoch: 554, iters: 12, time: 0.023, data: 0.001) G_GAN: 6.641 G_L1: 16.730 D_real: 0.002 D_fake: 0.007 \n",
            "(epoch: 554, iters: 112, time: 0.024, data: 0.001) G_GAN: 6.757 G_L1: 13.488 D_real: 0.003 D_fake: 0.003 \n",
            "(epoch: 554, iters: 212, time: 0.025, data: 0.001) G_GAN: 9.676 G_L1: 17.970 D_real: 0.002 D_fake: 0.000 \n",
            "End of epoch 554 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000306\n",
            "(epoch: 555, iters: 16, time: 0.689, data: 0.001) G_GAN: 5.822 G_L1: 12.661 D_real: 0.007 D_fake: 0.015 \n",
            "(epoch: 555, iters: 116, time: 0.026, data: 0.001) G_GAN: 7.008 G_L1: 13.923 D_real: 0.035 D_fake: 0.004 \n",
            "(epoch: 555, iters: 216, time: 0.024, data: 0.002) G_GAN: 4.918 G_L1: 13.343 D_real: 0.032 D_fake: 0.065 \n",
            "saving the model at the end of epoch 555, iters 164280\n",
            "End of epoch 555 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0000299\n",
            "(epoch: 556, iters: 20, time: 0.023, data: 0.002) G_GAN: 7.853 G_L1: 14.137 D_real: 0.024 D_fake: 0.002 \n",
            "(epoch: 556, iters: 120, time: 0.567, data: 0.001) G_GAN: 7.968 G_L1: 14.392 D_real: 0.063 D_fake: 0.003 \n",
            "(epoch: 556, iters: 220, time: 0.028, data: 0.001) G_GAN: 9.049 G_L1: 17.803 D_real: 0.010 D_fake: 0.001 \n",
            "End of epoch 556 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0000292\n",
            "(epoch: 557, iters: 24, time: 0.032, data: 0.002) G_GAN: 4.861 G_L1: 14.171 D_real: 0.001 D_fake: 0.330 \n",
            "(epoch: 557, iters: 124, time: 0.024, data: 0.001) G_GAN: 7.237 G_L1: 16.735 D_real: 0.000 D_fake: 0.010 \n",
            "(epoch: 557, iters: 224, time: 0.525, data: 0.001) G_GAN: 6.576 G_L1: 13.534 D_real: 0.007 D_fake: 0.005 \n",
            "End of epoch 557 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000286\n",
            "(epoch: 558, iters: 28, time: 0.024, data: 0.001) G_GAN: 5.483 G_L1: 14.964 D_real: 0.022 D_fake: 0.028 \n",
            "(epoch: 558, iters: 128, time: 0.024, data: 0.001) G_GAN: 7.051 G_L1: 13.573 D_real: 0.006 D_fake: 0.005 \n",
            "saving the latest model (epoch 558, total_iters 165000)\n",
            "(epoch: 558, iters: 228, time: 0.023, data: 0.002) G_GAN: 9.930 G_L1: 17.398 D_real: 0.108 D_fake: 0.000 \n",
            "End of epoch 558 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000279\n",
            "(epoch: 559, iters: 32, time: 0.618, data: 0.001) G_GAN: 11.124 G_L1: 13.575 D_real: 0.002 D_fake: 0.000 \n",
            "(epoch: 559, iters: 132, time: 0.030, data: 0.004) G_GAN: 8.090 G_L1: 15.226 D_real: 0.006 D_fake: 0.004 \n",
            "(epoch: 559, iters: 232, time: 0.030, data: 0.001) G_GAN: 8.196 G_L1: 17.394 D_real: 0.018 D_fake: 0.001 \n",
            "End of epoch 559 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0000272\n",
            "(epoch: 560, iters: 36, time: 0.026, data: 0.001) G_GAN: 12.046 G_L1: 16.919 D_real: 0.047 D_fake: 0.000 \n",
            "(epoch: 560, iters: 136, time: 0.540, data: 0.001) G_GAN: 6.579 G_L1: 15.120 D_real: 0.005 D_fake: 0.009 \n",
            "(epoch: 560, iters: 236, time: 0.023, data: 0.001) G_GAN: 5.189 G_L1: 14.271 D_real: 0.004 D_fake: 0.032 \n",
            "saving the model at the end of epoch 560, iters 165760\n",
            "End of epoch 560 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0000266\n",
            "(epoch: 561, iters: 40, time: 0.024, data: 0.001) G_GAN: 9.200 G_L1: 17.200 D_real: 0.011 D_fake: 0.000 \n",
            "(epoch: 561, iters: 140, time: 0.023, data: 0.001) G_GAN: 7.326 G_L1: 14.578 D_real: 0.007 D_fake: 0.002 \n",
            "(epoch: 561, iters: 240, time: 0.824, data: 0.001) G_GAN: 6.293 G_L1: 12.568 D_real: 0.020 D_fake: 0.008 \n",
            "End of epoch 561 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0000259\n",
            "(epoch: 562, iters: 44, time: 0.024, data: 0.003) G_GAN: 5.794 G_L1: 15.294 D_real: 0.008 D_fake: 0.014 \n",
            "(epoch: 562, iters: 144, time: 0.024, data: 0.001) G_GAN: 4.507 G_L1: 10.123 D_real: 0.001 D_fake: 0.265 \n",
            "(epoch: 562, iters: 244, time: 0.025, data: 0.001) G_GAN: 8.418 G_L1: 14.503 D_real: 0.007 D_fake: 0.001 \n",
            "End of epoch 562 / 600 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000252\n",
            "(epoch: 563, iters: 48, time: 0.524, data: 0.001) G_GAN: 6.844 G_L1: 16.291 D_real: 0.004 D_fake: 0.009 \n",
            "(epoch: 563, iters: 148, time: 0.024, data: 0.001) G_GAN: 8.697 G_L1: 16.363 D_real: 0.004 D_fake: 0.002 \n",
            "(epoch: 563, iters: 248, time: 0.029, data: 0.001) G_GAN: 5.102 G_L1: 15.321 D_real: 0.058 D_fake: 0.043 \n",
            "End of epoch 563 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000246\n",
            "(epoch: 564, iters: 52, time: 0.024, data: 0.001) G_GAN: 9.162 G_L1: 15.689 D_real: 0.003 D_fake: 0.001 \n",
            "(epoch: 564, iters: 152, time: 0.560, data: 0.001) G_GAN: 7.755 G_L1: 13.480 D_real: 0.004 D_fake: 0.006 \n",
            "(epoch: 564, iters: 252, time: 0.023, data: 0.002) G_GAN: 7.277 G_L1: 18.527 D_real: 0.001 D_fake: 0.006 \n",
            "End of epoch 564 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000239\n",
            "(epoch: 565, iters: 56, time: 0.026, data: 0.001) G_GAN: 6.444 G_L1: 13.432 D_real: 0.029 D_fake: 0.021 \n",
            "(epoch: 565, iters: 156, time: 0.025, data: 0.001) G_GAN: 6.783 G_L1: 11.935 D_real: 0.036 D_fake: 0.010 \n",
            "(epoch: 565, iters: 256, time: 0.585, data: 0.001) G_GAN: 9.060 G_L1: 13.999 D_real: 0.000 D_fake: 0.001 \n",
            "saving the model at the end of epoch 565, iters 167240\n",
            "End of epoch 565 / 600 \t Time Taken: 10 sec\n",
            "learning rate = 0.0000233\n",
            "(epoch: 566, iters: 60, time: 0.026, data: 0.002) G_GAN: 7.957 G_L1: 13.821 D_real: 0.001 D_fake: 0.003 \n",
            "(epoch: 566, iters: 160, time: 0.032, data: 0.001) G_GAN: 7.253 G_L1: 14.165 D_real: 0.003 D_fake: 0.004 \n",
            "(epoch: 566, iters: 260, time: 0.023, data: 0.002) G_GAN: 7.608 G_L1: 12.023 D_real: 0.010 D_fake: 0.003 \n",
            "End of epoch 566 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000226\n",
            "(epoch: 567, iters: 64, time: 0.593, data: 0.001) G_GAN: 7.658 G_L1: 14.990 D_real: 0.013 D_fake: 0.004 \n",
            "(epoch: 567, iters: 164, time: 0.025, data: 0.002) G_GAN: 4.749 G_L1: 13.581 D_real: 0.031 D_fake: 0.031 \n",
            "(epoch: 567, iters: 264, time: 0.025, data: 0.001) G_GAN: 7.637 G_L1: 17.691 D_real: 0.001 D_fake: 0.003 \n",
            "End of epoch 567 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000219\n",
            "(epoch: 568, iters: 68, time: 0.024, data: 0.001) G_GAN: 8.170 G_L1: 15.967 D_real: 0.007 D_fake: 0.004 \n",
            "(epoch: 568, iters: 168, time: 0.492, data: 0.001) G_GAN: 7.306 G_L1: 15.287 D_real: 0.010 D_fake: 0.002 \n",
            "(epoch: 568, iters: 268, time: 0.024, data: 0.003) G_GAN: 4.684 G_L1: 16.136 D_real: 0.027 D_fake: 0.366 \n",
            "End of epoch 568 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000213\n",
            "(epoch: 569, iters: 72, time: 0.023, data: 0.001) G_GAN: 6.584 G_L1: 16.517 D_real: 0.009 D_fake: 0.006 \n",
            "(epoch: 569, iters: 172, time: 0.030, data: 0.001) G_GAN: 4.780 G_L1: 11.434 D_real: 0.105 D_fake: 0.025 \n",
            "(epoch: 569, iters: 272, time: 0.569, data: 0.001) G_GAN: 8.335 G_L1: 11.940 D_real: 0.026 D_fake: 0.001 \n",
            "End of epoch 569 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000206\n",
            "(epoch: 570, iters: 76, time: 0.033, data: 0.001) G_GAN: 4.910 G_L1: 13.668 D_real: 0.007 D_fake: 0.079 \n",
            "(epoch: 570, iters: 176, time: 0.026, data: 0.001) G_GAN: 7.329 G_L1: 15.704 D_real: 0.030 D_fake: 0.002 \n",
            "(epoch: 570, iters: 276, time: 0.031, data: 0.002) G_GAN: 11.868 G_L1: 15.849 D_real: 0.000 D_fake: 0.000 \n",
            "saving the model at the end of epoch 570, iters 168720\n",
            "End of epoch 570 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000199\n",
            "(epoch: 571, iters: 80, time: 0.561, data: 0.001) G_GAN: 5.289 G_L1: 11.877 D_real: 0.002 D_fake: 0.017 \n",
            "(epoch: 571, iters: 180, time: 0.023, data: 0.001) G_GAN: 6.264 G_L1: 12.611 D_real: 0.003 D_fake: 0.006 \n",
            "(epoch: 571, iters: 280, time: 0.024, data: 0.001) G_GAN: 7.590 G_L1: 15.327 D_real: 0.021 D_fake: 0.006 \n",
            "End of epoch 571 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0000193\n",
            "(epoch: 572, iters: 84, time: 0.027, data: 0.001) G_GAN: 10.727 G_L1: 13.656 D_real: 0.026 D_fake: 0.000 \n",
            "(epoch: 572, iters: 184, time: 0.562, data: 0.001) G_GAN: 4.906 G_L1: 15.726 D_real: 0.011 D_fake: 0.219 \n",
            "(epoch: 572, iters: 284, time: 0.023, data: 0.001) G_GAN: 5.401 G_L1: 11.606 D_real: 0.008 D_fake: 0.043 \n",
            "End of epoch 572 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000186\n",
            "(epoch: 573, iters: 88, time: 0.024, data: 0.001) G_GAN: 5.666 G_L1: 18.993 D_real: 0.046 D_fake: 0.007 \n",
            "(epoch: 573, iters: 188, time: 0.024, data: 0.002) G_GAN: 5.858 G_L1: 13.158 D_real: 0.006 D_fake: 0.017 \n",
            "(epoch: 573, iters: 288, time: 0.556, data: 0.001) G_GAN: 6.457 G_L1: 15.470 D_real: 0.020 D_fake: 0.047 \n",
            "End of epoch 573 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000179\n",
            "(epoch: 574, iters: 92, time: 0.024, data: 0.002) G_GAN: 6.626 G_L1: 14.214 D_real: 0.008 D_fake: 0.022 \n",
            "(epoch: 574, iters: 192, time: 0.024, data: 0.001) G_GAN: 6.202 G_L1: 17.052 D_real: 0.000 D_fake: 0.009 \n",
            "(epoch: 574, iters: 292, time: 0.025, data: 0.001) G_GAN: 9.134 G_L1: 14.740 D_real: 0.002 D_fake: 0.001 \n",
            "End of epoch 574 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000173\n",
            "(epoch: 575, iters: 96, time: 0.727, data: 0.001) G_GAN: 6.338 G_L1: 15.198 D_real: 0.011 D_fake: 0.013 \n",
            "saving the latest model (epoch 575, total_iters 170000)\n",
            "(epoch: 575, iters: 196, time: 0.025, data: 0.002) G_GAN: 7.440 G_L1: 15.017 D_real: 0.073 D_fake: 0.001 \n",
            "(epoch: 575, iters: 296, time: 0.022, data: 0.001) G_GAN: 5.845 G_L1: 14.629 D_real: 0.007 D_fake: 0.018 \n",
            "saving the model at the end of epoch 575, iters 170200\n",
            "End of epoch 575 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0000166\n",
            "(epoch: 576, iters: 100, time: 0.023, data: 0.131) G_GAN: 8.010 G_L1: 13.944 D_real: 0.002 D_fake: 0.003 \n",
            "(epoch: 576, iters: 200, time: 0.809, data: 0.001) G_GAN: 6.886 G_L1: 13.861 D_real: 0.012 D_fake: 0.003 \n",
            "End of epoch 576 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0000159\n",
            "(epoch: 577, iters: 4, time: 0.034, data: 0.001) G_GAN: 6.165 G_L1: 15.199 D_real: 0.014 D_fake: 0.010 \n",
            "(epoch: 577, iters: 104, time: 0.023, data: 0.000) G_GAN: 8.139 G_L1: 14.294 D_real: 0.001 D_fake: 0.002 \n",
            "(epoch: 577, iters: 204, time: 0.024, data: 0.001) G_GAN: 7.704 G_L1: 14.502 D_real: 0.003 D_fake: 0.001 \n",
            "End of epoch 577 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000153\n",
            "(epoch: 578, iters: 8, time: 0.583, data: 0.002) G_GAN: 9.966 G_L1: 17.962 D_real: 0.013 D_fake: 0.000 \n",
            "(epoch: 578, iters: 108, time: 0.025, data: 0.001) G_GAN: 8.195 G_L1: 18.745 D_real: 0.007 D_fake: 0.004 \n",
            "(epoch: 578, iters: 208, time: 0.025, data: 0.001) G_GAN: 4.201 G_L1: 15.564 D_real: 0.080 D_fake: 0.192 \n",
            "End of epoch 578 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000146\n",
            "(epoch: 579, iters: 12, time: 0.024, data: 0.001) G_GAN: 11.296 G_L1: 17.302 D_real: 0.014 D_fake: 0.000 \n",
            "(epoch: 579, iters: 112, time: 0.519, data: 0.001) G_GAN: 4.380 G_L1: 15.614 D_real: 0.001 D_fake: 0.064 \n",
            "(epoch: 579, iters: 212, time: 0.030, data: 0.002) G_GAN: 7.174 G_L1: 21.991 D_real: 0.002 D_fake: 0.007 \n",
            "End of epoch 579 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000140\n",
            "(epoch: 580, iters: 16, time: 0.025, data: 0.002) G_GAN: 7.672 G_L1: 15.238 D_real: 0.026 D_fake: 0.002 \n",
            "(epoch: 580, iters: 116, time: 0.024, data: 0.001) G_GAN: 6.578 G_L1: 14.825 D_real: 0.068 D_fake: 0.007 \n",
            "(epoch: 580, iters: 216, time: 0.566, data: 0.001) G_GAN: 6.773 G_L1: 17.612 D_real: 0.004 D_fake: 0.009 \n",
            "saving the model at the end of epoch 580, iters 171680\n",
            "End of epoch 580 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0000133\n",
            "(epoch: 581, iters: 20, time: 0.026, data: 0.002) G_GAN: 9.666 G_L1: 16.427 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 581, iters: 120, time: 0.023, data: 0.001) G_GAN: 5.378 G_L1: 13.639 D_real: 0.000 D_fake: 0.035 \n",
            "(epoch: 581, iters: 220, time: 0.036, data: 0.001) G_GAN: 8.457 G_L1: 16.212 D_real: 0.002 D_fake: 0.002 \n",
            "End of epoch 581 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000126\n",
            "(epoch: 582, iters: 24, time: 0.541, data: 0.001) G_GAN: 6.015 G_L1: 14.612 D_real: 0.026 D_fake: 0.006 \n",
            "(epoch: 582, iters: 124, time: 0.025, data: 0.002) G_GAN: 6.079 G_L1: 14.669 D_real: 0.019 D_fake: 0.009 \n",
            "(epoch: 582, iters: 224, time: 0.024, data: 0.002) G_GAN: 7.348 G_L1: 15.984 D_real: 0.052 D_fake: 0.002 \n",
            "End of epoch 582 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000120\n",
            "(epoch: 583, iters: 28, time: 0.025, data: 0.001) G_GAN: 9.794 G_L1: 16.622 D_real: 0.037 D_fake: 0.000 \n",
            "(epoch: 583, iters: 128, time: 0.612, data: 0.002) G_GAN: 6.136 G_L1: 14.559 D_real: 0.042 D_fake: 0.006 \n",
            "(epoch: 583, iters: 228, time: 0.024, data: 0.002) G_GAN: 4.055 G_L1: 12.170 D_real: 0.002 D_fake: 0.072 \n",
            "End of epoch 583 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000113\n",
            "(epoch: 584, iters: 32, time: 0.024, data: 0.001) G_GAN: 6.561 G_L1: 15.373 D_real: 0.008 D_fake: 0.006 \n",
            "(epoch: 584, iters: 132, time: 0.024, data: 0.002) G_GAN: 9.952 G_L1: 15.116 D_real: 0.024 D_fake: 0.001 \n",
            "(epoch: 584, iters: 232, time: 0.577, data: 0.001) G_GAN: 8.211 G_L1: 14.329 D_real: 0.011 D_fake: 0.001 \n",
            "End of epoch 584 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000106\n",
            "(epoch: 585, iters: 36, time: 0.024, data: 0.001) G_GAN: 6.006 G_L1: 15.484 D_real: 0.043 D_fake: 0.031 \n",
            "(epoch: 585, iters: 136, time: 0.024, data: 0.001) G_GAN: 3.957 G_L1: 14.656 D_real: 0.013 D_fake: 0.108 \n",
            "(epoch: 585, iters: 236, time: 0.024, data: 0.001) G_GAN: 6.990 G_L1: 11.480 D_real: 0.008 D_fake: 0.004 \n",
            "saving the model at the end of epoch 585, iters 173160\n",
            "End of epoch 585 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000100\n",
            "(epoch: 586, iters: 40, time: 0.533, data: 0.001) G_GAN: 4.966 G_L1: 14.003 D_real: 0.013 D_fake: 0.023 \n",
            "(epoch: 586, iters: 140, time: 0.024, data: 0.001) G_GAN: 4.094 G_L1: 11.500 D_real: 0.034 D_fake: 0.042 \n",
            "(epoch: 586, iters: 240, time: 0.025, data: 0.001) G_GAN: 9.452 G_L1: 15.829 D_real: 0.005 D_fake: 0.002 \n",
            "End of epoch 586 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0000093\n",
            "(epoch: 587, iters: 44, time: 0.024, data: 0.002) G_GAN: 9.504 G_L1: 12.198 D_real: 0.004 D_fake: 0.001 \n",
            "(epoch: 587, iters: 144, time: 0.577, data: 0.001) G_GAN: 10.059 G_L1: 11.802 D_real: 0.007 D_fake: 0.000 \n",
            "(epoch: 587, iters: 244, time: 0.023, data: 0.002) G_GAN: 8.565 G_L1: 14.484 D_real: 0.000 D_fake: 0.001 \n",
            "End of epoch 587 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000086\n",
            "(epoch: 588, iters: 48, time: 0.024, data: 0.001) G_GAN: 8.264 G_L1: 14.259 D_real: 0.001 D_fake: 0.002 \n",
            "(epoch: 588, iters: 148, time: 0.025, data: 0.001) G_GAN: 6.129 G_L1: 12.937 D_real: 0.004 D_fake: 0.018 \n",
            "(epoch: 588, iters: 248, time: 0.560, data: 0.001) G_GAN: 4.452 G_L1: 15.508 D_real: 0.003 D_fake: 0.098 \n",
            "End of epoch 588 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000080\n",
            "(epoch: 589, iters: 52, time: 0.023, data: 0.001) G_GAN: 5.885 G_L1: 14.007 D_real: 0.003 D_fake: 0.014 \n",
            "(epoch: 589, iters: 152, time: 0.024, data: 0.001) G_GAN: 8.079 G_L1: 12.277 D_real: 0.002 D_fake: 0.002 \n",
            "(epoch: 589, iters: 252, time: 0.031, data: 0.001) G_GAN: 6.550 G_L1: 16.747 D_real: 0.001 D_fake: 0.014 \n",
            "End of epoch 589 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000073\n",
            "(epoch: 590, iters: 56, time: 0.605, data: 0.001) G_GAN: 7.308 G_L1: 14.200 D_real: 0.098 D_fake: 0.004 \n",
            "(epoch: 590, iters: 156, time: 0.024, data: 0.002) G_GAN: 6.835 G_L1: 11.962 D_real: 0.020 D_fake: 0.003 \n",
            "(epoch: 590, iters: 256, time: 0.028, data: 0.001) G_GAN: 7.360 G_L1: 13.204 D_real: 0.018 D_fake: 0.002 \n",
            "saving the model at the end of epoch 590, iters 174640\n",
            "End of epoch 590 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0000066\n",
            "(epoch: 591, iters: 60, time: 0.024, data: 0.001) G_GAN: 6.763 G_L1: 13.898 D_real: 0.005 D_fake: 0.003 \n",
            "(epoch: 591, iters: 160, time: 0.673, data: 0.002) G_GAN: 7.950 G_L1: 14.117 D_real: 0.025 D_fake: 0.002 \n",
            "(epoch: 591, iters: 260, time: 0.024, data: 0.003) G_GAN: 7.891 G_L1: 14.439 D_real: 0.021 D_fake: 0.008 \n",
            "End of epoch 591 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0000060\n",
            "(epoch: 592, iters: 64, time: 0.025, data: 0.001) G_GAN: 7.385 G_L1: 9.492 D_real: 0.022 D_fake: 0.017 \n",
            "saving the latest model (epoch 592, total_iters 175000)\n",
            "(epoch: 592, iters: 164, time: 0.024, data: 0.002) G_GAN: 9.106 G_L1: 12.044 D_real: 0.096 D_fake: 0.001 \n",
            "(epoch: 592, iters: 264, time: 0.568, data: 0.001) G_GAN: 6.643 G_L1: 12.213 D_real: 0.132 D_fake: 0.003 \n",
            "End of epoch 592 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000053\n",
            "(epoch: 593, iters: 68, time: 0.052, data: 0.002) G_GAN: 6.211 G_L1: 14.105 D_real: 0.123 D_fake: 0.010 \n",
            "(epoch: 593, iters: 168, time: 0.024, data: 0.002) G_GAN: 5.532 G_L1: 17.722 D_real: 0.041 D_fake: 0.017 \n",
            "(epoch: 593, iters: 268, time: 0.029, data: 0.001) G_GAN: 5.288 G_L1: 14.308 D_real: 0.046 D_fake: 0.023 \n",
            "End of epoch 593 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000047\n",
            "(epoch: 594, iters: 72, time: 0.558, data: 0.001) G_GAN: 7.228 G_L1: 14.106 D_real: 0.010 D_fake: 0.009 \n",
            "(epoch: 594, iters: 172, time: 0.024, data: 0.001) G_GAN: 5.181 G_L1: 15.176 D_real: 0.007 D_fake: 0.028 \n",
            "(epoch: 594, iters: 272, time: 0.023, data: 0.001) G_GAN: 4.346 G_L1: 10.672 D_real: 0.003 D_fake: 0.049 \n",
            "End of epoch 594 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000040\n",
            "(epoch: 595, iters: 76, time: 0.025, data: 0.001) G_GAN: 8.986 G_L1: 15.840 D_real: 0.006 D_fake: 0.001 \n",
            "(epoch: 595, iters: 176, time: 0.603, data: 0.001) G_GAN: 5.841 G_L1: 12.250 D_real: 0.006 D_fake: 0.034 \n",
            "(epoch: 595, iters: 276, time: 0.025, data: 0.001) G_GAN: 7.539 G_L1: 12.649 D_real: 0.002 D_fake: 0.008 \n",
            "saving the model at the end of epoch 595, iters 176120\n",
            "End of epoch 595 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0000033\n",
            "(epoch: 596, iters: 80, time: 0.024, data: 0.001) G_GAN: 6.405 G_L1: 11.813 D_real: 0.011 D_fake: 0.009 \n",
            "(epoch: 596, iters: 180, time: 0.029, data: 0.001) G_GAN: 6.691 G_L1: 15.432 D_real: 0.005 D_fake: 0.005 \n",
            "(epoch: 596, iters: 280, time: 0.575, data: 0.001) G_GAN: 6.535 G_L1: 12.895 D_real: 0.005 D_fake: 0.005 \n",
            "End of epoch 596 / 600 \t Time Taken: 9 sec\n",
            "learning rate = 0.0000027\n",
            "(epoch: 597, iters: 84, time: 0.029, data: 0.001) G_GAN: 2.737 G_L1: 13.510 D_real: 0.002 D_fake: 0.159 \n",
            "(epoch: 597, iters: 184, time: 0.024, data: 0.001) G_GAN: 6.847 G_L1: 14.125 D_real: 0.096 D_fake: 0.010 \n",
            "(epoch: 597, iters: 284, time: 0.024, data: 0.001) G_GAN: 7.389 G_L1: 15.491 D_real: 0.006 D_fake: 0.003 \n",
            "End of epoch 597 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000020\n",
            "(epoch: 598, iters: 88, time: 0.568, data: 0.001) G_GAN: 8.391 G_L1: 16.962 D_real: 0.002 D_fake: 0.001 \n",
            "(epoch: 598, iters: 188, time: 0.030, data: 0.001) G_GAN: 5.402 G_L1: 13.572 D_real: 0.044 D_fake: 0.013 \n",
            "(epoch: 598, iters: 288, time: 0.026, data: 0.001) G_GAN: 9.129 G_L1: 12.174 D_real: 0.015 D_fake: 0.001 \n",
            "End of epoch 598 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000013\n",
            "(epoch: 599, iters: 92, time: 0.023, data: 0.001) G_GAN: 7.367 G_L1: 15.524 D_real: 0.003 D_fake: 0.002 \n",
            "(epoch: 599, iters: 192, time: 0.569, data: 0.002) G_GAN: 7.435 G_L1: 13.173 D_real: 0.018 D_fake: 0.003 \n",
            "(epoch: 599, iters: 292, time: 0.023, data: 0.001) G_GAN: 4.887 G_L1: 14.192 D_real: 0.005 D_fake: 0.017 \n",
            "End of epoch 599 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000007\n",
            "(epoch: 600, iters: 96, time: 0.024, data: 0.002) G_GAN: 4.920 G_L1: 15.637 D_real: 0.004 D_fake: 0.037 \n",
            "(epoch: 600, iters: 196, time: 0.024, data: 0.001) G_GAN: 11.758 G_L1: 11.122 D_real: 0.016 D_fake: 0.000 \n",
            "(epoch: 600, iters: 296, time: 0.544, data: 0.001) G_GAN: 4.180 G_L1: 12.437 D_real: 0.005 D_fake: 0.033 \n",
            "saving the model at the end of epoch 600, iters 177600\n",
            "End of epoch 600 / 600 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UkcaFZiyASl"
      },
      "source": [
        "# Testing\n",
        "\n",
        "-   `python test.py --dataroot ./datasets/facades --direction BtoA --model pix2pix --name facades_pix2pix`\n",
        "\n",
        "Change the `--dataroot`, `--name`, and `--direction` to be consistent with your trained model's configuration and how you want to transform images.\n",
        "\n",
        "> from https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix:\n",
        "> Note that we specified --direction BtoA as Facades dataset's A to B direction is photos to labels.\n",
        "\n",
        "> If you would like to apply a pre-trained model to a collection of input images (rather than image pairs), please use --model test option. See ./scripts/test_single.sh for how to apply a model to Facade label maps (stored in the directory facades/testB).\n",
        "\n",
        "> See a list of currently available models at ./scripts/download_pix2pix_model.sh"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCsKkEq0yGh0",
        "outputId": "b31b7a4d-bf1a-4c75-b58b-f307d6790c6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in range(5,605,5):\n",
        "    !python test.py --dataroot '../AB' --direction AtoB --model pix2pix --name mel_pix2pix --preprocess none --netG resnet_6blocks --checkpoints_dir './checkpoints' --results_dir './results' --epoch $i"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/155_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_155\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 160                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/160_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_160\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 165                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/165_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_165\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 170                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/170_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_170\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 175                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/175_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_175\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 180                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/180_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_180\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 185                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/185_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_185\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 190                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/190_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_190\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 195                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/195_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_195\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 200                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/200_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_200\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 205                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/205_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_205\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 210                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/210_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_210\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 215                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/215_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_215\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 220                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/220_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_220\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 225                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/225_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_225\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 230                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/230_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_230\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 235                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/235_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_235\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 240                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/240_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_240\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 245                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/245_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_245\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 250                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/250_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_250\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 255                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/255_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_255\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 260                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/260_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_260\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 265                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/265_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_265\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 270                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/270_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_270\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 275                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/275_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_275\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 280                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/280_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_280\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 285                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/285_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_285\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 290                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/290_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_290\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 295                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/295_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_295\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 300                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/300_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_300\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 305                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/305_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_305\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 310                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/310_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_310\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 315                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/315_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_315\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 320                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/320_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_320\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 325                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/325_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_325\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 330                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/330_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_330\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 335                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/335_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_335\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 340                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/340_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_340\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 345                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/345_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_345\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 350                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/350_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_350\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 355                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/355_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_355\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 360                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/360_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_360\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 365                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/365_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_365\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 370                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/370_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_370\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 375                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/375_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_375\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 380                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/380_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_380\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 385                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/385_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_385\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 390                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/390_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_390\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 395                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/395_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_395\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 400                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/400_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_400\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 405                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/405_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_405\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 410                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/410_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_410\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 415                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/415_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_415\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 420                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/420_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_420\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 425                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/425_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_425\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 430                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/430_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_430\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 435                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/435_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_435\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 440                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/440_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_440\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 445                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/445_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_445\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 450                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/450_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_450\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 455                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/455_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_455\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 460                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/460_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_460\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 465                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/465_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_465\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 470                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/470_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_470\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 475                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/475_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_475\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 480                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/480_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_480\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 485                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/485_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_485\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 490                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/490_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_490\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 495                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/495_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_495\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 500                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/500_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_500\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 505                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/505_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_505\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 510                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/510_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_510\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 515                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/515_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_515\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 520                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/520_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_520\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 525                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/525_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_525\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 530                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/530_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_530\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 535                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/535_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_535\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 540                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/540_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_540\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 545                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/545_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_545\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 550                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/550_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_550\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 555                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/555_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_555\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 560                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/560_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_560\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 565                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/565_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_565\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 570                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/570_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_570\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 575                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/575_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_575\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 580                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/580_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_580\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 585                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/585_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_585\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 590                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/590_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_590\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 595                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/595_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_595\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB                         \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 600                           \t[default: latest]\n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results                     \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/600_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_600\n",
            "processing (0000)-th image... ['../AB/test/OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB/test/OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB/test/OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB/test/OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB/test/YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB/test/YAF_king.png']\n",
            "processing (0030)-th image... ['../AB/test/YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB/test/YAF_south.png']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzSKIPUByfiN"
      },
      "source": [
        "# Visualize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4hV7C4AABmZ",
        "outputId": "2d994c68-ffb8-4d1d-bf18-773a511edcfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!set -ex\n",
        "!python test.py --dataroot  '../AB1' --name mel_pix2pix --model test --netG resnet_6blocks --direction AtoB --dataset_mode single --norm batch "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ../AB1                        \t[default: None]\n",
            "             dataset_mode: single                        \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: latest                        \n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: test                          \n",
            "             model_suffix:                               \n",
            "               n_layers_D: 3                             \n",
            "                     name: mel_pix2pix                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_6blocks                \t[default: resnet_9blocks]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \t[default: instance]\n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: resize_and_crop               \n",
            "              results_dir: ./results/                    \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [SingleDataset] was created\n",
            "initialize network with normal\n",
            "model [TestModel] was created\n",
            "loading the model from ./checkpoints/mel_pix2pix/latest_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 7.841 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/mel_pix2pix/test_latest\n",
            "processing (0000)-th image... ['../AB1/test/Copy of OAF_deep.png']\n",
            "processing (0005)-th image... ['../AB1/test/Copy of OAF_mess.png']\n",
            "processing (0010)-th image... ['../AB1/test/Copy of OAF_rough.png']\n",
            "processing (0015)-th image... ['../AB1/test/Copy of OAF_vine.png']\n",
            "processing (0020)-th image... ['../AB1/test/Copy of YAF_beg.png']\n",
            "processing (0025)-th image... ['../AB1/test/Copy of YAF_king.png']\n",
            "processing (0030)-th image... ['../AB1/test/Copy of YAF_pool.png']\n",
            "processing (0035)-th image... ['../AB1/test/Copy of YAF_south.png']\n",
            "processing (0040)-th image... ['../AB1/train/OAF_beg.png']\n",
            "processing (0045)-th image... ['../AB1/train/OAF_cause.png']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwKHOpzBG2zM",
        "outputId": "02f4fd2a-6361-49d3-b583-5bb61c265bcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "!python -m visdom.server"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking for scripts.\n",
            "It's Alive!\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/visdom/server.py\", line 1922, in <module>\n",
            "    download_scripts_and_run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/visdom/server.py\", line 1918, in download_scripts_and_run\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/visdom/server.py\", line 1913, in main\n",
            "    use_frontend_client_polling=FLAGS.use_frontend_client_polling)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/visdom/server.py\", line 1791, in start_server\n",
            "    app.listen(port, max_buffer_size=1024 ** 3)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tornado/web.py\", line 1944, in listen\n",
            "    server.listen(port, address)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tornado/tcpserver.py\", line 142, in listen\n",
            "    sockets = bind_sockets(port, address=address)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tornado/netutil.py\", line 197, in bind_sockets\n",
            "    sock.bind(sockaddr)\n",
            "OSError: [Errno 98] Address already in use\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lti54ssQDgbo",
        "outputId": "46d3eca8-94d5-4e98-98bc-d622c2dde73f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "os.getcwd()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/pytorch-CycleGAN-and-pix2pix'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Mgg8raPyizq",
        "outputId": "84677168-8cab-414c-d954-64ab2a8a1112",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img = plt.imread('../results/mel_pix2pix/test_latest/images/03-01-01-01-09_fake_B.png')\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f8d734909b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0G3oVH9DyqLQ",
        "outputId": "3bc932e5-2aa5-4545-9bcb-e40f6378656e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "img = plt.imread('../results/mel_pix2pix/test_latest/images/03-01-01-01-09_real_A.png')\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f8d71bbba20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErK5OC1j1LH4",
        "outputId": "66435fa5-1092-4c06-d7a1-ef9b2dc564d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "img = plt.imread('../results/mel_pix2pix/test_latest/images/03-01-01-01-09_real_B.png')\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f8d71bad320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiEGgm08Q3oH"
      },
      "source": [
        "!zip -r ./results.zip ./results\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qU8XcWvFRbcJ",
        "outputId": "82c86f46-e719-44fc-8de7-de3827b62c32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"./results.zip\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-ff11ff0d80db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./results.zip\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0;34m'port'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m       \u001b[0;34m'path'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m       \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m   })\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: TypeError: Failed to fetch"
          ]
        }
      ]
    }
  ]
}